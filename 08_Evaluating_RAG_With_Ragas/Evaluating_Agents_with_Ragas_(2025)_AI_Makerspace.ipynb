{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1ub1OLYZQvz"
      },
      "source": [
        "# Using Ragas to Evaluate an Agent Application built with LangChain and LangGraph\n",
        "\n",
        "In the following notebook, we'll be looking at how [Ragas](https://github.com/explodinggradients/ragas) can be helpful in a number of ways when looking to evaluate your RAG applications!\n",
        "\n",
        "While this example is rooted in LangChain/LangGraph - Ragas is framework agnostic (you don't even need to be using a framework!).\n",
        "\n",
        "We'll:\n",
        "\n",
        "- Collect our data\n",
        "- Create a simple Agent application\n",
        "- Evaluate our Agent application\n",
        "\n",
        "> NOTE: This notebook is very lightly modified from Ragas' [LangGraph tutorial](https://docs.ragas.io/en/stable/howtos/integrations/_langgraph_agent_evaluation/)!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8Ms4ngAZQv1"
      },
      "source": [
        "## Installing Ragas and Other Dependencies\n",
        "Install Ragas and Langgraph with pip:\n",
        "\n",
        "> NOTE: Skip this step if you are running the notebook locally."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "vQk4aWbpZQv1"
      },
      "outputs": [],
      "source": [
        "#!pip install -qU langgraph==0.2.44 ragas==0.2.12 nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7iNPhN9_opo"
      },
      "source": [
        "### metals.dev API Key\n",
        "\n",
        "Sign up for an account on [metals.dev](https://metals.dev/) to get your API key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lB5bVnoV7rz-",
        "outputId": "e06d119b-fc01-466f-864c-f63bc1c299b2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"METAL_API_KEY\"] = getpass.getpass(\"Enter your API key: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOK8wAl8_zsq"
      },
      "source": [
        "### OpenAI API Key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGYb7M0x7y2g",
        "outputId": "59b66cbb-d559-4c91-bbf5-542bbe49f31e"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJJ-WKWMZQv2"
      },
      "source": [
        "## Building the ReAct Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SduQYJbZQv3"
      },
      "source": [
        "### Define the get_metal_price Tool\n",
        "\n",
        "The get_metal_price tool will be used by the agent to fetch the price of a specified metal. We'll create this tool using the @tool decorator from LangChain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1X2TsFLfZQv3"
      },
      "outputs": [],
      "source": [
        "from langchain_core.tools import tool\n",
        "import requests\n",
        "from requests.structures import CaseInsensitiveDict\n",
        "import os\n",
        "\n",
        "\n",
        "# Define the tools for the agent to use\n",
        "@tool\n",
        "def get_metal_price(metal_name: str) -> float:\n",
        "    \"\"\"Fetches the current per gram price of the specified metal.\n",
        "\n",
        "    Args:\n",
        "        metal_name : The name of the metal (e.g., 'gold', 'silver', 'platinum').\n",
        "\n",
        "    Returns:\n",
        "        float: The current price of the metal in dollars per gram.\n",
        "\n",
        "    Raises:\n",
        "        KeyError: If the specified metal is not found in the data source.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        metal_name = metal_name.lower().strip()\n",
        "        url = f\"https://api.metals.dev/v1/latest?api_key={os.environ['METAL_API_KEY']}&currency=USD&unit=toz\"\n",
        "        headers = CaseInsensitiveDict()\n",
        "        headers[\"Accept\"] = \"application/json\"\n",
        "        resp = requests.get(url, headers=headers)\n",
        "        print(resp)\n",
        "        metal_price = resp.json()[\"metals\"]\n",
        "        if metal_name not in metal_price:\n",
        "            raise KeyError(\n",
        "                f\"Metal '{metal_name}' not found. Available metals: {', '.join(metal_price['metals'].keys())}\"\n",
        "            )\n",
        "        return metal_price[metal_name]\n",
        "    except Exception as e:\n",
        "        raise Exception(f\"Error fetching metal price: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j85XikcLZQv4"
      },
      "source": [
        "### Binding the Tool to the LLM\n",
        "With the get_metal_price tool defined, the next step is to bind it to the ChatOpenAI model. This enables the agent to invoke the tool during its execution based on the user's requests allowing it to interact with external data and perform actions beyond its native capabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "lsxVT0lUZQv4"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "tools = [get_metal_price]\n",
        "llm = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
        "llm_with_tools = llm.bind_tools(tools)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuDuSrmQZQv4"
      },
      "source": [
        "In LangGraph, state plays a crucial role in tracking and updating information as the graph executes. As different parts of the graph run, the state evolves to reflect the changes and contains information that is passed between nodes.\n",
        "\n",
        "For example, in a conversational system like this one, the state is used to track the exchanged messages. Each time a new message is generated, it is added to the state and the updated state is passed through the nodes, ensuring the conversation progresses logically.\n",
        "\n",
        "### Defining the State\n",
        "To implement this in LangGraph, we define a state class that maintains a list of messages. Whenever a new message is produced it gets appended to this list, ensuring that the conversation history is continuously updated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "JHHXxYT1ZQv4"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import END\n",
        "from langchain_core.messages import AnyMessage\n",
        "from langgraph.graph.message import add_messages\n",
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "\n",
        "class GraphState(TypedDict):\n",
        "    messages: Annotated[list[AnyMessage], add_messages]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KGbjrAOZQv4"
      },
      "source": [
        "### Defining the should_continue Function\n",
        "The `should_continue` function determines whether the conversation should proceed with further tool interactions or end. Specifically, it checks if the last message contains any tool calls (e.g., a request for metal prices).\n",
        "\n",
        "- If the last message includes tool calls, indicating that the agent has invoked an external tool, the conversation continues and moves to the \"tools\" node.\n",
        "- If there are no tool calls, the conversation ends, represented by the END state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "KjppKPRDZQv4"
      },
      "outputs": [],
      "source": [
        "# Define the function that determines whether to continue or not\n",
        "def should_continue(state: GraphState):\n",
        "    messages = state[\"messages\"]\n",
        "    last_message = messages[-1]\n",
        "    if last_message.tool_calls:\n",
        "        return \"tools\"\n",
        "    return END"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbyJRNRvZQv4"
      },
      "source": [
        "### Calling the Model\n",
        "The `call_model` function interacts with the Language Model (LLM) to generate a response based on the current state of the conversation. It takes the updated state as input, processes it and returns a model-generated response."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ZYflc7eZZQv4"
      },
      "outputs": [],
      "source": [
        "# Define the function that calls the model\n",
        "def call_model(state: GraphState):\n",
        "    messages = state[\"messages\"]\n",
        "    response = llm_with_tools.invoke(messages)\n",
        "    return {\"messages\": [response]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzxIHVa2ZQv4"
      },
      "source": [
        "### Creating the Assistant Node\n",
        "The `assistant` node is a key component responsible for processing the current state of the conversation and using the Language Model (LLM) to generate a relevant response. It evaluates the state, determines the appropriate course of action, and invokes the LLM to produce a response that aligns with the ongoing dialogue."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_fPD6W2SZQv4"
      },
      "outputs": [],
      "source": [
        "# Node\n",
        "def assistant(state: GraphState):\n",
        "    response = llm_with_tools.invoke(state[\"messages\"])\n",
        "    return {\"messages\": [response]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vc3No3agZQv5"
      },
      "source": [
        "### Creating the Tool Node\n",
        "The `tool_node` is responsible for managing interactions with external tools, such as fetching metal prices or performing other actions beyond the LLM's native capabilities. The tools themselves are defined earlier in the code, and the tool_node invokes these tools based on the current state and the needs of the conversation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "vz2qlceBZQv5"
      },
      "outputs": [],
      "source": [
        "from langgraph.prebuilt import ToolNode\n",
        "\n",
        "# Node\n",
        "tools = [get_metal_price]\n",
        "tool_node = ToolNode(tools)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2FWZfGFZQv5"
      },
      "source": [
        "### Building the Graph\n",
        "The graph structure is the backbone of the agentic workflow, consisting of interconnected nodes and edges. To construct this graph, we use the StateGraph builder which allows us to define and connect various nodes. Each node represents a step in the process (e.g., the assistant node, tool node) and the edges dictate the flow of execution between these steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "FeGI8G3KZQv5",
        "outputId": "31692c4e-f5c8-477c-cdba-84a1cfd1ad81"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from langgraph.graph import START, StateGraph\n",
        "from IPython.display import Image, display\n",
        "\n",
        "# Define a new graph for the agent\n",
        "builder = StateGraph(GraphState)\n",
        "\n",
        "# Define the two nodes we will cycle between\n",
        "builder.add_node(\"assistant\", assistant)\n",
        "builder.add_node(\"tools\", tool_node)\n",
        "\n",
        "# Set the entrypoint as `agent`\n",
        "builder.add_edge(START, \"assistant\")\n",
        "\n",
        "# Making a conditional edge\n",
        "# should_continue will determine which node is called next.\n",
        "builder.add_conditional_edges(\"assistant\", should_continue, [\"tools\", END])\n",
        "\n",
        "# Making a normal edge from `tools` to `agent`.\n",
        "# The `agent` node will be called after the `tool`.\n",
        "builder.add_edge(\"tools\", \"assistant\")\n",
        "\n",
        "# Compile and display the graph for a visual overview\n",
        "react_graph = builder.compile()\n",
        "display(Image(react_graph.get_graph(xray=True).draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlNB4fI4ZQv5"
      },
      "source": [
        "To test our setup, we will run the agent with a query. The agent will fetch the price of copper using the metals.dev API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzt0I-n2ZQv5",
        "outputId": "b4a32beb-1717-462e-9b42-cc698dc5216c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<Response [200]>\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "messages = [HumanMessage(content=\"What is the price of silver?\")]\n",
        "result = react_graph.invoke({\"messages\": messages})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esoHsop8ZQv5",
        "outputId": "2889a5e0-7f82-4d19-8319-112ed655c484"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[HumanMessage(content='What is the price of silver?', additional_kwargs={}, response_metadata={}, id='5b87b283-3b8b-434a-b787-ccc44dabbb30'),\n",
              " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_aFRs6IphiGQtvrCfjADPWUzB', 'function': {'arguments': '{\"metal_name\":\"silver\"}', 'name': 'get_metal_price'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 116, 'total_tokens': 134, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_79b79be41f', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--a21a4b15-a0dd-431a-ad7a-30f39466728c-0', tool_calls=[{'name': 'get_metal_price', 'args': {'metal_name': 'silver'}, 'id': 'call_aFRs6IphiGQtvrCfjADPWUzB', 'type': 'tool_call'}], usage_metadata={'input_tokens': 116, 'output_tokens': 18, 'total_tokens': 134, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
              " ToolMessage(content='32.4865', name='get_metal_price', id='7b1a00d4-78ab-4fd4-897b-f896683bd2ef', tool_call_id='call_aFRs6IphiGQtvrCfjADPWUzB'),\n",
              " AIMessage(content='The current price of silver is approximately $32.49 per gram.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 147, 'total_tokens': 163, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_79b79be41f', 'finish_reason': 'stop', 'logprobs': None}, id='run--072f753a-008b-4965-96a4-65d94b92c66e-0', usage_metadata={'input_tokens': 147, 'output_tokens': 16, 'total_tokens': 163, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result[\"messages\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsK_VEDSZQv6"
      },
      "source": [
        "### Converting Messages to Ragas Evaluation Format\n",
        "\n",
        "In the current implementation, the GraphState stores messages exchanged between the human user, the AI (LLM's responses), and any external tools (APIs or services the AI uses) in a list. Each message is an object in LangChain's format\n",
        "\n",
        "```python\n",
        "# Implementation of Graph State\n",
        "class GraphState(TypedDict):\n",
        "    messages: Annotated[list[AnyMessage], add_messages]\n",
        "```\n",
        "\n",
        "Each time a message is exchanged during agent execution, it gets added to the messages list in the GraphState. However, Ragas requires a specific message format for evaluating interactions.\n",
        "\n",
        "Ragas uses its own format to evaluate agent interactions. So, if you're using LangGraph, you will need to convert the LangChain message objects into Ragas message objects. This allows you to evaluate your AI agents with Ragas’ built-in evaluation tools.\n",
        "\n",
        "**Goal:**  Convert the list of LangChain messages (e.g., HumanMessage, AIMessage, and ToolMessage) into the format expected by Ragas, so the evaluation framework can understand and process them properly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edpIDCgi6hkx"
      },
      "source": [
        "To convert a list of LangChain messages into a format suitable for Ragas evaluation, Ragas provides the function [convert_to_ragas_messages][ragas.integrations.langgraph.convert_to_ragas_messages], which can be used to transform LangChain messages into the format expected by Ragas.\n",
        "\n",
        "Here's how you can use the function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "oGX9bx286hkx"
      },
      "outputs": [],
      "source": [
        "from ragas.integrations.langgraph import convert_to_ragas_messages\n",
        "\n",
        "# Assuming 'result[\"messages\"]' contains the list of LangChain messages\n",
        "ragas_trace = convert_to_ragas_messages(result[\"messages\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Udcg7kCH6hkx",
        "outputId": "ac21080d-76de-4043-8604-40930aacac20"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[HumanMessage(content='What is the price of silver?', metadata=None, type='human'),\n",
              " AIMessage(content='', metadata=None, type='ai', tool_calls=[ToolCall(name='get_metal_price', args={'metal_name': 'silver'})]),\n",
              " ToolMessage(content='32.4865', metadata=None, type='tool'),\n",
              " AIMessage(content='The current price of silver is approximately $32.49 per gram.', metadata=None, type='ai', tool_calls=[])]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ragas_trace  # List of Ragas messages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Question: \n",
        "\n",
        "Describe in your own words what a \"trace\" is."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> A structured record of the full interaction between the user, the AI agent, and any tools used during the conversation—capturing every step the agent took to reach its final response.\n",
        "\n",
        "More specifically:\n",
        "\n",
        "* It is a **sequential list of messages**, typically including:\n",
        "\n",
        "  * `HumanMessage` – user queries\n",
        "  * `AIMessage` – LLM outputs (which may contain tool invocations)\n",
        "  * `ToolMessage` – responses from external tools\n",
        "* It reflects the **flow of reasoning**, **tool usage**, and **response generation**.\n",
        "* It’s essential input to Ragas, enabling accurate multi-turn evaluation of agent performance.\n",
        "\n",
        "In summary, a *trace* is like a conversation transcript enriched with tool calls and outputs, allowing you to evaluate what the agent *did*, *why*, and *how well* it met the user's goals."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5mbTp5aZQv6"
      },
      "source": [
        "## Evaluating the Agent's Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H885v5sxZQv6"
      },
      "source": [
        "For this tutorial, let us evaluate the Agent with the following metrics:\n",
        "\n",
        "- [Tool call Accuracy](https://docs.ragas.io/en/stable/concepts/metrics/available_metrics/agents/#tool-call-accuracy):ToolCallAccuracy is a metric that can be used to evaluate the performance of the LLM in identifying and calling the required tools to complete a given task.  \n",
        "\n",
        "- [Agent Goal accuracy](https://docs.ragas.io/en/stable/concepts/metrics/available_metrics/agents/#agent-goal-accuracy): Agent goal accuracy is a metric that can be used to evaluate the performance of the LLM in identifying and achieving the goals of the user. This is a binary metric, with 1 indicating that the AI has achieved the goal and 0 indicating that the AI has not achieved the goal.\n",
        "- [Topic Adherence](https://docs.ragas.io/en/stable/concepts/metrics/available_metrics/agents/): Topic adherence is a metric that can be used to ensure the Agent system is staying \"on-topic\", meaning that it's not straying from the intended use case. You can think of this as a kinda of faithfulness, where the responses of the LLM should stay faithful to the topic provided.\n",
        "\n",
        "\n",
        "First, let us actually run our Agent with a couple of queries, and make sure we have the ground truth labels for these queries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Question:\n",
        "\n",
        "Describe *how* each of the above metrics are calculated. This will require you to read the documentation for each metric."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**1. Tool Call Accuracy**\n",
        "\n",
        "**Purpose:**\n",
        "Evaluates whether the AI agent correctly identifies and invokes the appropriate tools with the correct arguments to fulfill a user's request.\n",
        "\n",
        "**Calculation:**\n",
        "\n",
        "* **Inputs Required:**\n",
        "\n",
        "  * `user_input`: The sequence of interactions between the user and the agent.\n",
        "  * `reference_tool_calls`: The expected tool calls that should be made to accomplish the task.\n",
        "\n",
        "* **Process:**\n",
        "\n",
        "  1. Compare the tool calls made by the agent during the interaction with the `reference_tool_calls`.\n",
        "  2. Assess both the correctness of the tool names and the accuracy of the arguments passed.\n",
        "\n",
        "* **Scoring:**\n",
        "\n",
        "  * The metric returns a score between 0 and 1.\n",
        "  * A score of 1 indicates that all tool calls were correctly identified and executed with the appropriate arguments.\n",
        "  * A score of 0 indicates that none of the tool calls matched the expected references.\n",
        "\n",
        "---\n",
        "\n",
        "**2. Agent Goal Accuracy**\n",
        "\n",
        "**Purpose:**\n",
        "Assesses whether the AI agent successfully achieves the user's intended goal during the interaction.\n",
        "\n",
        "**Calculation:**\n",
        "\n",
        "* **Inputs Required:**\n",
        "\n",
        "  * `user_input`: The sequence of interactions between the user and the agent.\n",
        "  * `reference`: A description or the expected outcome representing the user's goal.\n",
        "\n",
        "* **Process:**\n",
        "\n",
        "  1. The agent's final response is compared against the `reference` to determine if the user's goal was met.\n",
        "  2. This comparison can be done with or without a reference, but providing a reference allows for more precise evaluation.\n",
        "\n",
        "* **Scoring:**\n",
        "\n",
        "  * The metric returns a binary score:\n",
        "\n",
        "    * `1` if the agent's response successfully achieves the user's goal.\n",
        "    * `0` if it does not.\n",
        "\n",
        "---\n",
        "\n",
        "**3. Topic Adherence**\n",
        "\n",
        "**Purpose:**\n",
        "Evaluates whether the AI agent's responses remain within the predefined topics or domains during the interaction.\n",
        "\n",
        "**Calculation:**\n",
        "\n",
        "* **Inputs Required:**\n",
        "\n",
        "  * `user_input`: The sequence of interactions between the user and the agent.\n",
        "  * `reference_topics`: A list of topics that the agent is expected to adhere to.\n",
        "\n",
        "* **Process:**\n",
        "\n",
        "  1. Analyze each response from the agent to determine if it aligns with the `reference_topics`.\n",
        "  2. Classify responses as either adhering to the topic or deviating from it.\n",
        "\n",
        "* **Scoring:**\n",
        "\n",
        "  * The metric computes precision, recall, and F1 score:\n",
        "\n",
        "    * **Precision**: Proportion of on-topic responses among all responses.\n",
        "    * **Recall**: Proportion of on-topic responses among all expected on-topic interactions.\n",
        "    * **F1 Score**: Harmonic mean of precision and recall."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kRRIyTAZQv6"
      },
      "source": [
        "### Tool Call Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CC973Yq1ZQv6",
        "outputId": "8d18667e-a32c-4649-a9c9-49c734177b55"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from ragas.metrics import ToolCallAccuracy\n",
        "from ragas.dataset_schema import MultiTurnSample\n",
        "from ragas.integrations.langgraph import convert_to_ragas_messages\n",
        "import ragas.messages as r\n",
        "\n",
        "\n",
        "ragas_trace = convert_to_ragas_messages(\n",
        "    messages=result[\"messages\"]\n",
        ")  # List of Ragas messages converted using the Ragas function\n",
        "\n",
        "sample = MultiTurnSample(\n",
        "    user_input=ragas_trace,\n",
        "    reference_tool_calls=[\n",
        "        r.ToolCall(name=\"get_metal_price\", args={\"metal_name\": \"silver\"})\n",
        "    ],\n",
        ")\n",
        "\n",
        "tool_accuracy_scorer = ToolCallAccuracy()\n",
        "tool_accuracy_scorer.llm = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
        "await tool_accuracy_scorer.multi_turn_ascore(sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S14jlVw06hkx"
      },
      "source": [
        "Tool Call Accuracy: 1, because the LLM correctly identified and used the necessary tool (get_metal_price) with the correct parameters (i.e., metal name as \"silver\")."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGOL1CBsZQv6"
      },
      "source": [
        "### Agent Goal Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FA0kMvTfZQwB",
        "outputId": "1e2e4979-ef59-4af4-b395-b4bc846a16ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<Response [200]>\n"
          ]
        }
      ],
      "source": [
        "messages = [HumanMessage(content=\"What is the price of 10 grams of silver?\")]\n",
        "\n",
        "result = react_graph.invoke({\"messages\": messages})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJr4Hxn8ZQwB",
        "outputId": "0282a461-d379-40c4-b186-fe4242bad882"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[HumanMessage(content='What is the price of 10 grams of silver?', additional_kwargs={}, response_metadata={}, id='6772dd87-42f0-48b7-bd75-753e5be7c0cd'),\n",
              " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_hiWsZn55uCSU9IT7kteRNKzo', 'function': {'arguments': '{\"metal_name\":\"silver\"}', 'name': 'get_metal_price'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 120, 'total_tokens': 138, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_79b79be41f', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--52752fe2-3156-43d2-a158-79bfa0044b23-0', tool_calls=[{'name': 'get_metal_price', 'args': {'metal_name': 'silver'}, 'id': 'call_hiWsZn55uCSU9IT7kteRNKzo', 'type': 'tool_call'}], usage_metadata={'input_tokens': 120, 'output_tokens': 18, 'total_tokens': 138, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
              " ToolMessage(content='32.4865', name='get_metal_price', id='c6c38e4b-9685-4c12-90d3-ab8c59cb8e54', tool_call_id='call_hiWsZn55uCSU9IT7kteRNKzo'),\n",
              " AIMessage(content='The current price of silver is approximately $32.49 per gram. Therefore, the price of 10 grams of silver would be about $324.87.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 151, 'total_tokens': 185, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_79b79be41f', 'finish_reason': 'stop', 'logprobs': None}, id='run--bb4b6ca2-3027-46cc-92b2-0a4a832de711-0', usage_metadata={'input_tokens': 151, 'output_tokens': 34, 'total_tokens': 185, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result[\"messages\"]  # List of Langchain messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StDNqR2vZQwB",
        "outputId": "a92e93c6-ece8-4f72-a92d-d1e512175899"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[HumanMessage(content='What is the price of 10 grams of silver?', metadata=None, type='human'),\n",
              " AIMessage(content='', metadata=None, type='ai', tool_calls=[ToolCall(name='get_metal_price', args={'metal_name': 'silver'})]),\n",
              " ToolMessage(content='32.4865', metadata=None, type='tool'),\n",
              " AIMessage(content='The current price of silver is approximately $32.49 per gram. Therefore, the price of 10 grams of silver would be about $324.87.', metadata=None, type='ai', tool_calls=[])]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from ragas.integrations.langgraph import convert_to_ragas_messages\n",
        "\n",
        "ragas_trace = convert_to_ragas_messages(\n",
        "    result[\"messages\"]\n",
        ")  # List of Ragas messages converted using the Ragas function\n",
        "ragas_trace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6u9-RYdZQwB",
        "outputId": "76ffcaa7-676b-46f9-e931-dddfabee16c3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from ragas.dataset_schema import MultiTurnSample\n",
        "from ragas.metrics import AgentGoalAccuracyWithReference\n",
        "from ragas.llms import LangchainLLMWrapper\n",
        "\n",
        "\n",
        "sample = MultiTurnSample(\n",
        "    user_input=ragas_trace,\n",
        "    reference=\"Price of 10 grams of silver\",\n",
        ")\n",
        "\n",
        "scorer = AgentGoalAccuracyWithReference()\n",
        "\n",
        "evaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1-mini\"))\n",
        "scorer.llm = evaluator_llm\n",
        "await scorer.multi_turn_ascore(sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K71VkA7o6hk0"
      },
      "source": [
        "Agent Goal Accuracy: 1, because the LLM correctly achieved the user’s goal of retrieving the price of 10 grams of silver."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0fKvUqpDQVK"
      },
      "source": [
        "### Topic Adherence\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "4ouIaXBNDZgc"
      },
      "outputs": [],
      "source": [
        "messages = [HumanMessage(content=\"How fast can an eagle fly?\")]\n",
        "\n",
        "result = react_graph.invoke({\"messages\": messages})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBRGGNb4DyBa",
        "outputId": "b1de5ece-c17d-4ea1-bdfb-ba90da3ae343"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[HumanMessage(content='How fast can an eagle fly?', additional_kwargs={}, response_metadata={}, id='98f7f3c6-adff-4385-88eb-303cd9bb0816'),\n",
              " AIMessage(content='Eagles are known for their impressive flying abilities. Depending on the species, eagles can fly at speeds ranging from 30 to 50 miles per hour (48 to 80 kilometers per hour) during normal flight. When diving or hunting, some species, like the golden eagle, can reach speeds of up to 150 miles per hour (240 kilometers per hour). Would you like to know about a specific species of eagle?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 88, 'prompt_tokens': 116, 'total_tokens': 204, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_79b79be41f', 'finish_reason': 'stop', 'logprobs': None}, id='run--e39268e1-7415-4ad3-b973-ca521655a0aa-0', usage_metadata={'input_tokens': 116, 'output_tokens': 88, 'total_tokens': 204, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result[\"messages\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3i7NIgjD8ec",
        "outputId": "4aaa7855-2108-48d4-a872-9428b0981572"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[HumanMessage(content='How fast can an eagle fly?', metadata=None, type='human'),\n",
              " AIMessage(content='Eagles are known for their impressive flying abilities. Depending on the species, eagles can fly at speeds ranging from 30 to 50 miles per hour (48 to 80 kilometers per hour) during normal flight. When diving or hunting, some species, like the golden eagle, can reach speeds of up to 150 miles per hour (240 kilometers per hour). Would you like to know about a specific species of eagle?', metadata=None, type='ai', tool_calls=[])]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from ragas.integrations.langgraph import convert_to_ragas_messages\n",
        "\n",
        "ragas_trace = convert_to_ragas_messages(\n",
        "    result[\"messages\"]\n",
        ")  # List of Ragas messages converted using the Ragas function\n",
        "ragas_trace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLTMVPaMDzal",
        "outputId": "44fb96b3-0628-4c65-e87c-4e0a5a795047"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.float64(0.0)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from ragas.metrics import TopicAdherenceScore\n",
        "\n",
        "sample = MultiTurnSample(\n",
        "    user_input=ragas_trace,\n",
        "    reference_topics = [\"metals\"]\n",
        ")\n",
        "\n",
        "evaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1-mini\"))\n",
        "scorer = TopicAdherenceScore(llm = evaluator_llm, mode=\"precision\")\n",
        "await scorer.multi_turn_ascore(sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ac2I2MZJEcK5"
      },
      "source": [
        "As we can see, the current implementation fails due to talking about birds, when it should be talking about metal!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

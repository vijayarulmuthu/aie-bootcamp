{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLokDKoN1aKv"
      },
      "source": [
        "# Using Ragas to Evaluate a RAG Application built with LangChain and LangGraph\n",
        "\n",
        "In the following notebook, we'll be looking at how [Ragas](https://github.com/explodinggradients/ragas) can be helpful in a number of ways when looking to evaluate your RAG applications!\n",
        "\n",
        "While this example is rooted in LangChain/LangGraph - Ragas is framework agnostic (you don't even need to be using a framework!).\n",
        "\n",
        "- ü§ù Breakout Room #1\n",
        "  1. Task 1: Installing Required Libraries\n",
        "  2. Task 2: Set Environment Variables\n",
        "  3. Task 3: Synthetic Dataset Generation for Evaluation using Ragas\n",
        "  4. Task 4: Evaluating our Pipeline with Ragas\n",
        "  5. Task 6: Making Adjustments and Re-Evaluating\n",
        "\n",
        "But first! Let's set some dependencies!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0k9tqHdq2BGi"
      },
      "source": [
        "## Dependencies and API Keys:\n",
        "\n",
        "> NOTE: Please skip the pip install commands if you are running the notebook locally."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njvrpsHWifeS",
        "outputId": "df62835e-ad3b-446c-9c83-d9b8330bafa5"
      },
      "outputs": [],
      "source": [
        "#!pip install -qU ragas==0.2.10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DjesmARj2I4A"
      },
      "outputs": [],
      "source": [
        "#!pip install -qU langchain-community==0.3.14 langchain-openai==0.2.14 unstructured==0.16.12 langgraph==0.2.61 langchain-qdrant==0.2.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3d5seTX2xyx"
      },
      "source": [
        "We'll also need to provide our API keys.\n",
        "\n",
        "First, OpenAI's for our LLM/embedding model combination!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_J02wP3gdLds",
        "outputId": "7e122a12-e645-4108-e710-1d3cbb904f8d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass(\"Please enter your OpenAI API key!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zTz1-4U3Hg0"
      },
      "source": [
        "## Generating Synthetic Test Data\n",
        "\n",
        "We wil be using Ragas to build out a set of synthetic test questions, references, and reference contexts. This is useful because it will allow us to find out how our system is performing.\n",
        "\n",
        "> NOTE: Ragas is best suited for finding *directional* changes in your LLM-based systems. The absolute scores aren't comparable in a vacuum."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pssK40Eh4MIc"
      },
      "source": [
        "### Data Preparation\n",
        "\n",
        "We'll prepare our data - and download our webpages which we'll be using for our data today.\n",
        "\n",
        "These webpages are from [Simon Willison's](https://simonwillison.net/) yearly \"AI learnings\".\n",
        "\n",
        "- [2023 Blog](https://simonwillison.net/2023/Dec/31/ai-in-2023/)\n",
        "- [2024 Blog](https://simonwillison.net/2024/Dec/31/llms-in-2024/)\n",
        "\n",
        "Let's start by collecting our data into a useful pile!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "12cpcowvhW3O"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: data: File exists\n"
          ]
        }
      ],
      "source": [
        "!mkdir data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAHtGwnsfiA5",
        "outputId": "60ed4a56-f558-4a7d-9b8f-7cb18c28cc06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 31554    0 31554    0     0  62590      0 --:--:-- --:--:-- --:--:-- 62607\n"
          ]
        }
      ],
      "source": [
        "!curl https://simonwillison.net/2023/Dec/31/ai-in-2023/ -o data/2023_llms.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEs60mX1hB_a",
        "outputId": "fa9a5bd0-32c0-4d32-d1f1-c4e8ee7905bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 70721    0 70721    0     0   413k      0 --:--:-- --:--:-- --:--:--  411k\n"
          ]
        }
      ],
      "source": [
        "!curl https://simonwillison.net/2024/Dec/31/llms-in-2024/ -o data/2024_llms.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfKQgiR14Omj"
      },
      "source": [
        "Next, let's load our data into a familiar LangChain format using the `DirectoryLoader`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "dTYMPlsTiDRe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
            "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.document_loaders import DirectoryLoader\n",
        "\n",
        "path = \"data/\"\n",
        "loader = DirectoryLoader(path, glob=\"*.html\")\n",
        "docs = loader.load()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfyA65MM4Tbn"
      },
      "source": [
        "### Knowledge Graph Based Synthetic Generation\n",
        "\n",
        "Ragas uses a knowledge graph based approach to create data. This is extremely useful as it allows us to create complex queries rather simply. The additional testset complexity allows us to evaluate larger problems more effectively, as systems tend to be very strong on simple evaluation tasks.\n",
        "\n",
        "Let's start by defining our `generator_llm` (which will generate our questions, summaries, and more), and our `generator_embeddings` which will be useful in building our graph."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbZ9j1EL-X55"
      },
      "source": [
        "### Abstracted SDG\n",
        "\n",
        "The above method is the full process - but we can shortcut that using the provided abstractions!\n",
        "\n",
        "This will generate our knowledge graph under the hood, and will - from there - generate our personas and scenarios to construct our queries.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ragas.llms import LangchainLLMWrapper\n",
        "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1\"))\n",
        "generator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "bf73dc001ec14333975be942dc78df31",
            "ea51201a73a045de8579dafb17d70bec",
            "a5e6260095bf4ca6bce229adfe9c3fbe",
            "0e460f92c5a749efb198864545a124c0",
            "4347f5ea75c74effbc9552cb69c82301",
            "8f986d822b964e969ad20d1b1088dec9",
            "c40abe6ce691401ea8db2562b3b322fb",
            "cb12c0b6145b48908ca058e0a7282828",
            "0107beec40af42ffa66b216070f97d5c",
            "245c32a588d142628f06eba44324c1b8",
            "f9499b2235294b638ed87d73894b341f",
            "a74c472ad4ff49d49dd6648ce89f5471",
            "b12c215bb97e49fea6129d7ca7cdcc6b",
            "f37518d278b34353a38bcc50f8743959",
            "2d888020728341a6ad146908634a6a2f",
            "1ea4551d38bc4e3ea2a99eb62e6bf942",
            "da4d36932dad4270a94b003affc28333",
            "675034bd626b4c528eb77e35e4087191",
            "7a84047d2b724edd891ca63b5741a43b",
            "5bec2586cfcb4ddabf9f2378b32fa4dc",
            "5e5fe22186e742e6bd1142a0d8471656",
            "79fce08fefc948d0bec02db61a6ab21b",
            "2c9e188608204caa9c6a449843084ceb",
            "8299304353ff46b597fdadeacddabdf5",
            "fc33ba2055c149a4a85ac6f586de47ee",
            "8e87eb2bff19452ab778993dbc1a2586",
            "be4c08a6cdb54d23a32b283379fdea8e",
            "f5a56214fe25441e8a5004ec76476a94",
            "3230d232b04448fe9a68a204b46bc91c",
            "fd11e4046c464b7285ddd7a7b7cd51c8",
            "e0e92282b50048c4a25414273f1777ff",
            "8be24cac973b4db7a85ab46581c1efb7",
            "cbe80c1e537a413ebe0f5a98038148d6",
            "472c776f27834cd8907902679ff93c24",
            "19160948d9af4cd5bfe1a8a97727fb49",
            "d528743f9a0047778a7f808214fdf49c",
            "a37137bd3fad4362bef3817ae7ad2ad9",
            "da926343593245d9b34f8a77183c4115",
            "c4470c9d055c4b8793dda8dfc7496b83",
            "4183285878f347f1b8caae9dce6ec0fd",
            "37831f1641db461e93e5011d343b5cb2",
            "f69d31545a1045d4959e0640abe3409a",
            "74ac36e0ca6c4a3ba53d070b37b9f1aa",
            "ba53eab6f7e441569d2a16aa8f26511d",
            "a604a0b844a94570be523a881c8455ba",
            "594a9d371fb4406e97630f35712d276c",
            "d52c4da39f564a12ba46044e0797eb95",
            "25baeb72f87d4e5ba0e8c10bcf3afd58",
            "96b1fb2a1577445d9778ad65da0abdbb",
            "f7bf032ee32c46628a3a28ff2cedcc10",
            "810264507cae4987b88531845ca03921",
            "d6395d76874241cf87b37390a6c58424",
            "35e71aea98cc41b7a090071a9d8ccde7",
            "3b72baad55d34b77b5c56588c00280b9",
            "16a0c539ddb040d7b32047894480a348",
            "5cea5f1121f64866b6932ac6bb0a8829",
            "03e6ff4dc0d645668324964cbf114211",
            "c1b6cdf48bae4226a374ffbabb861ecc",
            "ec44f75ea457496c9443b881bc156146",
            "d64c39da94b148d4989fe271521dc967",
            "7803a3e67b28452390202dc69d4289f3",
            "618a24e305d44bd39a3023aa44f3383c",
            "d9f54cd68cd8493fb1bc2a216eb15c03",
            "4592465145b44c17a9acb5fcab9b2e8b",
            "8b77a827824440d6b53f4a14346c0d70",
            "20848c82096c458fb118006897a0b7e0",
            "521c3b51f249490986addd4010423064",
            "bda6a62b9fd143a3b0628e60580d23c9",
            "970b83c42f4f4d7ebb252c4f26f6ea56",
            "d1e5f706d17b4c27b0ce1cb127fdc891",
            "7d5ccb84254b461da11bd8045424bc30",
            "fd71a316693343cc9a92fae9471a2f6e",
            "35e6cd723807485f81eb053c2c92b96c",
            "837e33bad8be4a6d8722ca878b9d409e",
            "559b618c027e4f12bfe58286b208c9b4",
            "5d5df07e34d545ed9b2975034645c453",
            "319b66f299064965b91ce4282dc9c280",
            "b38eb659d045417cb0e05a4486a83590",
            "7cfc3038a06249819e2496f7e0571b89",
            "01fa9def167548fba96e573921712950",
            "7288a537b3034e499797d2c3294f8383",
            "f3c9086c454841f6914e299a11f7d217",
            "ec3472c7d29b4ad0ab91e3c2f6874bd5",
            "2b4f209c6c3c46abaa0d5a83cb10ae38",
            "3c470306f04542f29c53dd21a4de93d7",
            "7c0ead4589784ecb8d5380a895fe1c41",
            "8723f89faf044f97b5abfa3666404497",
            "7c8f4bf420754b538baea7a420b6a76a",
            "d390d71dd2694801a77b103a6a707da3",
            "11d272eb6b7146659e5c688ec04c8749",
            "68599f8e85ef4fcba92ea891f75b5535",
            "d1b550cbeaef43a7a98ffbba97fb37ee",
            "d08cba8d32514ca2bb1e0d403ceadd7e",
            "ba29aad6b8d74a09ad347ce8648deeab",
            "96426fde6b9542208f45409965d0216c",
            "bba06b49269840ea8247ecc85552050b",
            "9e0794e92f9646ab8aa21f0ec0ed7981",
            "f10fe2d8ed6e45b595e66db0a3f972a1",
            "fe1cfe8194c142fdb11a4dd28e1adb00"
          ]
        },
        "id": "ZvXsRbwIlfm1",
        "outputId": "4579c020-3af6-4355-aecc-b9529b8eda12"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "365cad4c1efc4c46a5919b8cfb7c58c4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying HeadlinesExtractor:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d4279a0690294fe09f0fad40b02c5fe8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying HeadlineSplitter:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ab0532f2ec6b4ce4a15ea4decd9f93f1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying SummaryExtractor:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e27d87042000428283b7303577e7863e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying CustomNodeFilter:   0%|          | 0/12 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2bed37b7eee241fd8104acc961f70fb5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/26 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cfef505219154708bcb193987f81ebbd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying [CosineSimilarityBuilder, OverlapScoreBuilder]:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1cea0b2812b64715a4be56e91a13d27c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating personas:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c520a69d66d948149f0a6c043242eeec",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Scenarios:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e7d4c5591ffc45af9099a98710c1eddf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating Samples:   0%|          | 0/12 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from ragas.testset import TestsetGenerator\n",
        "\n",
        "generator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings)\n",
        "dataset = generator.generate_with_langchain_docs(docs, testset_size=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1jsrtjNllwiI",
        "outputId": "a96af811-7f54-49e9-adbb-9155948ff203"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "user_input",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "reference_contexts",
                  "rawType": "object",
                  "type": "unknown"
                },
                {
                  "name": "reference",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "synthesizer_name",
                  "rawType": "object",
                  "type": "string"
                }
              ],
              "conversionMethod": "pd.DataFrame",
              "ref": "5728ed8a-57ee-45e8-a003-34e3c1322c02",
              "rows": [
                [
                  "0",
                  "Which organizations, including Stability AI, have produced better-than-GPT-3 class large language models?",
                  "['We don‚Äôt yet know how to build GPT-4 Vibes Based Development LLMs are really smart, and also really, really dumb Gullibility is the biggest unsolved problem Code may be the best application The ethics of this space remain diabolically complex My blog in 2023 Here‚Äôs the sequel to this post: Things we learned about LLMs in 2024. Large Language Models In the past 24-36 months, our species has discovered that you can take a GIANT corpus of text, run it through a pile of GPUs, and use it to create a fascinating new kind of software. LLMs can do a lot of things. They can answer questions, summarize documents, translate from one language to another, extract information and even write surprisingly competent code. They can also help you cheat at your homework, generate unlimited streams of fake content and be used for all manner of nefarious purposes. So far, I think they‚Äôre a net positive. I‚Äôve used them on a personal level to improve my productivity (and entertain myself) in all sorts of different ways. I think people who learn how to use them effectively can gain a significant boost to their quality of life. A lot of people are yet to be sold on their value! Some think their negatives outweigh their positives, some think they are all hot air, and some even think they represent an existential threat to humanity. They‚Äôre actually quite easy to build The most surprising thing we‚Äôve learned about LLMs this year is that they‚Äôre actually quite easy to build. Intuitively, one would expect that systems this powerful would take millions of lines of complex code. Instead, it turns out a few hundred lines of Python is genuinely enough to train a basic version! What matters most is the training data. You need a lot of data to make these things work, and the quantity and quality of the training data appears to be the most important factor in how good the resulting model is. If you can gather the right data, and afford to pay for the GPUs to train it, you can build an LLM. A year ago, the only organization that had released a generally useful LLM was OpenAI. We‚Äôve now seen better-than-GPT-3 class models produced by Anthropic, Mistral, Google, Meta, EleutherAI, Stability AI, TII in Abu Dhabi (Falcon), Microsoft Research, xAI, Replit, Baidu and a bunch of other organizations. The training cost (hardware and electricity) is still significant‚Äîinitially millions of dollars, but that seems to have dropped to the tens of thousands already. Microsoft‚Äôs Phi-2 claims to have used ‚Äú14 days on 96 A100 GPUs‚Äù, which works out at around $35,000 using current Lambda pricing. So training an LLM still isn‚Äôt something a hobbyist can afford, but it‚Äôs no longer the sole domain of the super-rich. I like to compare the difficulty of training an LLM to that of building a suspension bridge‚Äînot trivial, but hundreds of countries around the world have figured out how to do it. (Correction: Wikipedia‚Äôs Suspension bridges by country category lists 44 countries). You can run LLMs on your own devices In January of this year, I thought it would be years before I could run a useful LLM on my own computer. GPT-3 and 3.5 were pretty much the only games in town, and I thought that even if the model weights were available it would take a $10,000+ server to run them. Then in February, Meta released Llama. And a few weeks later in March, Georgi Gerganov released code that got it working on a MacBook. I wrote about how Large language models are having their Stable Diffusion moment, and with hindsight that was a very good call! This unleashed a whirlwind of innovation, which was accelerated further in July when Meta released Llama 2‚Äîan improved version which, crucially, included permission for commercial use. Today there are literally thousands of LLMs that can be run locally, on all manner of different devices. I run a bunch of them on my laptop. I run Mistral 7B (a surprisingly great model) on my iPhone. You can install several different apps to get your own, local, completely private LLM. My own LLM project provides a CLI tool for running an array of different models via plugins. You can even run them entirely in your browser using WebAssembly and the latest Chrome! Hobbyists can build their own fine-tuned models I said earlier that building an LLM was still out of reach of hobbyists. That may be true for training from scratch, but fine-tuning one of those models is another matter entirely. There‚Äôs now a fascinating ecosystem of people training their own models on top of these foundations, publishing those models, building fine-tuning datasets and sharing those too. The Hugging Face Open LLM Leaderboard is one place that tracks these. I can‚Äôt even attempt to count them, and any count would be out-of-date within a few hours. The best overall openly licensed LLM at any time is rarely a foundation model: instead, it‚Äôs whichever fine-tuned community model has most recently discovered the best combination of fine-tuning data. This is a huge advantage for open over closed models: the closed, hosted models don‚Äôt have thousands of researchers and hobbyists around the world collaborating and competing to improve them. We don‚Äôt yet know how to build GPT-4 Frustratingly, despite the enormous leaps ahead we‚Äôve had this year, we are yet to see an alternative model that‚Äôs better than GPT-4. OpenAI released GPT-4 in March, though it later turned out we had a sneak peak of it in February when Microsoft used it as part of the new Bing. This may well change in the next few weeks: Google‚Äôs Gemini Ultra has big claims, but isn‚Äôt yet available for us to try out. The team behind Mistral are working to beat GPT-4 as well, and their track record is already extremely strong considering their first public model only came out in September, and they‚Äôve released two significant improvements since then. Still,']",
                  "Organizations that have produced better-than-GPT-3 class large language models include Anthropic, Mistral, Google, Meta, EleutherAI, Stability AI, TII in Abu Dhabi (Falcon), Microsoft Research, xAI, Replit, and Baidu.",
                  "single_hop_specifc_query_synthesizer"
                ],
                [
                  "1",
                  "How does the use of Python by large language models (LLMs) impact their code generation capabilities, and what are the implications for evaluating LLM performance in coding tasks?",
                  "['I‚Äôm surprised that no-one has beaten the now almost year old GPT-4 by now. OpenAI clearly have some substantial tricks that they haven‚Äôt shared yet. Vibes Based Development As a computer scientist and software engineer, LLMs are infuriating. Even the openly licensed ones are still the world‚Äôs most convoluted black boxes. We continue to have very little idea what they can do, how exactly they work and how best to control them. I‚Äôm used to programming where the computer does exactly what I tell it to do. Prompting an LLM is decidedly not that! The worst part is the challenge of evaluating them. There are plenty of benchmarks, but no benchmark is going to tell you if an LLM actually ‚Äúfeels‚Äù right when you try it for a given task. I find I have to work with an LLM for a few weeks in order to get a good intuition for it‚Äôs strengths and weaknesses. This greatly limits how many I can evaluate myself! The most frustrating thing for me is at the level of individual prompting. Sometimes I‚Äôll tweak a prompt and capitalize some of the words in it, to emphasize that I really want it to OUTPUT VALID MARKDOWN or similar. Did capitalizing those words make a difference? I still don‚Äôt have a good methodology for figuring that out. We‚Äôre left with what‚Äôs effectively Vibes Based Development. It‚Äôs vibes all the way down. I‚Äôd love to see us move beyond vibes in 2024! LLMs are really smart, and also really, really dumb On the one hand, we keep on finding new things that LLMs can do that we didn‚Äôt expect‚Äîand that the people who trained the models didn‚Äôt expect either. That‚Äôs usually really fun! But on the other hand, the things you sometimes have to do to get the models to behave are often incredibly dumb. Does ChatGPT get lazy in December, because its hidden system prompt includes the current date and its training data shows that people provide less useful answers coming up to the holidays? The honest answer is ‚Äúmaybe‚Äù! No-one is entirely sure, but if you give it a different date its answers may skew slightly longer. Sometimes it omits sections of code and leaves you to fill them in, but if you tell it you can‚Äôt type because you don‚Äôt have any fingers it produces the full code for you instead. There are so many more examples like this. Offer it cash tips for better answers. Tell it your career depends on it. Give it positive reinforcement. It‚Äôs all so dumb, but it works! Gullibility is the biggest unsolved problem I coined the term prompt injection in September last year. 15 months later, I regret to say that we‚Äôre still no closer to a robust, dependable solution to this problem. I‚Äôve written a ton about this already. Beyond that specific class of security vulnerabilities, I‚Äôve started seeing this as a wider problem of gullibility. Language Models are gullible. They ‚Äúbelieve‚Äù what we tell them‚Äîwhat‚Äôs in their training data, then what‚Äôs in the fine-tuning data, then what‚Äôs in the prompt. In order to be useful tools for us, we need them to believe what we feed them! But it turns out a lot of the things we want to build need them not to be gullible. Everyone wants an AI personal assistant. If you hired a real-world personal assistant who believed everything that anyone told them, you would quickly find that their ability to positively impact your life was severely limited. A lot of people are excited about AI agents‚Äîan infuriatingly vague term that seems to be converging on ‚ÄúAI systems that can go away and act on your behalf‚Äù. We‚Äôve been talking about them all year, but I‚Äôve seen few if any examples of them running in production, despite lots of exciting prototypes. I think this is because of gullibility. Can we solve this? Honestly, I‚Äôm beginning to suspect that you can‚Äôt fully solve gullibility without achieving AGI. So it may be quite a while before those agent dreams can really start to come true! Code may be the best application Over the course of the year, it‚Äôs become increasingly clear that writing code is one of the things LLMs are most capable of. If you think about what they do, this isn‚Äôt such a big surprise. The grammar rules of programming languages like Python and JavaScript are massively less complicated than the grammar of Chinese, Spanish or English. It‚Äôs still astonishing to me how effective they are though. One of the great weaknesses of LLMs is their tendency to hallucinate‚Äîto imagine things that don‚Äôt correspond to reality. You would expect this to be a particularly bad problem for code‚Äîif an LLM hallucinates a method that doesn‚Äôt exist, the code should be useless. Except... you can run generated code to see if it‚Äôs correct. And with patterns like ChatGPT Code Interpreter the LLM can execute the code itself, process the error message, then rewrite it and keep trying until it works! So hallucination is a much lesser problem for code generation than for anything else. If only we had the equivalent of Code Interpreter for fact-checking natural language! How should we feel about this as software engineers? On the one hand, this feels like a threat: who needs a programmer if ChatGPT can write code for you? On the other hand, as software engineers we are better placed to take advantage of this than anyone else. We‚Äôve all been given weird coding interns‚Äîwe can use our deep knowledge to prompt them to solve coding problems more effectively than anyone else can. The ethics of this space remain diabolically complex In September last year Andy Baio and I produced the first major story on the unlicensed training data behind Stable Diffusion. Since then, almost every major LLM (and most of the image generation models) have also been trained on unlicensed data. Just this week, the New York Times launched a landmark lawsuit against OpenAI and']",
                  "According to the context, writing code is one of the things LLMs are most capable of, and this is partly because the grammar rules of programming languages like Python are massively less complicated than those of natural languages such as Chinese, Spanish, or English. This makes it less surprising that LLMs are effective at generating code in Python. Although LLMs have a tendency to hallucinate, this issue is less problematic for code generation because generated code can be run to check its correctness. Additionally, tools like ChatGPT Code Interpreter allow the LLM to execute Python code, process error messages, and iteratively rewrite the code until it works. This means that hallucination is a much lesser problem for code generation than for other tasks. However, evaluating LLM performance in coding tasks remains challenging, as benchmarks may not fully capture whether an LLM 'feels' right for a given task, and developing a good methodology for prompt engineering and evaluation is still an open problem.",
                  "single_hop_specifc_query_synthesizer"
                ],
                [
                  "2",
                  "Wut is AI?",
                  "['Simon Willison‚Äôs Weblog Subscribe Stuff we figured out about AI in 2023 31st December 2023 2023 was the breakthrough year for Large Language Models (LLMs). I think it‚Äôs OK to call these AI‚Äîthey‚Äôre the latest and (currently) most interesting development in the academic field of Artificial Intelligence that dates back to the 1950s. Here‚Äôs my attempt to round up the highlights in one place! Large Language Models They‚Äôre actually quite easy to build You can run LLMs on your own devices Hobbyists can build their own fine-tuned models']",
                  "AI refers to Large Language Models, which are the latest and most interesting development in the academic field of Artificial Intelligence.",
                  "single_hop_specifc_query_synthesizer"
                ],
                [
                  "3",
                  "Whaat is the signifficance of OpenAI in the context of LLMs and AI discusionns acccording to the blog's 2023 tag cloud and traffic data?",
                  "['Microsoft over this issue. The 69 page PDF is genuinely worth reading‚Äîespecially the first few pages, which lay out the issues in a way that‚Äôs surprisingly easy to follow. The rest of the document includes some of the clearest explanations of what LLMs are, how they work and how they are built that I‚Äôve read anywhere. The legal arguments here are complex. I‚Äôm not a lawyer, but I don‚Äôt think this one will be easily decided. Whichever way it goes, I expect this case to have a profound impact on how this technology develops in the future. Law is not ethics. Is it OK to train models on people‚Äôs content without their permission, when those models will then be used in ways that compete with those people? As the quality of results produced by AI models has increased over the year, these questions have become even more pressing. The impact on human society in terms of these models is already huge, if difficult to objectively measure. People have certainly lost work to them‚Äîanecdotally, I‚Äôve seen this for copywriters, artists and translators. There are a great deal of untold stories here. I‚Äôm hoping 2024 sees significant amounts of dedicated journalism on this topic. My blog in 2023 Here‚Äôs a tag cloud for content I posted to my blog in 2023 (generated using Django SQL Dashboard): Tag cloud words in order of size: ai, generativeai, llms, openai, chatgpt, projects, python, datasette, ethics, llama, homebrewllms, sqlite, gpt3, promptengineering, promptinjection, llm, security, opensource, gpt4, weeknotes The top five: ai (342), generativeai (300), llms (287), openai (86), chatgpt (78). I‚Äôve written a lot about this stuff! I grabbed a screenshot of my Plausible analytics for the year, fed that to ChatGPT Vision, told it to extract the data into a table, then got it to mix in entry titles (from a SQL query it wrote) and produced this table with it. Here are my top entries this year by amount of traffic: Article Visitors Pageviews Bing: ‚ÄúI will not harm you unless you harm me first‚Äù 1.1M 1.3M Leaked Google document: ‚ÄúWe Have No Moat, And Neither Does OpenAI‚Äù 132k 162k Large language models are having their Stable Diffusion moment 121k 150k Prompt injection: What‚Äôs the worst that can happen? 79.8k 95.9k Embeddings: What they are and why they matter 61.7k 79.3k Catching up on the weird world of LLMs 61.6k 85.9k llamafile is the new best way to run an LLM on your own computer 52k 66k Prompt injection explained, with video, slides, and a transcript 51k 61.9k AI-enhanced development makes me more ambitious with my projects 49.6k 60.1k Understanding GPT tokenizers 49.5k 61.1k Exploring GPTs: ChatGPT in a trench coat? 46.4k 58.5k Could you train a ChatGPT-beating model for $85,000 and run it in a browser? 40.5k 49.2k How to implement Q&A against your documentation with GPT3, embeddings and Datasette 37.3k 44.9k Lawyer cites fake cases invented by ChatGPT, judge is not amused 37.1k 47.4k Now add a walrus: Prompt engineering in DALL-E 3 32.8k 41.2k Web LLM runs the vicuna-7b Large Language Model entirely in your browser, and it‚Äôs very impressive 32.5k 38.2k ChatGPT can‚Äôt access the internet, even though it really looks like it can 30.5k 34.2k Stanford Alpaca, and the acceleration of on-device large language model development 29.7k 35.7k Run Llama 2 on your own Mac using LLM and Homebrew 27.9k 33.6k Midjourney 5.1 26.7k 33.4k Think of language models like ChatGPT as a ‚Äúcalculator for words‚Äù 25k 31.8k Multi-modal prompt injection image attacks against GPT-4V 23.7k 27.4k I also gave a bunch of talks and podcast appearances. I‚Äôve started habitually turning my talks into annotated presentations‚Äîhere are my best from 2023: Prompt injection explained, with video, slides, and a transcript Catching up on the weird world of LLMs Making Large Language Models work for you Open questions for AI engineering Embeddings: What they are and why they matter Financial sustainability for open source projects at GitHub Universe And in podcasts: What AI can do for you on the Theory of Change Working in public on Path to Citus Con LLMs break the internet on the Changelog Talking Large Language Models on Rooftop Ruby Thoughts on the OpenAI board situation on Newsroom Robots Industry‚Äôs Tardy Response to the AI Prompt Injection Vulnerability on RedMonk Conversations Posted 31st December 2023 at 11:59 pm ¬∑ Follow me on Mastodon, Bluesky, Twitter or subscribe to my newsletter More recent articles Feed a video to a vision LLM as a sequence of JPEG frames on the CLI (also LLM 0.25) - 5th May 2025 Two publishers and three authors fail to understand what \"vibe coding\" means - 1st May 2025 Understanding the recent criticism of the Chatbot Arena - 30th April 2025 This is Stuff we figured out about AI in 2023 by Simon Willison, posted on 31st December 2023. Part of series LLMs annual review Stuff we figured out about AI in 2023 - Dec. 31, 2023, 11:59 p.m. Things we learned about LLMs in 2024 - Dec. 31, 2024, 6:07 p.m. blogging 105 ai 1262 generative-ai 1089 llms 1076 Next: Tom Scott, and the formidable power of escalating streaks Previous: Last weeknotes of 2023 Colophon ¬© 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 2025']",
                  "According to the blog's 2023 tag cloud, 'openai' was one of the top five most used tags, with 86 mentions, indicating its prominence in discussions about LLMs and AI. Additionally, one of the top traffic articles was titled 'Leaked Google document: ‚ÄúWe Have No Moat, And Neither Does OpenAI‚Äù', which received 132k visitors and 162k pageviews, further highlighting OpenAI's significant role in the AI and LLM conversation on the blog.",
                  "single_hop_specifc_query_synthesizer"
                ],
                [
                  "4",
                  "Considering the applications of LLMs such as code generation and productivity enhancement, how has the rise of LLMs impacted software engineering and programming roles, particularly in terms of both opportunities and perceived threats, as discussed in the context?",
                  "['<1-hop>\\n\\nWe don‚Äôt yet know how to build GPT-4 Vibes Based Development LLMs are really smart, and also really, really dumb Gullibility is the biggest unsolved problem Code may be the best application The ethics of this space remain diabolically complex My blog in 2023 Here‚Äôs the sequel to this post: Things we learned about LLMs in 2024. Large Language Models In the past 24-36 months, our species has discovered that you can take a GIANT corpus of text, run it through a pile of GPUs, and use it to create a fascinating new kind of software. LLMs can do a lot of things. They can answer questions, summarize documents, translate from one language to another, extract information and even write surprisingly competent code. They can also help you cheat at your homework, generate unlimited streams of fake content and be used for all manner of nefarious purposes. So far, I think they‚Äôre a net positive. I‚Äôve used them on a personal level to improve my productivity (and entertain myself) in all sorts of different ways. I think people who learn how to use them effectively can gain a significant boost to their quality of life. A lot of people are yet to be sold on their value! Some think their negatives outweigh their positives, some think they are all hot air, and some even think they represent an existential threat to humanity. They‚Äôre actually quite easy to build The most surprising thing we‚Äôve learned about LLMs this year is that they‚Äôre actually quite easy to build. Intuitively, one would expect that systems this powerful would take millions of lines of complex code. Instead, it turns out a few hundred lines of Python is genuinely enough to train a basic version! What matters most is the training data. You need a lot of data to make these things work, and the quantity and quality of the training data appears to be the most important factor in how good the resulting model is. If you can gather the right data, and afford to pay for the GPUs to train it, you can build an LLM. A year ago, the only organization that had released a generally useful LLM was OpenAI. We‚Äôve now seen better-than-GPT-3 class models produced by Anthropic, Mistral, Google, Meta, EleutherAI, Stability AI, TII in Abu Dhabi (Falcon), Microsoft Research, xAI, Replit, Baidu and a bunch of other organizations. The training cost (hardware and electricity) is still significant‚Äîinitially millions of dollars, but that seems to have dropped to the tens of thousands already. Microsoft‚Äôs Phi-2 claims to have used ‚Äú14 days on 96 A100 GPUs‚Äù, which works out at around $35,000 using current Lambda pricing. So training an LLM still isn‚Äôt something a hobbyist can afford, but it‚Äôs no longer the sole domain of the super-rich. I like to compare the difficulty of training an LLM to that of building a suspension bridge‚Äînot trivial, but hundreds of countries around the world have figured out how to do it. (Correction: Wikipedia‚Äôs Suspension bridges by country category lists 44 countries). You can run LLMs on your own devices In January of this year, I thought it would be years before I could run a useful LLM on my own computer. GPT-3 and 3.5 were pretty much the only games in town, and I thought that even if the model weights were available it would take a $10,000+ server to run them. Then in February, Meta released Llama. And a few weeks later in March, Georgi Gerganov released code that got it working on a MacBook. I wrote about how Large language models are having their Stable Diffusion moment, and with hindsight that was a very good call! This unleashed a whirlwind of innovation, which was accelerated further in July when Meta released Llama 2‚Äîan improved version which, crucially, included permission for commercial use. Today there are literally thousands of LLMs that can be run locally, on all manner of different devices. I run a bunch of them on my laptop. I run Mistral 7B (a surprisingly great model) on my iPhone. You can install several different apps to get your own, local, completely private LLM. My own LLM project provides a CLI tool for running an array of different models via plugins. You can even run them entirely in your browser using WebAssembly and the latest Chrome! Hobbyists can build their own fine-tuned models I said earlier that building an LLM was still out of reach of hobbyists. That may be true for training from scratch, but fine-tuning one of those models is another matter entirely. There‚Äôs now a fascinating ecosystem of people training their own models on top of these foundations, publishing those models, building fine-tuning datasets and sharing those too. The Hugging Face Open LLM Leaderboard is one place that tracks these. I can‚Äôt even attempt to count them, and any count would be out-of-date within a few hours. The best overall openly licensed LLM at any time is rarely a foundation model: instead, it‚Äôs whichever fine-tuned community model has most recently discovered the best combination of fine-tuning data. This is a huge advantage for open over closed models: the closed, hosted models don‚Äôt have thousands of researchers and hobbyists around the world collaborating and competing to improve them. We don‚Äôt yet know how to build GPT-4 Frustratingly, despite the enormous leaps ahead we‚Äôve had this year, we are yet to see an alternative model that‚Äôs better than GPT-4. OpenAI released GPT-4 in March, though it later turned out we had a sneak peak of it in February when Microsoft used it as part of the new Bing. This may well change in the next few weeks: Google‚Äôs Gemini Ultra has big claims, but isn‚Äôt yet available for us to try out. The team behind Mistral are working to beat GPT-4 as well, and their track record is already extremely strong considering their first public model only came out in September, and they‚Äôve released two significant improvements since then. Still,', '<2-hop>\\n\\nI‚Äôm surprised that no-one has beaten the now almost year old GPT-4 by now. OpenAI clearly have some substantial tricks that they haven‚Äôt shared yet. Vibes Based Development As a computer scientist and software engineer, LLMs are infuriating. Even the openly licensed ones are still the world‚Äôs most convoluted black boxes. We continue to have very little idea what they can do, how exactly they work and how best to control them. I‚Äôm used to programming where the computer does exactly what I tell it to do. Prompting an LLM is decidedly not that! The worst part is the challenge of evaluating them. There are plenty of benchmarks, but no benchmark is going to tell you if an LLM actually ‚Äúfeels‚Äù right when you try it for a given task. I find I have to work with an LLM for a few weeks in order to get a good intuition for it‚Äôs strengths and weaknesses. This greatly limits how many I can evaluate myself! The most frustrating thing for me is at the level of individual prompting. Sometimes I‚Äôll tweak a prompt and capitalize some of the words in it, to emphasize that I really want it to OUTPUT VALID MARKDOWN or similar. Did capitalizing those words make a difference? I still don‚Äôt have a good methodology for figuring that out. We‚Äôre left with what‚Äôs effectively Vibes Based Development. It‚Äôs vibes all the way down. I‚Äôd love to see us move beyond vibes in 2024! LLMs are really smart, and also really, really dumb On the one hand, we keep on finding new things that LLMs can do that we didn‚Äôt expect‚Äîand that the people who trained the models didn‚Äôt expect either. That‚Äôs usually really fun! But on the other hand, the things you sometimes have to do to get the models to behave are often incredibly dumb. Does ChatGPT get lazy in December, because its hidden system prompt includes the current date and its training data shows that people provide less useful answers coming up to the holidays? The honest answer is ‚Äúmaybe‚Äù! No-one is entirely sure, but if you give it a different date its answers may skew slightly longer. Sometimes it omits sections of code and leaves you to fill them in, but if you tell it you can‚Äôt type because you don‚Äôt have any fingers it produces the full code for you instead. There are so many more examples like this. Offer it cash tips for better answers. Tell it your career depends on it. Give it positive reinforcement. It‚Äôs all so dumb, but it works! Gullibility is the biggest unsolved problem I coined the term prompt injection in September last year. 15 months later, I regret to say that we‚Äôre still no closer to a robust, dependable solution to this problem. I‚Äôve written a ton about this already. Beyond that specific class of security vulnerabilities, I‚Äôve started seeing this as a wider problem of gullibility. Language Models are gullible. They ‚Äúbelieve‚Äù what we tell them‚Äîwhat‚Äôs in their training data, then what‚Äôs in the fine-tuning data, then what‚Äôs in the prompt. In order to be useful tools for us, we need them to believe what we feed them! But it turns out a lot of the things we want to build need them not to be gullible. Everyone wants an AI personal assistant. If you hired a real-world personal assistant who believed everything that anyone told them, you would quickly find that their ability to positively impact your life was severely limited. A lot of people are excited about AI agents‚Äîan infuriatingly vague term that seems to be converging on ‚ÄúAI systems that can go away and act on your behalf‚Äù. We‚Äôve been talking about them all year, but I‚Äôve seen few if any examples of them running in production, despite lots of exciting prototypes. I think this is because of gullibility. Can we solve this? Honestly, I‚Äôm beginning to suspect that you can‚Äôt fully solve gullibility without achieving AGI. So it may be quite a while before those agent dreams can really start to come true! Code may be the best application Over the course of the year, it‚Äôs become increasingly clear that writing code is one of the things LLMs are most capable of. If you think about what they do, this isn‚Äôt such a big surprise. The grammar rules of programming languages like Python and JavaScript are massively less complicated than the grammar of Chinese, Spanish or English. It‚Äôs still astonishing to me how effective they are though. One of the great weaknesses of LLMs is their tendency to hallucinate‚Äîto imagine things that don‚Äôt correspond to reality. You would expect this to be a particularly bad problem for code‚Äîif an LLM hallucinates a method that doesn‚Äôt exist, the code should be useless. Except... you can run generated code to see if it‚Äôs correct. And with patterns like ChatGPT Code Interpreter the LLM can execute the code itself, process the error message, then rewrite it and keep trying until it works! So hallucination is a much lesser problem for code generation than for anything else. If only we had the equivalent of Code Interpreter for fact-checking natural language! How should we feel about this as software engineers? On the one hand, this feels like a threat: who needs a programmer if ChatGPT can write code for you? On the other hand, as software engineers we are better placed to take advantage of this than anyone else. We‚Äôve all been given weird coding interns‚Äîwe can use our deep knowledge to prompt them to solve coding problems more effectively than anyone else can. The ethics of this space remain diabolically complex In September last year Andy Baio and I produced the first major story on the unlicensed training data behind Stable Diffusion. Since then, almost every major LLM (and most of the image generation models) have also been trained on unlicensed data. Just this week, the New York Times launched a landmark lawsuit against OpenAI and']",
                  "The rise of LLMs has significantly impacted software engineering and programming roles, especially through their applications in code generation and productivity enhancement. According to the context, writing code has emerged as one of the most effective applications of LLMs, largely because programming languages have simpler grammar rules compared to natural languages. LLMs can generate surprisingly competent code, and tools like ChatGPT Code Interpreter allow the model to execute and iteratively improve its own code, reducing the impact of hallucinations that might otherwise render generated code useless. This capability presents both opportunities and threats for software engineers. On one hand, there is a perceived threat that LLMs could replace programmers, as they can automate many coding tasks. On the other hand, software engineers are uniquely positioned to leverage LLMs as powerful tools or 'weird coding interns,' using their expertise to prompt LLMs more effectively than non-experts. This duality means that while LLMs may automate certain aspects of programming, they also offer significant productivity boosts and new ways for engineers to enhance their work, provided they adapt to and integrate these tools into their workflows.",
                  "multi_hop_abstract_query_synthesizer"
                ],
                [
                  "5",
                  "How have large language models impacted software engineering roles, particularly through applications like code generation, and what challenges do software engineers face when working with these models?",
                  "['<1-hop>\\n\\nWe don‚Äôt yet know how to build GPT-4 Vibes Based Development LLMs are really smart, and also really, really dumb Gullibility is the biggest unsolved problem Code may be the best application The ethics of this space remain diabolically complex My blog in 2023 Here‚Äôs the sequel to this post: Things we learned about LLMs in 2024. Large Language Models In the past 24-36 months, our species has discovered that you can take a GIANT corpus of text, run it through a pile of GPUs, and use it to create a fascinating new kind of software. LLMs can do a lot of things. They can answer questions, summarize documents, translate from one language to another, extract information and even write surprisingly competent code. They can also help you cheat at your homework, generate unlimited streams of fake content and be used for all manner of nefarious purposes. So far, I think they‚Äôre a net positive. I‚Äôve used them on a personal level to improve my productivity (and entertain myself) in all sorts of different ways. I think people who learn how to use them effectively can gain a significant boost to their quality of life. A lot of people are yet to be sold on their value! Some think their negatives outweigh their positives, some think they are all hot air, and some even think they represent an existential threat to humanity. They‚Äôre actually quite easy to build The most surprising thing we‚Äôve learned about LLMs this year is that they‚Äôre actually quite easy to build. Intuitively, one would expect that systems this powerful would take millions of lines of complex code. Instead, it turns out a few hundred lines of Python is genuinely enough to train a basic version! What matters most is the training data. You need a lot of data to make these things work, and the quantity and quality of the training data appears to be the most important factor in how good the resulting model is. If you can gather the right data, and afford to pay for the GPUs to train it, you can build an LLM. A year ago, the only organization that had released a generally useful LLM was OpenAI. We‚Äôve now seen better-than-GPT-3 class models produced by Anthropic, Mistral, Google, Meta, EleutherAI, Stability AI, TII in Abu Dhabi (Falcon), Microsoft Research, xAI, Replit, Baidu and a bunch of other organizations. The training cost (hardware and electricity) is still significant‚Äîinitially millions of dollars, but that seems to have dropped to the tens of thousands already. Microsoft‚Äôs Phi-2 claims to have used ‚Äú14 days on 96 A100 GPUs‚Äù, which works out at around $35,000 using current Lambda pricing. So training an LLM still isn‚Äôt something a hobbyist can afford, but it‚Äôs no longer the sole domain of the super-rich. I like to compare the difficulty of training an LLM to that of building a suspension bridge‚Äînot trivial, but hundreds of countries around the world have figured out how to do it. (Correction: Wikipedia‚Äôs Suspension bridges by country category lists 44 countries). You can run LLMs on your own devices In January of this year, I thought it would be years before I could run a useful LLM on my own computer. GPT-3 and 3.5 were pretty much the only games in town, and I thought that even if the model weights were available it would take a $10,000+ server to run them. Then in February, Meta released Llama. And a few weeks later in March, Georgi Gerganov released code that got it working on a MacBook. I wrote about how Large language models are having their Stable Diffusion moment, and with hindsight that was a very good call! This unleashed a whirlwind of innovation, which was accelerated further in July when Meta released Llama 2‚Äîan improved version which, crucially, included permission for commercial use. Today there are literally thousands of LLMs that can be run locally, on all manner of different devices. I run a bunch of them on my laptop. I run Mistral 7B (a surprisingly great model) on my iPhone. You can install several different apps to get your own, local, completely private LLM. My own LLM project provides a CLI tool for running an array of different models via plugins. You can even run them entirely in your browser using WebAssembly and the latest Chrome! Hobbyists can build their own fine-tuned models I said earlier that building an LLM was still out of reach of hobbyists. That may be true for training from scratch, but fine-tuning one of those models is another matter entirely. There‚Äôs now a fascinating ecosystem of people training their own models on top of these foundations, publishing those models, building fine-tuning datasets and sharing those too. The Hugging Face Open LLM Leaderboard is one place that tracks these. I can‚Äôt even attempt to count them, and any count would be out-of-date within a few hours. The best overall openly licensed LLM at any time is rarely a foundation model: instead, it‚Äôs whichever fine-tuned community model has most recently discovered the best combination of fine-tuning data. This is a huge advantage for open over closed models: the closed, hosted models don‚Äôt have thousands of researchers and hobbyists around the world collaborating and competing to improve them. We don‚Äôt yet know how to build GPT-4 Frustratingly, despite the enormous leaps ahead we‚Äôve had this year, we are yet to see an alternative model that‚Äôs better than GPT-4. OpenAI released GPT-4 in March, though it later turned out we had a sneak peak of it in February when Microsoft used it as part of the new Bing. This may well change in the next few weeks: Google‚Äôs Gemini Ultra has big claims, but isn‚Äôt yet available for us to try out. The team behind Mistral are working to beat GPT-4 as well, and their track record is already extremely strong considering their first public model only came out in September, and they‚Äôve released two significant improvements since then. Still,', '<2-hop>\\n\\nI‚Äôm surprised that no-one has beaten the now almost year old GPT-4 by now. OpenAI clearly have some substantial tricks that they haven‚Äôt shared yet. Vibes Based Development As a computer scientist and software engineer, LLMs are infuriating. Even the openly licensed ones are still the world‚Äôs most convoluted black boxes. We continue to have very little idea what they can do, how exactly they work and how best to control them. I‚Äôm used to programming where the computer does exactly what I tell it to do. Prompting an LLM is decidedly not that! The worst part is the challenge of evaluating them. There are plenty of benchmarks, but no benchmark is going to tell you if an LLM actually ‚Äúfeels‚Äù right when you try it for a given task. I find I have to work with an LLM for a few weeks in order to get a good intuition for it‚Äôs strengths and weaknesses. This greatly limits how many I can evaluate myself! The most frustrating thing for me is at the level of individual prompting. Sometimes I‚Äôll tweak a prompt and capitalize some of the words in it, to emphasize that I really want it to OUTPUT VALID MARKDOWN or similar. Did capitalizing those words make a difference? I still don‚Äôt have a good methodology for figuring that out. We‚Äôre left with what‚Äôs effectively Vibes Based Development. It‚Äôs vibes all the way down. I‚Äôd love to see us move beyond vibes in 2024! LLMs are really smart, and also really, really dumb On the one hand, we keep on finding new things that LLMs can do that we didn‚Äôt expect‚Äîand that the people who trained the models didn‚Äôt expect either. That‚Äôs usually really fun! But on the other hand, the things you sometimes have to do to get the models to behave are often incredibly dumb. Does ChatGPT get lazy in December, because its hidden system prompt includes the current date and its training data shows that people provide less useful answers coming up to the holidays? The honest answer is ‚Äúmaybe‚Äù! No-one is entirely sure, but if you give it a different date its answers may skew slightly longer. Sometimes it omits sections of code and leaves you to fill them in, but if you tell it you can‚Äôt type because you don‚Äôt have any fingers it produces the full code for you instead. There are so many more examples like this. Offer it cash tips for better answers. Tell it your career depends on it. Give it positive reinforcement. It‚Äôs all so dumb, but it works! Gullibility is the biggest unsolved problem I coined the term prompt injection in September last year. 15 months later, I regret to say that we‚Äôre still no closer to a robust, dependable solution to this problem. I‚Äôve written a ton about this already. Beyond that specific class of security vulnerabilities, I‚Äôve started seeing this as a wider problem of gullibility. Language Models are gullible. They ‚Äúbelieve‚Äù what we tell them‚Äîwhat‚Äôs in their training data, then what‚Äôs in the fine-tuning data, then what‚Äôs in the prompt. In order to be useful tools for us, we need them to believe what we feed them! But it turns out a lot of the things we want to build need them not to be gullible. Everyone wants an AI personal assistant. If you hired a real-world personal assistant who believed everything that anyone told them, you would quickly find that their ability to positively impact your life was severely limited. A lot of people are excited about AI agents‚Äîan infuriatingly vague term that seems to be converging on ‚ÄúAI systems that can go away and act on your behalf‚Äù. We‚Äôve been talking about them all year, but I‚Äôve seen few if any examples of them running in production, despite lots of exciting prototypes. I think this is because of gullibility. Can we solve this? Honestly, I‚Äôm beginning to suspect that you can‚Äôt fully solve gullibility without achieving AGI. So it may be quite a while before those agent dreams can really start to come true! Code may be the best application Over the course of the year, it‚Äôs become increasingly clear that writing code is one of the things LLMs are most capable of. If you think about what they do, this isn‚Äôt such a big surprise. The grammar rules of programming languages like Python and JavaScript are massively less complicated than the grammar of Chinese, Spanish or English. It‚Äôs still astonishing to me how effective they are though. One of the great weaknesses of LLMs is their tendency to hallucinate‚Äîto imagine things that don‚Äôt correspond to reality. You would expect this to be a particularly bad problem for code‚Äîif an LLM hallucinates a method that doesn‚Äôt exist, the code should be useless. Except... you can run generated code to see if it‚Äôs correct. And with patterns like ChatGPT Code Interpreter the LLM can execute the code itself, process the error message, then rewrite it and keep trying until it works! So hallucination is a much lesser problem for code generation than for anything else. If only we had the equivalent of Code Interpreter for fact-checking natural language! How should we feel about this as software engineers? On the one hand, this feels like a threat: who needs a programmer if ChatGPT can write code for you? On the other hand, as software engineers we are better placed to take advantage of this than anyone else. We‚Äôve all been given weird coding interns‚Äîwe can use our deep knowledge to prompt them to solve coding problems more effectively than anyone else can. The ethics of this space remain diabolically complex In September last year Andy Baio and I produced the first major story on the unlicensed training data behind Stable Diffusion. Since then, almost every major LLM (and most of the image generation models) have also been trained on unlicensed data. Just this week, the New York Times launched a landmark lawsuit against OpenAI and']",
                  "Large language models (LLMs) have significantly impacted software engineering roles, especially through their strong capabilities in code generation. As noted, writing code is one of the tasks LLMs are most capable of, due to the relatively simple grammar of programming languages compared to natural languages. This has led to LLMs being used to write surprisingly competent code, and tools like ChatGPT Code Interpreter can even execute and iteratively improve generated code, reducing issues like hallucination. However, this advancement presents both opportunities and challenges for software engineers. On one hand, LLMs can be seen as a threat to traditional programming roles, since they can automate parts of the coding process. On the other hand, software engineers are uniquely positioned to leverage LLMs effectively, using their expertise to prompt and guide these models to solve complex coding problems. Despite these benefits, engineers face challenges such as the 'black box' nature of LLMs, difficulties in evaluating their outputs, and the need for 'Vibes Based Development'‚Äîrelying on intuition and trial-and-error when prompting models. Additionally, issues like model gullibility and the lack of robust methodologies for prompt engineering remain unresolved, complicating the integration of LLMs into software engineering workflows.",
                  "multi_hop_abstract_query_synthesizer"
                ],
                [
                  "6",
                  "How does the use of synthetic training data provide advantages over organic data in the development of large language models, and what are some examples of these advantages as described in recent model training practices?",
                  "['<1-hop>\\n\\nThe rise of inference-scaling ‚Äúreasoning‚Äù models Was the best currently available LLM trained in China for less than $6m? The environmental impact got better The environmental impact got much, much worse The year of slop Synthetic training data works great LLMs somehow got even harder to use Knowledge is incredibly unevenly distributed LLMs need better criticism Everything tagged ‚Äúllms‚Äù on my blog in 2024 The GPT-4 barrier was comprehensively broken In my December 2023 review I wrote about how We don‚Äôt yet know how to build GPT-4‚ÄîOpenAI‚Äôs best model was almost a year old at that point, yet no other AI lab had produced anything better. What did OpenAI know that the rest of us didn‚Äôt? I‚Äôm relieved that this has changed completely in the past twelve months. 18 organizations now have models on the Chatbot Arena Leaderboard that rank higher than the original GPT-4 from March 2023 (GPT-4-0314 on the board)‚Äî70 models in total. Screenshot of a comparison table showing AI model rankings. Table headers: Rank (UB), Rank (StyleCtrl), Model, Arena Score, 95% CI, Votes, Organization, License. Shows 12 models including GLM-4-0520, Llama-3-70B-Instruct, Gemini-1.5-Flash-8B-Exp-0827, with rankings, scores, and licensing details. Models range from rank 52-69 with Arena scores between 1186-1207. The earliest of those was Google‚Äôs Gemini 1.5 Pro, released in February. In addition to producing GPT-4 level outputs, it introduced several brand new capabilities to the field‚Äîmost notably its 1 million (and then later 2 million) token input context length, and the ability to input video. I wrote about this at the time in The killer app of Gemini Pro 1.5 is video, which earned me a short appearance as a talking head in the Google I/O opening keynote in May. Gemini 1.5 Pro also illustrated one of the key themes of 2024: increased context lengths. Last year most models accepted 4,096 or 8,192 tokens, with the notable exception of Claude 2.1 which accepted 200,000. Today every serious provider has a 100,000+ token model, and Google‚Äôs Gemini series accepts up to 2 million. Longer inputs dramatically increase the scope of problems that can be solved with an LLM: you can now throw in an entire book and ask questions about its contents, but more importantly you can feed in a lot of example code to help the model correctly solve a coding problem. LLM use-cases that involve long inputs are far more interesting to me than short prompts that rely purely on the information already baked into the model weights. Many of my tools were built using this pattern. Getting back to models that beat GPT-4: Anthropic‚Äôs Claude 3 series launched in March, and Claude 3 Opus quickly became my new favourite daily-driver. They upped the ante even more in June with the launch of Claude 3.5 Sonnet‚Äîa model that is still my favourite six months later (though it got a significant upgrade on October 22, confusingly keeping the same 3.5 version number. Anthropic fans have since taken to calling it Claude 3.6). Then there‚Äôs the rest. If you browse the Chatbot Arena leaderboard today‚Äîstill the most useful single place to get a vibes-based evaluation of models‚Äîyou‚Äôll see that GPT-4-0314 has fallen to around 70th place. The 18 organizations with higher scoring models are Google, OpenAI, Alibaba, Anthropic, Meta, Reka AI, 01 AI, Amazon, Cohere, DeepSeek, Nvidia, Mistral, NexusFlow, Zhipu AI, xAI, AI21 Labs, Princeton and Tencent. Training a GPT-4 beating model was a huge deal in 2023. In 2024 it‚Äôs an achievement that isn‚Äôt even particularly notable, though I personally still celebrate any time a new organization joins that list. Some of those GPT-4 models run on my laptop My personal laptop is a 64GB M2 MacBook Pro from 2023. It‚Äôs a powerful machine, but it‚Äôs also nearly two years old now‚Äîand crucially it‚Äôs the same laptop I‚Äôve been using ever since I first ran an LLM on my computer back in March 2023 (see Large language models are having their Stable Diffusion moment). That same laptop that could just about run a GPT-3-class model in March last year has now run multiple GPT-4 class models! Some of my notes on that: Qwen2.5-Coder-32B is an LLM that can code well that runs on my Mac talks about Qwen2.5-Coder-32B in November‚Äîan Apache 2.0 licensed model! I can now run a GPT-4 class model on my laptop talks about running Meta‚Äôs Llama 3.3 70B (released in December) This remains astonishing to me. I thought a model with the capabilities and output quality of GPT-4 needed a datacenter class server with one or more $40,000+ GPUs. These models take up enough of my 64GB of RAM that I don‚Äôt run them often‚Äîthey don‚Äôt leave much room for anything else. The fact that they run at all is a testament to the incredible training and inference performance gains that we‚Äôve figured out over the past year. It turns out there was a lot of low-hanging fruit to be harvested in terms of model efficiency. I expect there‚Äôs still more to come. Meta‚Äôs Llama 3.2 models deserve a special mention. They may not be GPT-4 class, but at 1B and 3B sizes they punch massively above their weight. I run Llama 3.2 3B on my iPhone using the free MLC Chat iOS app and it‚Äôs a shockingly capable model for its tiny (<2GB) size. Try firing it up and asking it for ‚Äúa plot outline of a Netflix Christmas movie where a data journalist falls in love with a local ceramacist‚Äù. Here‚Äôs what I got, at a respectable 20 tokens per second: MLC Chat: Llama - [System] Ready to chat. a plot outline of a Netflix Christmas movie where a data journalist falls in love with a local ceramacist. Show as Markdown is turned on. Here\\'s a plot outline for a Netflix Christmas movie: Title: \"Love in the Clay\" Plot Outline: We meet our protagonist, JESSICA, a data journalist who has just returned to her hometown of Willow Creek, a small, charming town nestled in the snow-covered mountains. She\\'s back to work', '<2-hop>\\n\\nmodel available to try out through their chat interface on November 20th. To understand more about inference scaling I recommend Is AI progress slowing down? by Arvind Narayanan and Sayash Kapoor. Nothing yet from Anthropic or Meta but I would be very surprised if they don‚Äôt have their own inference-scaling models in the works. Meta published a relevant paper Training Large Language Models to Reason in a Continuous Latent Space in December. Was the best currently available LLM trained in China for less than $6m? Not quite, but almost! It does make for a great attention-grabbing headline. The big news to end the year was the release of DeepSeek v3‚Äîdropped on Hugging Face on Christmas Day without so much as a README file, then followed by documentation and a paper the day after that. DeepSeek v3 is a huge 685B parameter model‚Äîone of the largest openly licensed models currently available, significantly bigger than the largest of Meta‚Äôs Llama series, Llama 3.1 405B. Benchmarks put it up there with Claude 3.5 Sonnet. Vibe benchmarks (aka the Chatbot Arena) currently rank it 7th, just behind the Gemini 2.0 and OpenAI 4o/o1 models. This is by far the highest ranking openly licensed model. The really impressive thing about DeepSeek v3 is the training cost. The model was trained on 2,788,000 H800 GPU hours at an estimated cost of $5,576,000. Llama 3.1 405B trained 30,840,000 GPU hours‚Äî11x that used by DeepSeek v3, for a model that benchmarks slightly worse. Those US export regulations on GPUs to China seem to have inspired some very effective training optimizations! The environmental impact got better A welcome result of the increased efficiency of the models‚Äîboth the hosted ones and the ones I can run locally‚Äîis that the energy usage and environmental impact of running a prompt has dropped enormously over the past couple of years. OpenAI themselves are charging 100x less for a prompt compared to the GPT-3 days. I have it on good authority that neither Google Gemini nor Amazon Nova (two of the least expensive model providers) are running prompts at a loss. I think this means that, as individual users, we don‚Äôt need to feel any guilt at all for the energy consumed by the vast majority of our prompts. The impact is likely neglible compared to driving a car down the street or maybe even watching a video on YouTube. Likewise, training. DeepSeek v3 training for less than $6m is a fantastic sign that training costs can and should continue to drop. For less efficient models I find it useful to compare their energy usage to commercial flights. The largest Llama 3 model cost about the same as a single digit number of fully loaded passenger flights from New York to London. That‚Äôs certainly not nothing, but once trained that model can be used by millions of people at no extra training cost. The environmental impact got much, much worse The much bigger problem here is the enormous competitive buildout of the infrastructure that is imagined to be necessary for these models in the future. Companies like Google, Meta, Microsoft and Amazon are all spending billions of dollars rolling out new datacenters, with a very material impact on the electricity grid and the environment. There‚Äôs even talk of spinning up new nuclear power stations, but those can take decades. Is this infrastructure necessary? DeepSeek v3‚Äôs $6m training cost and the continued crash in LLM prices might hint that it‚Äôs not. But would you want to be the big tech executive that argued NOT to build out this infrastructure only to be proven wrong in a few years‚Äô time? An interesting point of comparison here could be the way railways rolled out around the world in the 1800s. Constructing these required enormous investments and had a massive environmental impact, and many of the lines that were built turned out to be unnecessary‚Äîsometimes multiple lines from different companies serving the exact same routes! The resulting bubbles contributed to several financial crashes, see Wikipedia for Panic of 1873, Panic of 1893, Panic of 1901 and the UK‚Äôs Railway Mania. They left us with a lot of useful infrastructure and a great deal of bankruptcies and environmental damage. The year of slop 2024 was the year that the word \"slop\" became a term of art. I wrote about this in May, expanding on this tweet by @deepfates: Watching in real time as ‚Äúslop‚Äù becomes a term of art. the way that ‚Äúspam‚Äù became the term for unwanted emails, ‚Äúslop‚Äù is going in the dictionary as the term for unwanted AI generated content I expanded that definition a tiny bit to this: Slop describes AI-generated content that is both unrequested and unreviewed. I ended up getting quoted talking about slop in both the Guardian and the NY Times. Here‚Äôs what I said in the NY TImes: Society needs concise ways to talk about modern A.I. ‚Äî both the positives and the negatives. ‚ÄòIgnore that email, it‚Äôs spam,‚Äô and ‚ÄòIgnore that article, it‚Äôs slop,‚Äô are both useful lessons. I love the term ‚Äúslop‚Äù because it so succinctly captures one of the ways we should not be using generative AI! Slop was even in the running for Oxford Word of the Year 2024, but it lost to brain rot. Synthetic training data works great An idea that surprisingly seems to have stuck in the public consciousness is that of ‚Äúmodel collapse‚Äù. This was first described in the paper The Curse of Recursion: Training on Generated Data Makes Models Forget in May 2023, and repeated in Nature in July 2024 with the more eye-catching headline AI models collapse when trained on recursively generated data. The idea is seductive: as the internet floods with AI-generated slop the models themselves will degenerate, feeding on their own output in a way that leads to their inevitable demise! That‚Äôs clearly not happening. Instead, we are seeing AI labs increasingly train on synthetic content‚Äîdeliberately creating artificial data to help steer their models in the right way. One', '<3-hop>\\n\\nof the best descriptions I‚Äôve seen of this comes from the Phi-4 technical report, which included this: Synthetic data as a substantial component of pretraining is becoming increasingly common, and the Phi series of models has consistently emphasized the importance of synthetic data. Rather than serving as a cheap substitute for organic data, synthetic data has several direct advantages over organic data. Structured and Gradual Learning. In organic datasets, the relationship between tokens is often complex and indirect. Many reasoning steps may be required to connect the current token to the next, making it challenging for the model to learn effectively from next-token prediction. By contrast, each token generated by a language model is by definition predicted by the preceding tokens, making it easier for a model to follow the resulting reasoning patterns. Another common technique is to use larger models to help create training data for their smaller, cheaper alternatives‚Äîa trick used by an increasing number of labs. DeepSeek v3 used ‚Äúreasoning‚Äù data created by DeepSeek-R1. Meta‚Äôs Llama 3.3 70B fine-tuning used over 25M synthetically generated examples. Careful design of the training data that goes into an LLM appears to be the entire game for creating these models. The days of just grabbing a full scrape of the web and indiscriminately dumping it into a training run are long gone. LLMs somehow got even harder to use A drum I‚Äôve been banging for a while is that LLMs are power-user tools‚Äîthey‚Äôre chainsaws disguised as kitchen knives. They look deceptively simple to use‚Äîhow hard can it be to type messages to a chatbot?‚Äîbut in reality you need a huge depth of both understanding and experience to make the most of them and avoid their many pitfalls. If anything, this problem got worse in 2024. We‚Äôve built computer systems you can talk to in human language, that will answer your questions and usually get them right! ... depending on the question, and how you ask it, and whether it‚Äôs accurately reflected in the undocumented and secret training set. The number of available systems has exploded. Different systems have different tools they can apply to your problems‚Äîlike Python and JavaScript and web search and image generation and maybe even database lookups... so you‚Äôd better understand what those tools are, what they can do and how to tell if the LLM used them or not. Did you know ChatGPT has two entirely different ways of running Python now? Want to build a Claude Artifact that talks to an external API? You‚Äôd better understand CSP and CORS HTTP headers first. The models may have got more capable, but most of the limitations remained the same. OpenAI‚Äôs o1 may finally be able to (mostly) count the Rs in strawberry, but its abilities are still limited by its nature as an LLM and the constraints placed on it by the harness it‚Äôs running in. o1 can‚Äôt run web searches or use Code Interpreter, but GPT-4o can‚Äîboth in that same ChatGPT UI. (o1 will pretend to do those things if you ask it to, a regression to the URL hallucinations bug from early 2023). What are we doing about this? Not much. Most users are thrown in at the deep end. The default LLM chat UI is like taking brand new computer users, dropping them into a Linux terminal and expecting them to figure it all out. Meanwhile, it‚Äôs increasingly common for end users to develop wildly inaccurate mental models of how these things work and what they are capable of. I‚Äôve seen so many examples of people trying to win an argument with a screenshot from ChatGPT‚Äîan inherently ludicrous proposition, given the inherent unreliability of these models crossed with the fact that you can get them to say anything if you prompt them right. There‚Äôs a flipside to this too: a lot of better informed people have sworn off LLMs entirely because they can‚Äôt see how anyone could benefit from a tool with so many flaws. The key skill in getting the most out of LLMs is learning to work with tech that is both inherently unreliable and incredibly powerful at the same time. This is a decidedly non-obvious skill to acquire! There is so much space for helpful education content here, but we need to do do a lot better than outsourcing it all to AI grifters with bombastic Twitter threads. Knowledge is incredibly unevenly distributed Most people have heard of ChatGPT by now. How many have heard of Claude? The knowledge gap between the people who actively follow this stuff and the 99% of the population who do not is vast. The pace of change doesn‚Äôt help either. In just the past month we‚Äôve seen general availability of live interfaces where you can point your phone‚Äôs camera at something and talk about it with your voice... and optionally have it pretend to be Santa. Most self-certified nerds haven‚Äôt even tried that yet. Given the ongoing (and potential) impact on society that this technology has, I don‚Äôt think the size of this gap is healthy. I‚Äôd like to see a lot more effort put into improving this. LLMs need better criticism A lot of people absolutely hate this stuff. In some of the spaces I hang out (Mastodon, Bluesky, Lobste.rs, even Hacker News on occasion) even suggesting that ‚ÄúLLMs are useful‚Äù can be enough to kick off a huge fight. I get it. There are plenty of reasons to dislike this technology‚Äîthe environmental impact, the (lack of) ethics of the training data, the lack of reliability, the negative applications, the potential impact on people‚Äôs jobs. LLMs absolutely warrant criticism. We need to be talking through these problems, finding ways to mitigate them and helping people learn how to use these tools responsibly in ways where the positive applications outweigh the negative. I like people who are skeptical of this stuff. The hype has been deafening for more than two years now, and there are enormous quantities of snake oil and misinformation out there. A lot']",
                  "Synthetic training data offers several direct advantages over organic data in the development of large language models. According to the Phi-4 technical report, synthetic data enables structured and gradual learning because each token generated is predicted by the preceding tokens, making it easier for models to follow reasoning patterns. In contrast, organic datasets often have complex and indirect relationships between tokens, which can make effective learning more challenging. Additionally, synthetic data allows for deliberate design and curation, helping steer models in desired directions. Recent model training practices illustrate these benefits: for example, DeepSeek v3 used 'reasoning' data created by DeepSeek-R1, and Meta‚Äôs Llama 3.3 70B fine-tuning involved over 25 million synthetically generated examples. These practices show that synthetic data is not just a substitute for organic data but a tool for more effective and targeted model training.",
                  "multi_hop_abstract_query_synthesizer"
                ],
                [
                  "7",
                  "How have improvements in LLM efficiency over the past year influenced both the environmental impact of AI model training and the cost of using large language models, according to recent trends?",
                  "['<1-hop>\\n\\nThe rise of inference-scaling ‚Äúreasoning‚Äù models Was the best currently available LLM trained in China for less than $6m? The environmental impact got better The environmental impact got much, much worse The year of slop Synthetic training data works great LLMs somehow got even harder to use Knowledge is incredibly unevenly distributed LLMs need better criticism Everything tagged ‚Äúllms‚Äù on my blog in 2024 The GPT-4 barrier was comprehensively broken In my December 2023 review I wrote about how We don‚Äôt yet know how to build GPT-4‚ÄîOpenAI‚Äôs best model was almost a year old at that point, yet no other AI lab had produced anything better. What did OpenAI know that the rest of us didn‚Äôt? I‚Äôm relieved that this has changed completely in the past twelve months. 18 organizations now have models on the Chatbot Arena Leaderboard that rank higher than the original GPT-4 from March 2023 (GPT-4-0314 on the board)‚Äî70 models in total. Screenshot of a comparison table showing AI model rankings. Table headers: Rank (UB), Rank (StyleCtrl), Model, Arena Score, 95% CI, Votes, Organization, License. Shows 12 models including GLM-4-0520, Llama-3-70B-Instruct, Gemini-1.5-Flash-8B-Exp-0827, with rankings, scores, and licensing details. Models range from rank 52-69 with Arena scores between 1186-1207. The earliest of those was Google‚Äôs Gemini 1.5 Pro, released in February. In addition to producing GPT-4 level outputs, it introduced several brand new capabilities to the field‚Äîmost notably its 1 million (and then later 2 million) token input context length, and the ability to input video. I wrote about this at the time in The killer app of Gemini Pro 1.5 is video, which earned me a short appearance as a talking head in the Google I/O opening keynote in May. Gemini 1.5 Pro also illustrated one of the key themes of 2024: increased context lengths. Last year most models accepted 4,096 or 8,192 tokens, with the notable exception of Claude 2.1 which accepted 200,000. Today every serious provider has a 100,000+ token model, and Google‚Äôs Gemini series accepts up to 2 million. Longer inputs dramatically increase the scope of problems that can be solved with an LLM: you can now throw in an entire book and ask questions about its contents, but more importantly you can feed in a lot of example code to help the model correctly solve a coding problem. LLM use-cases that involve long inputs are far more interesting to me than short prompts that rely purely on the information already baked into the model weights. Many of my tools were built using this pattern. Getting back to models that beat GPT-4: Anthropic‚Äôs Claude 3 series launched in March, and Claude 3 Opus quickly became my new favourite daily-driver. They upped the ante even more in June with the launch of Claude 3.5 Sonnet‚Äîa model that is still my favourite six months later (though it got a significant upgrade on October 22, confusingly keeping the same 3.5 version number. Anthropic fans have since taken to calling it Claude 3.6). Then there‚Äôs the rest. If you browse the Chatbot Arena leaderboard today‚Äîstill the most useful single place to get a vibes-based evaluation of models‚Äîyou‚Äôll see that GPT-4-0314 has fallen to around 70th place. The 18 organizations with higher scoring models are Google, OpenAI, Alibaba, Anthropic, Meta, Reka AI, 01 AI, Amazon, Cohere, DeepSeek, Nvidia, Mistral, NexusFlow, Zhipu AI, xAI, AI21 Labs, Princeton and Tencent. Training a GPT-4 beating model was a huge deal in 2023. In 2024 it‚Äôs an achievement that isn‚Äôt even particularly notable, though I personally still celebrate any time a new organization joins that list. Some of those GPT-4 models run on my laptop My personal laptop is a 64GB M2 MacBook Pro from 2023. It‚Äôs a powerful machine, but it‚Äôs also nearly two years old now‚Äîand crucially it‚Äôs the same laptop I‚Äôve been using ever since I first ran an LLM on my computer back in March 2023 (see Large language models are having their Stable Diffusion moment). That same laptop that could just about run a GPT-3-class model in March last year has now run multiple GPT-4 class models! Some of my notes on that: Qwen2.5-Coder-32B is an LLM that can code well that runs on my Mac talks about Qwen2.5-Coder-32B in November‚Äîan Apache 2.0 licensed model! I can now run a GPT-4 class model on my laptop talks about running Meta‚Äôs Llama 3.3 70B (released in December) This remains astonishing to me. I thought a model with the capabilities and output quality of GPT-4 needed a datacenter class server with one or more $40,000+ GPUs. These models take up enough of my 64GB of RAM that I don‚Äôt run them often‚Äîthey don‚Äôt leave much room for anything else. The fact that they run at all is a testament to the incredible training and inference performance gains that we‚Äôve figured out over the past year. It turns out there was a lot of low-hanging fruit to be harvested in terms of model efficiency. I expect there‚Äôs still more to come. Meta‚Äôs Llama 3.2 models deserve a special mention. They may not be GPT-4 class, but at 1B and 3B sizes they punch massively above their weight. I run Llama 3.2 3B on my iPhone using the free MLC Chat iOS app and it‚Äôs a shockingly capable model for its tiny (<2GB) size. Try firing it up and asking it for ‚Äúa plot outline of a Netflix Christmas movie where a data journalist falls in love with a local ceramacist‚Äù. Here‚Äôs what I got, at a respectable 20 tokens per second: MLC Chat: Llama - [System] Ready to chat. a plot outline of a Netflix Christmas movie where a data journalist falls in love with a local ceramacist. Show as Markdown is turned on. Here\\'s a plot outline for a Netflix Christmas movie: Title: \"Love in the Clay\" Plot Outline: We meet our protagonist, JESSICA, a data journalist who has just returned to her hometown of Willow Creek, a small, charming town nestled in the snow-covered mountains. She\\'s back to work', \"<2-hop>\\n\\non a story about the town's history and the effects of gentrification on the local community. Here‚Äôs the rest of the transcript. It‚Äôs bland and generic, but my phone can pitch bland and generic Christmas movies to Netflix now! LLM prices crashed, thanks to competition and increased efficiency The past twelve months have seen a dramatic collapse in the cost of running a prompt through the top tier hosted LLMs. In December 2023 (here‚Äôs the Internet Archive for the OpenAI pricing page) OpenAI were charging $30/million input tokens for GPT-4, $10/mTok for the then-new GPT-4 Turbo and $1/mTok for GPT-3.5 Turbo. Today $30/mTok gets you OpenAI‚Äôs most expensive model, o1. GPT-4o is $2.50 (12x cheaper than GPT-4) and GPT-4o mini is $0.15/mTok‚Äî200x cheaper than GPT-4, nearly 7x cheaper than GPT-3.5 and massively more capable than that model. Other model providers charge even less. Anthropic‚Äôs Claude 3 Haiku (from March, but still their cheapest model) is $0.25/mTok. Google‚Äôs Gemini 1.5 Flash is $0.075/mTok and their Gemini 1.5 Flash 8B is $0.0375/mTok‚Äîthat‚Äôs 27x cheaper than GPT-3.5 Turbo last year. I‚Äôve been tracking these pricing changes under my llm-pricing tag. These price drops are driven by two factors: increased competition and increased efficiency. The efficiency thing is really important for everyone who is concerned about the environmental impact of LLMs. These price drops tie directly to how much energy is being used for running prompts. There‚Äôs still plenty to worry about with respect to the environmental impact of the great AI datacenter buildout, but a lot of the concerns over the energy cost of individual prompts are no longer credible. Here‚Äôs a fun napkin calculation: how much would it cost to generate short descriptions of every one of the 68,000 photos in my personal photo library using Google‚Äôs Gemini 1.5 Flash 8B (released in October), their cheapest model? Each photo would need 260 input tokens and around 100 output tokens. 260 * 68,000 = 17,680,000 input tokens 17,680,000 * $0.0375/million = $0.66 100 * 68,000 = 6,800,000 output tokens 6,800,000 * $0.15/million = $1.02 That‚Äôs a total cost of $1.68 to process 68,000 images. That‚Äôs so absurdly cheap I had to run the numbers three times to confirm I got it right. How good are those descriptions? Here‚Äôs what I got from this command: llm -m gemini-1.5-flash-8b-latest describe -a IMG_1825.jpeg Against this photo of butterflies at the California Academy of Sciences: A photo of two butterflies feeding on a red tray A shallow dish, likely a hummingbird or butterfly feeder, is red. Pieces of orange slices of fruit are visible inside the dish. Two butterflies are positioned in the feeder, one is a dark brown/black butterfly with white/cream-colored markings. The other is a large, brown butterfly with patterns of lighter brown, beige, and black markings, including prominent eye spots. The larger brown butterfly appears to be feeding on the fruit. 260 input tokens, 92 output tokens. Cost approximately 0.0024 cents (that‚Äôs less than a 400th of a cent). This increase in efficiency and reduction in price is my single favourite trend from 2024. I want the utility of LLMs at a fraction of the energy cost and it looks like that‚Äôs what we‚Äôre getting. Multimodal vision is common, audio and video are starting to emerge My butterfly example above illustrates another key trend from 2024: the rise of multi-modal LLMs. A year ago the single most notable example of these was GPT-4 Vision, released at OpenAI‚Äôs DevDay in November 2023. Google‚Äôs multi-modal Gemini 1.0 was announced on December 7th 2023 so it also (just) makes it into the 2023 window. In 2024, almost every significant model vendor released multi-modal models. We saw the Claude 3 series from Anthropic in March, Gemini 1.5 Pro in April (images, audio and video), then September brought Qwen2-VL and Mistral‚Äôs Pixtral 12B and Meta‚Äôs Llama 3.2 11B and 90B vision models. We got audio input and output from OpenAI in October, then November saw SmolVLM from Hugging Face and December saw image and video models from Amazon Nova. In October I upgraded my LLM CLI tool to support multi-modal models via attachments. It now has plugins for a whole collection of different vision models. I think people who complain that LLM improvement has slowed are often missing the enormous advances in these multi-modal models. Being able to run prompts against images (and audio and video) is a fascinating new way to apply these models. Voice and live camera mode are science fiction come to life The audio and live video modes that have started to emerge deserve a special mention. The ability to talk to ChatGPT first arrived in September 2023, but it was mostly an illusion: OpenAI used their excellent Whisper speech-to-text model and a new text-to-speech model (creatively named tts-1) to enable conversations with the ChatGPT mobile apps, but the actual model just saw text. The May 13th announcement of GPT-4o included a demo of a brand new voice mode, where the true multi-modal GPT-4o (the o is for ‚Äúomni‚Äù) model could accept audio input and output incredibly realistic sounding speech without needing separate TTS or STT models. The demo also sounded conspicuously similar to Scarlett Johansson... and after she complained the voice from the demo, Skye, never made it to a production product. The delay in releasing the new voice mode after the initial demo caused quite a lot of confusion. I wrote about that in ChatGPT in ‚Äú4o‚Äù mode is not running the new features yet. When ChatGPT Advanced Voice mode finally did roll out (a slow roll from August through September) it was spectacular. I‚Äôve been using it extensively on walks with my dog and it‚Äôs amazing how much the improvement in intonation elevates the material. I‚Äôve also had a lot of fun experimenting with the OpenAI audio APIs. Even more fun: Advanced Voice mode can do accents! Here‚Äôs what happened when I told it I need you to pretend to be a California brown pelican with a very thick Russian accent, but\"]",
                  "Improvements in LLM efficiency over the past year have significantly reduced both the environmental impact of AI model training and the cost of using large language models. As described, the dramatic collapse in the cost of running prompts through top-tier hosted LLMs is directly tied to increased efficiency and competition. For example, OpenAI‚Äôs GPT-4o is now 12 times cheaper than GPT-4, and other providers like Google and Anthropic offer even lower prices. This efficiency means that the energy cost per prompt has dropped, alleviating many concerns about the environmental impact of individual LLM usage. While the overall environmental impact of large-scale AI datacenter buildouts remains a concern, the energy required for each prompt is now much lower, making LLMs more accessible and environmentally sustainable. These trends are exemplified by the ability to process large datasets, such as generating descriptions for 68,000 photos, at a negligible cost and energy footprint.",
                  "multi_hop_abstract_query_synthesizer"
                ],
                [
                  "8",
                  "How has ChatGPT been discussed in relation to both its practical applications and its societal impact, including concerns about job displacement and ethical considerations, as reflected in the 2024 and 2023 blog posts and analytics?",
                  "['<1-hop>\\n\\nof very bad decisions are being made based on that hype. Being critical is a virtue. If we want people with decision-making authority to make good decisions about how to apply these tools we first need to acknowledge that there ARE good applications, and then help explain how to put those into practice while avoiding the many unintiutive traps. (If you still don‚Äôt think there are any good applications at all I‚Äôm not sure why you made it to this point in the article!) I think telling people that this whole field is environmentally catastrophic plagiarism machines that constantly make things up is doing those people a disservice, no matter how much truth that represents. There is genuine value to be had here, but getting to that value is unintuitive and needs guidance. Those of us who understand this stuff have a duty to help everyone else figure it out. Everything tagged ‚Äúllms‚Äù on my blog in 2024 Because I undoubtedly missed a whole bunch of things, here‚Äôs every long-form post I wrote in 2024 that I tagged with llms: January 7th: It‚Äôs OK to call it Artificial Intelligence 9th: What I should have said about the term Artificial Intelligence 17th: Talking about Open Source LLMs on Oxide and Friends 26th: LLM 0.13: The annotated release notes February 21st: The killer app of Gemini Pro 1.5 is video March 5th: Prompt injection and jailbreaking are not the same thing 8th: The GPT-4 barrier has finally been broken 22nd: Claude and ChatGPT for ad-hoc sidequests 23rd: Building and testing C extensions for SQLite with ChatGPT Code Interpreter 26th: llm cmd undo last git commit‚Äîa new plugin for LLM April 8th: Building files-to-prompt entirely using Claude 3 Opus 10th: Three major LLM releases in 24 hours (plus weeknotes) 17th: AI for Data Journalism: demonstrating what we can do with this stuff right now 22nd: Options for accessing Llama 3 from the terminal using LLM May 8th: Slop is the new name for unwanted AI-generated content 15th: ChatGPT in ‚Äú4o‚Äù mode is not running the new features yet 29th: Training is not the same as chatting: ChatGPT and other LLMs don‚Äôt remember everything you say June 6th: Accidental prompt injection against RAG applications 10th: Thoughts on the WWDC 2024 keynote on Apple Intelligence 17th: Language models on the command-line 21st: Building search-based RAG using Claude, Datasette and Val Town 27th: Open challenges for AI engineering July 14th: Imitation Intelligence, my keynote for PyCon US 2024 19th: Weeknotes: GPT-4o mini, LLM 0.15, sqlite-utils 3.37 and building a staging environment August 6th: Weeknotes: a staging environment, a Datasette alpha and a bunch of new LLMs 8th: django-http-debug, a new Django app mostly written by Claude 23rd: Claude‚Äôs API now supports CORS requests, enabling client-side applications 26th: Building a tool showing how Gemini Pro can return bounding boxes for objects in images September 6th: Calling LLMs from client-side JavaScript, converting PDFs to HTML + weeknotes 10th: Notes from my appearance on the Software Misadventures Podcast 12th: Notes on OpenAI‚Äôs new o1 chain-of-thought models 20th: Notes on using LLMs for code 29th: NotebookLM‚Äôs automatically generated podcasts are surprisingly effective 30th: Weeknotes: Three podcasts, two trips and a new plugin system October 1st: OpenAI DevDay 2024 live blog 2nd: OpenAI DevDay: Let‚Äôs build developer tools, not digital God 15th: ChatGPT will happily write you a thinly disguised horoscope 17th: Video scraping: extracting JSON data from a 35 second screen capture for less than 1/10th of a cent 18th: Experimenting with audio input and output for the OpenAI Chat Completion API 19th: Running Llama 3.2 Vision and Phi-3.5 Vision on a Mac with mistral.rs 21st: Everything I built with Claude Artifacts this week 22nd: Initial explorations of Anthropic‚Äôs new Computer Use capability 24th: Notes on the new Claude analysis JavaScript code execution tool 27th: Run a prompt to generate and execute jq programs using llm-jq 29th: You can now run prompts against images, audio and video in your terminal using LLM 30th: WÃ∂eÃ∂eÃ∂kÃ∂nÃ∂oÃ∂tÃ∂eÃ∂sÃ∂ Monthnotes for October November 4th: Claude 3.5 Haiku 7th: Project: VERDAD‚Äîtracking misinformation in radio broadcasts using Gemini 1.5 12th: Qwen2.5-Coder-32B is an LLM that can code well that runs on my Mac 19th: Notes from Bing Chat‚ÄîOur First Encounter With Manipulative AI 25th: Ask questions of SQLite databases and CSV/JSON files in your terminal December 4th: First impressions of the new Amazon Nova LLMs (via a new llm-bedrock plugin) 7th: Prompts.js 9th: I can now run a GPT-4 class model on my laptop 10th: ChatGPT Canvas can make API requests now, but it‚Äôs complicated 11th: Gemini 2.0 Flash: An outstanding multi-modal LLM with a sci-fi streaming mode 19th: Building Python tools with a one-shot prompt using uv run and Claude Projects 19th: Gemini 2.0 Flash ‚ÄúThinking mode‚Äù 20th: December in LLMs has been a lot 20th: Live blog: the 12th day of OpenAI‚Äî‚ÄúEarly evals for OpenAI o3‚Äù 24th: Trying out QvQ‚ÄîQwen‚Äôs new visual reasoning model 31st: Things we learned about LLMs in 2024 (This list generated using Django SQL Dashboard with a SQL query written for me by Claude.) Posted 31st December 2024 at 6:07 pm ¬∑ Follow me on Mastodon, Bluesky, Twitter or subscribe to my newsletter More recent articles Feed a video to a vision LLM as a sequence of JPEG frames on the CLI (also LLM 0.25) - 5th May 2025 Two publishers and three authors fail to understand what \"vibe coding\" means - 1st May 2025 Understanding the recent criticism of the Chatbot Arena - 30th April 2025 This is Things we learned about LLMs in 2024 by Simon Willison, posted on 31st December 2024. Part of series LLMs annual review Stuff we figured out about AI in 2023 - Dec. 31, 2023, 11:59 p.m. Things we learned about LLMs in 2024 - Dec. 31, 2024, 6:07 p.m. google 360 ai 1262 openai 289 generative-ai 1089 local-llms 113 llms 1076 anthropic 136 gemini 80 meta 32 llm-reasoning 44 long-context 15 ai-energy-usage 5 Next: Ending a year long posting streak Previous: Trying out', '<2-hop>\\n\\nMicrosoft over this issue. The 69 page PDF is genuinely worth reading‚Äîespecially the first few pages, which lay out the issues in a way that‚Äôs surprisingly easy to follow. The rest of the document includes some of the clearest explanations of what LLMs are, how they work and how they are built that I‚Äôve read anywhere. The legal arguments here are complex. I‚Äôm not a lawyer, but I don‚Äôt think this one will be easily decided. Whichever way it goes, I expect this case to have a profound impact on how this technology develops in the future. Law is not ethics. Is it OK to train models on people‚Äôs content without their permission, when those models will then be used in ways that compete with those people? As the quality of results produced by AI models has increased over the year, these questions have become even more pressing. The impact on human society in terms of these models is already huge, if difficult to objectively measure. People have certainly lost work to them‚Äîanecdotally, I‚Äôve seen this for copywriters, artists and translators. There are a great deal of untold stories here. I‚Äôm hoping 2024 sees significant amounts of dedicated journalism on this topic. My blog in 2023 Here‚Äôs a tag cloud for content I posted to my blog in 2023 (generated using Django SQL Dashboard): Tag cloud words in order of size: ai, generativeai, llms, openai, chatgpt, projects, python, datasette, ethics, llama, homebrewllms, sqlite, gpt3, promptengineering, promptinjection, llm, security, opensource, gpt4, weeknotes The top five: ai (342), generativeai (300), llms (287), openai (86), chatgpt (78). I‚Äôve written a lot about this stuff! I grabbed a screenshot of my Plausible analytics for the year, fed that to ChatGPT Vision, told it to extract the data into a table, then got it to mix in entry titles (from a SQL query it wrote) and produced this table with it. Here are my top entries this year by amount of traffic: Article Visitors Pageviews Bing: ‚ÄúI will not harm you unless you harm me first‚Äù 1.1M 1.3M Leaked Google document: ‚ÄúWe Have No Moat, And Neither Does OpenAI‚Äù 132k 162k Large language models are having their Stable Diffusion moment 121k 150k Prompt injection: What‚Äôs the worst that can happen? 79.8k 95.9k Embeddings: What they are and why they matter 61.7k 79.3k Catching up on the weird world of LLMs 61.6k 85.9k llamafile is the new best way to run an LLM on your own computer 52k 66k Prompt injection explained, with video, slides, and a transcript 51k 61.9k AI-enhanced development makes me more ambitious with my projects 49.6k 60.1k Understanding GPT tokenizers 49.5k 61.1k Exploring GPTs: ChatGPT in a trench coat? 46.4k 58.5k Could you train a ChatGPT-beating model for $85,000 and run it in a browser? 40.5k 49.2k How to implement Q&A against your documentation with GPT3, embeddings and Datasette 37.3k 44.9k Lawyer cites fake cases invented by ChatGPT, judge is not amused 37.1k 47.4k Now add a walrus: Prompt engineering in DALL-E 3 32.8k 41.2k Web LLM runs the vicuna-7b Large Language Model entirely in your browser, and it‚Äôs very impressive 32.5k 38.2k ChatGPT can‚Äôt access the internet, even though it really looks like it can 30.5k 34.2k Stanford Alpaca, and the acceleration of on-device large language model development 29.7k 35.7k Run Llama 2 on your own Mac using LLM and Homebrew 27.9k 33.6k Midjourney 5.1 26.7k 33.4k Think of language models like ChatGPT as a ‚Äúcalculator for words‚Äù 25k 31.8k Multi-modal prompt injection image attacks against GPT-4V 23.7k 27.4k I also gave a bunch of talks and podcast appearances. I‚Äôve started habitually turning my talks into annotated presentations‚Äîhere are my best from 2023: Prompt injection explained, with video, slides, and a transcript Catching up on the weird world of LLMs Making Large Language Models work for you Open questions for AI engineering Embeddings: What they are and why they matter Financial sustainability for open source projects at GitHub Universe And in podcasts: What AI can do for you on the Theory of Change Working in public on Path to Citus Con LLMs break the internet on the Changelog Talking Large Language Models on Rooftop Ruby Thoughts on the OpenAI board situation on Newsroom Robots Industry‚Äôs Tardy Response to the AI Prompt Injection Vulnerability on RedMonk Conversations Posted 31st December 2023 at 11:59 pm ¬∑ Follow me on Mastodon, Bluesky, Twitter or subscribe to my newsletter More recent articles Feed a video to a vision LLM as a sequence of JPEG frames on the CLI (also LLM 0.25) - 5th May 2025 Two publishers and three authors fail to understand what \"vibe coding\" means - 1st May 2025 Understanding the recent criticism of the Chatbot Arena - 30th April 2025 This is Stuff we figured out about AI in 2023 by Simon Willison, posted on 31st December 2023. Part of series LLMs annual review Stuff we figured out about AI in 2023 - Dec. 31, 2023, 11:59 p.m. Things we learned about LLMs in 2024 - Dec. 31, 2024, 6:07 p.m. blogging 105 ai 1262 generative-ai 1089 llms 1076 Next: Tom Scott, and the formidable power of escalating streaks Previous: Last weeknotes of 2023 Colophon ¬© 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 2025']",
                  "ChatGPT has been a recurring topic in blog posts and analytics throughout 2023 and 2024, reflecting both its practical applications and its broader societal impact. In 2024, ChatGPT was featured in discussions about ad-hoc sidequests, code interpretation, and its evolving features, such as the '4o' mode and the distinction between training and chatting. The blog highlights the need for critical evaluation of AI tools like ChatGPT, emphasizing that while there are unintuitive traps and potential for misuse, there is also genuine value that requires guidance to realize. Ethical concerns are raised, particularly regarding the training of models on people's content without permission and the resulting competition with human workers, which has led to job losses among copywriters, artists, and translators. The analytics from 2023 show that 'chatgpt' was among the top tags and most visited articles, including topics like 'Lawyer cites fake cases invented by ChatGPT' and 'ChatGPT can‚Äôt access the internet, even though it really looks like it can.' These entries illustrate both the capabilities and limitations of ChatGPT, as well as the legal and ethical debates surrounding its use. Overall, the blog posts and analytics demonstrate that ChatGPT is at the center of ongoing discussions about practical utility, ethical challenges, and its significant, if sometimes difficult to measure, impact on society.",
                  "multi_hop_specific_query_synthesizer"
                ],
                [
                  "9",
                  "Anthropic make LLMs, but what is problem with LLMs and what is needed to make them useful, Anthropic way?",
                  "['<1-hop>\\n\\nskeptical as to their utility based, once again, on the challenge of gullibility. LLMs believe anything you tell them. Any systems that attempts to make meaningful decisions on your behalf will run into the same roadblock: how good is a travel agent, or a digital assistant, or even a research tool if it can‚Äôt distinguish truth from fiction? Just the other day Google Search was caught serving up an entirely fake description of the non-existant movie ‚ÄúEncanto 2‚Äù. It turned out to be summarizing an imagined movie listing from a fan fiction wiki. Prompt injection is a natural consequence of this gulibility. I‚Äôve seen precious little progress on tackling that problem in 2024, and we‚Äôve been talking about it since September 2022. I‚Äôm beginning to see the most popular idea of ‚Äúagents‚Äù as dependent on AGI itself. A model that‚Äôs robust against gulliblity is a very tall order indeed. Evals really matter Anthropic‚Äôs Amanda Askell (responsible for much of the work behind Claude‚Äôs Character): The boring yet crucial secret behind good system prompts is test-driven development. You don‚Äôt write down a system prompt and find ways to test it. You write down tests and find a system prompt that passes them. It‚Äôs become abundantly clear over the course of 2024 that writing good automated evals for LLM-powered systems is the skill that‚Äôs most needed to build useful applications on top of these models. If you have a strong eval suite you can adopt new models faster, iterate better and build more reliable and useful product features than your competition. Vercel‚Äôs Malte Ubl: When @v0 first came out we were paranoid about protecting the prompt with all kinds of pre and post processing complexity. We completely pivoted to let it rip. A prompt without the evals, models, and especially UX is like getting a broken ASML machine without a manual I‚Äôm still trying to figure out the best patterns for doing this for my own work. Everyone knows that evals are important, but there remains a lack of great guidance for how to best implement them‚ÄîI‚Äôm tracking this under my evals tag. My SVG pelican riding a bicycle benchmark is a pale imitation of what a real eval suite should look like. Apple Intelligence is bad, Apple‚Äôs MLX library is excellent As a Mac user I‚Äôve been feeling a lot better about my choice of platform this year. Last year it felt like my lack of a Linux/Windows machine with an NVIDIA GPU was a huge disadvantage in terms of trying out new models. On paper, a 64GB Mac should be a great machine for running models due to the way the CPU and GPU can share the same memory. In practice, many models are released as model weights and libraries that reward NVIDIA‚Äôs CUDA over other platforms. The llama.cpp ecosystem helped a lot here, but the real breakthrough has been Apple‚Äôs MLX library, ‚Äúan array framework for Apple Silicon‚Äù. It‚Äôs fantastic. Apple‚Äôs mlx-lm Python library supports running a wide range of MLX-compatible models on my Mac, with excellent performance. mlx-community on Hugging Face offers more than 1,000 models that have been converted to the necessary format. Prince Canuma‚Äôs excellent, fast moving mlx-vlm project brings vision LLMs to Apple Silicon as well. I used that recently to run Qwen‚Äôs QvQ. While MLX is a game changer, Apple‚Äôs own ‚ÄúApple Intelligence‚Äù features have mostly been a disappointment. I wrote about their initial announcement in June, and I was optimistic that Apple had focused hard on the subset of LLM applications that preserve user privacy and minimize the chance of users getting mislead by confusing features. Now that those features are rolling out they‚Äôre pretty weak. As an LLM power-user I know what these models are capable of, and Apple‚Äôs LLM features offer a pale imitation of what a frontier LLM can do. Instead we‚Äôre getting notification summaries that misrepresent news headlines and writing assistant tools that I‚Äôve not found useful at all. Genmoji are kind of fun though. The rise of inference-scaling ‚Äúreasoning‚Äù models The most interesting development in the final quarter of 2024 was the introduction of a new shape of LLM, exemplified by OpenAI‚Äôs o1 models‚Äîinitially released as o1-preview and o1-mini on September 12th. One way to think about these models is an extension of the chain-of-thought prompting trick, first explored in the May 2022 paper Large Language Models are Zero-Shot Reasoners. This is that trick where, if you get a model to talk out loud about a problem it‚Äôs solving, you often get a result which the model would not have achieved otherwise. o1 takes this process and further bakes it into the model itself. The details are somewhat obfuscated: o1 models spend ‚Äúreasoning tokens‚Äù thinking through the problem that are not directly visible to the user (though the ChatGPT UI shows a summary of them), then outputs a final result. The biggest innovation here is that it opens up a new way to scale a model: instead of improving model performance purely through additional compute at training time, models can now take on harder problems by spending more compute on inference. The sequel to o1, o3 (they skipped ‚Äúo2‚Äù for European trademark reasons) was announced on 20th December with an impressive result against the ARC-AGI benchmark, albeit one that likely involved more than $1,000,000 of compute time expense! o3 is expected to ship in January. I doubt many people have real-world problems that would benefit from that level of compute expenditure‚ÄîI certainly don‚Äôt!‚Äîbut it appears to be a genuine next step in LLM architecture for taking on much harder problems. OpenAI are not the only game in town here. Google released their first entrant in the category, gemini-2.0-flash-thinking-exp, on December 19th. Alibaba‚Äôs Qwen team released their QwQ model on November 28th‚Äîunder an Apache 2.0 license, and that one I could run on my own machine. They followed that up with a vision reasoning model called QvQ on December 24th, which I also ran locally. DeepSeek made their DeepSeek-R1-Lite-Preview', '<2-hop>\\n\\nWe don‚Äôt yet know how to build GPT-4 Vibes Based Development LLMs are really smart, and also really, really dumb Gullibility is the biggest unsolved problem Code may be the best application The ethics of this space remain diabolically complex My blog in 2023 Here‚Äôs the sequel to this post: Things we learned about LLMs in 2024. Large Language Models In the past 24-36 months, our species has discovered that you can take a GIANT corpus of text, run it through a pile of GPUs, and use it to create a fascinating new kind of software. LLMs can do a lot of things. They can answer questions, summarize documents, translate from one language to another, extract information and even write surprisingly competent code. They can also help you cheat at your homework, generate unlimited streams of fake content and be used for all manner of nefarious purposes. So far, I think they‚Äôre a net positive. I‚Äôve used them on a personal level to improve my productivity (and entertain myself) in all sorts of different ways. I think people who learn how to use them effectively can gain a significant boost to their quality of life. A lot of people are yet to be sold on their value! Some think their negatives outweigh their positives, some think they are all hot air, and some even think they represent an existential threat to humanity. They‚Äôre actually quite easy to build The most surprising thing we‚Äôve learned about LLMs this year is that they‚Äôre actually quite easy to build. Intuitively, one would expect that systems this powerful would take millions of lines of complex code. Instead, it turns out a few hundred lines of Python is genuinely enough to train a basic version! What matters most is the training data. You need a lot of data to make these things work, and the quantity and quality of the training data appears to be the most important factor in how good the resulting model is. If you can gather the right data, and afford to pay for the GPUs to train it, you can build an LLM. A year ago, the only organization that had released a generally useful LLM was OpenAI. We‚Äôve now seen better-than-GPT-3 class models produced by Anthropic, Mistral, Google, Meta, EleutherAI, Stability AI, TII in Abu Dhabi (Falcon), Microsoft Research, xAI, Replit, Baidu and a bunch of other organizations. The training cost (hardware and electricity) is still significant‚Äîinitially millions of dollars, but that seems to have dropped to the tens of thousands already. Microsoft‚Äôs Phi-2 claims to have used ‚Äú14 days on 96 A100 GPUs‚Äù, which works out at around $35,000 using current Lambda pricing. So training an LLM still isn‚Äôt something a hobbyist can afford, but it‚Äôs no longer the sole domain of the super-rich. I like to compare the difficulty of training an LLM to that of building a suspension bridge‚Äînot trivial, but hundreds of countries around the world have figured out how to do it. (Correction: Wikipedia‚Äôs Suspension bridges by country category lists 44 countries). You can run LLMs on your own devices In January of this year, I thought it would be years before I could run a useful LLM on my own computer. GPT-3 and 3.5 were pretty much the only games in town, and I thought that even if the model weights were available it would take a $10,000+ server to run them. Then in February, Meta released Llama. And a few weeks later in March, Georgi Gerganov released code that got it working on a MacBook. I wrote about how Large language models are having their Stable Diffusion moment, and with hindsight that was a very good call! This unleashed a whirlwind of innovation, which was accelerated further in July when Meta released Llama 2‚Äîan improved version which, crucially, included permission for commercial use. Today there are literally thousands of LLMs that can be run locally, on all manner of different devices. I run a bunch of them on my laptop. I run Mistral 7B (a surprisingly great model) on my iPhone. You can install several different apps to get your own, local, completely private LLM. My own LLM project provides a CLI tool for running an array of different models via plugins. You can even run them entirely in your browser using WebAssembly and the latest Chrome! Hobbyists can build their own fine-tuned models I said earlier that building an LLM was still out of reach of hobbyists. That may be true for training from scratch, but fine-tuning one of those models is another matter entirely. There‚Äôs now a fascinating ecosystem of people training their own models on top of these foundations, publishing those models, building fine-tuning datasets and sharing those too. The Hugging Face Open LLM Leaderboard is one place that tracks these. I can‚Äôt even attempt to count them, and any count would be out-of-date within a few hours. The best overall openly licensed LLM at any time is rarely a foundation model: instead, it‚Äôs whichever fine-tuned community model has most recently discovered the best combination of fine-tuning data. This is a huge advantage for open over closed models: the closed, hosted models don‚Äôt have thousands of researchers and hobbyists around the world collaborating and competing to improve them. We don‚Äôt yet know how to build GPT-4 Frustratingly, despite the enormous leaps ahead we‚Äôve had this year, we are yet to see an alternative model that‚Äôs better than GPT-4. OpenAI released GPT-4 in March, though it later turned out we had a sneak peak of it in February when Microsoft used it as part of the new Bing. This may well change in the next few weeks: Google‚Äôs Gemini Ultra has big claims, but isn‚Äôt yet available for us to try out. The team behind Mistral are working to beat GPT-4 as well, and their track record is already extremely strong considering their first public model only came out in September, and they‚Äôve released two significant improvements since then. Still,']",
                  "Anthropic is one of the organizations that has produced better-than-GPT-3 class large language models (LLMs). A big problem with LLMs is gullibility‚Äîthey believe anything you tell them, which makes it hard for them to distinguish truth from fiction. This gullibility leads to issues like prompt injection and unreliable decision-making. According to Anthropic‚Äôs Amanda Askell, the key to making LLMs more useful is having strong automated evaluation (eval) suites. Instead of just writing system prompts and testing them, you should write tests first and then create prompts that pass those tests. Good evals help you adopt new models faster, iterate better, and build more reliable and useful product features.",
                  "multi_hop_specific_query_synthesizer"
                ],
                [
                  "10",
                  "How did Meta's Llama 3.3 70B utilize synthetic data in its fine-tuning, and what does its ability to run on a personal laptop reveal about recent advances in large language model efficiency?",
                  "['<1-hop>\\n\\nof the best descriptions I‚Äôve seen of this comes from the Phi-4 technical report, which included this: Synthetic data as a substantial component of pretraining is becoming increasingly common, and the Phi series of models has consistently emphasized the importance of synthetic data. Rather than serving as a cheap substitute for organic data, synthetic data has several direct advantages over organic data. Structured and Gradual Learning. In organic datasets, the relationship between tokens is often complex and indirect. Many reasoning steps may be required to connect the current token to the next, making it challenging for the model to learn effectively from next-token prediction. By contrast, each token generated by a language model is by definition predicted by the preceding tokens, making it easier for a model to follow the resulting reasoning patterns. Another common technique is to use larger models to help create training data for their smaller, cheaper alternatives‚Äîa trick used by an increasing number of labs. DeepSeek v3 used ‚Äúreasoning‚Äù data created by DeepSeek-R1. Meta‚Äôs Llama 3.3 70B fine-tuning used over 25M synthetically generated examples. Careful design of the training data that goes into an LLM appears to be the entire game for creating these models. The days of just grabbing a full scrape of the web and indiscriminately dumping it into a training run are long gone. LLMs somehow got even harder to use A drum I‚Äôve been banging for a while is that LLMs are power-user tools‚Äîthey‚Äôre chainsaws disguised as kitchen knives. They look deceptively simple to use‚Äîhow hard can it be to type messages to a chatbot?‚Äîbut in reality you need a huge depth of both understanding and experience to make the most of them and avoid their many pitfalls. If anything, this problem got worse in 2024. We‚Äôve built computer systems you can talk to in human language, that will answer your questions and usually get them right! ... depending on the question, and how you ask it, and whether it‚Äôs accurately reflected in the undocumented and secret training set. The number of available systems has exploded. Different systems have different tools they can apply to your problems‚Äîlike Python and JavaScript and web search and image generation and maybe even database lookups... so you‚Äôd better understand what those tools are, what they can do and how to tell if the LLM used them or not. Did you know ChatGPT has two entirely different ways of running Python now? Want to build a Claude Artifact that talks to an external API? You‚Äôd better understand CSP and CORS HTTP headers first. The models may have got more capable, but most of the limitations remained the same. OpenAI‚Äôs o1 may finally be able to (mostly) count the Rs in strawberry, but its abilities are still limited by its nature as an LLM and the constraints placed on it by the harness it‚Äôs running in. o1 can‚Äôt run web searches or use Code Interpreter, but GPT-4o can‚Äîboth in that same ChatGPT UI. (o1 will pretend to do those things if you ask it to, a regression to the URL hallucinations bug from early 2023). What are we doing about this? Not much. Most users are thrown in at the deep end. The default LLM chat UI is like taking brand new computer users, dropping them into a Linux terminal and expecting them to figure it all out. Meanwhile, it‚Äôs increasingly common for end users to develop wildly inaccurate mental models of how these things work and what they are capable of. I‚Äôve seen so many examples of people trying to win an argument with a screenshot from ChatGPT‚Äîan inherently ludicrous proposition, given the inherent unreliability of these models crossed with the fact that you can get them to say anything if you prompt them right. There‚Äôs a flipside to this too: a lot of better informed people have sworn off LLMs entirely because they can‚Äôt see how anyone could benefit from a tool with so many flaws. The key skill in getting the most out of LLMs is learning to work with tech that is both inherently unreliable and incredibly powerful at the same time. This is a decidedly non-obvious skill to acquire! There is so much space for helpful education content here, but we need to do do a lot better than outsourcing it all to AI grifters with bombastic Twitter threads. Knowledge is incredibly unevenly distributed Most people have heard of ChatGPT by now. How many have heard of Claude? The knowledge gap between the people who actively follow this stuff and the 99% of the population who do not is vast. The pace of change doesn‚Äôt help either. In just the past month we‚Äôve seen general availability of live interfaces where you can point your phone‚Äôs camera at something and talk about it with your voice... and optionally have it pretend to be Santa. Most self-certified nerds haven‚Äôt even tried that yet. Given the ongoing (and potential) impact on society that this technology has, I don‚Äôt think the size of this gap is healthy. I‚Äôd like to see a lot more effort put into improving this. LLMs need better criticism A lot of people absolutely hate this stuff. In some of the spaces I hang out (Mastodon, Bluesky, Lobste.rs, even Hacker News on occasion) even suggesting that ‚ÄúLLMs are useful‚Äù can be enough to kick off a huge fight. I get it. There are plenty of reasons to dislike this technology‚Äîthe environmental impact, the (lack of) ethics of the training data, the lack of reliability, the negative applications, the potential impact on people‚Äôs jobs. LLMs absolutely warrant criticism. We need to be talking through these problems, finding ways to mitigate them and helping people learn how to use these tools responsibly in ways where the positive applications outweigh the negative. I like people who are skeptical of this stuff. The hype has been deafening for more than two years now, and there are enormous quantities of snake oil and misinformation out there. A lot', '<2-hop>\\n\\nThe rise of inference-scaling ‚Äúreasoning‚Äù models Was the best currently available LLM trained in China for less than $6m? The environmental impact got better The environmental impact got much, much worse The year of slop Synthetic training data works great LLMs somehow got even harder to use Knowledge is incredibly unevenly distributed LLMs need better criticism Everything tagged ‚Äúllms‚Äù on my blog in 2024 The GPT-4 barrier was comprehensively broken In my December 2023 review I wrote about how We don‚Äôt yet know how to build GPT-4‚ÄîOpenAI‚Äôs best model was almost a year old at that point, yet no other AI lab had produced anything better. What did OpenAI know that the rest of us didn‚Äôt? I‚Äôm relieved that this has changed completely in the past twelve months. 18 organizations now have models on the Chatbot Arena Leaderboard that rank higher than the original GPT-4 from March 2023 (GPT-4-0314 on the board)‚Äî70 models in total. Screenshot of a comparison table showing AI model rankings. Table headers: Rank (UB), Rank (StyleCtrl), Model, Arena Score, 95% CI, Votes, Organization, License. Shows 12 models including GLM-4-0520, Llama-3-70B-Instruct, Gemini-1.5-Flash-8B-Exp-0827, with rankings, scores, and licensing details. Models range from rank 52-69 with Arena scores between 1186-1207. The earliest of those was Google‚Äôs Gemini 1.5 Pro, released in February. In addition to producing GPT-4 level outputs, it introduced several brand new capabilities to the field‚Äîmost notably its 1 million (and then later 2 million) token input context length, and the ability to input video. I wrote about this at the time in The killer app of Gemini Pro 1.5 is video, which earned me a short appearance as a talking head in the Google I/O opening keynote in May. Gemini 1.5 Pro also illustrated one of the key themes of 2024: increased context lengths. Last year most models accepted 4,096 or 8,192 tokens, with the notable exception of Claude 2.1 which accepted 200,000. Today every serious provider has a 100,000+ token model, and Google‚Äôs Gemini series accepts up to 2 million. Longer inputs dramatically increase the scope of problems that can be solved with an LLM: you can now throw in an entire book and ask questions about its contents, but more importantly you can feed in a lot of example code to help the model correctly solve a coding problem. LLM use-cases that involve long inputs are far more interesting to me than short prompts that rely purely on the information already baked into the model weights. Many of my tools were built using this pattern. Getting back to models that beat GPT-4: Anthropic‚Äôs Claude 3 series launched in March, and Claude 3 Opus quickly became my new favourite daily-driver. They upped the ante even more in June with the launch of Claude 3.5 Sonnet‚Äîa model that is still my favourite six months later (though it got a significant upgrade on October 22, confusingly keeping the same 3.5 version number. Anthropic fans have since taken to calling it Claude 3.6). Then there‚Äôs the rest. If you browse the Chatbot Arena leaderboard today‚Äîstill the most useful single place to get a vibes-based evaluation of models‚Äîyou‚Äôll see that GPT-4-0314 has fallen to around 70th place. The 18 organizations with higher scoring models are Google, OpenAI, Alibaba, Anthropic, Meta, Reka AI, 01 AI, Amazon, Cohere, DeepSeek, Nvidia, Mistral, NexusFlow, Zhipu AI, xAI, AI21 Labs, Princeton and Tencent. Training a GPT-4 beating model was a huge deal in 2023. In 2024 it‚Äôs an achievement that isn‚Äôt even particularly notable, though I personally still celebrate any time a new organization joins that list. Some of those GPT-4 models run on my laptop My personal laptop is a 64GB M2 MacBook Pro from 2023. It‚Äôs a powerful machine, but it‚Äôs also nearly two years old now‚Äîand crucially it‚Äôs the same laptop I‚Äôve been using ever since I first ran an LLM on my computer back in March 2023 (see Large language models are having their Stable Diffusion moment). That same laptop that could just about run a GPT-3-class model in March last year has now run multiple GPT-4 class models! Some of my notes on that: Qwen2.5-Coder-32B is an LLM that can code well that runs on my Mac talks about Qwen2.5-Coder-32B in November‚Äîan Apache 2.0 licensed model! I can now run a GPT-4 class model on my laptop talks about running Meta‚Äôs Llama 3.3 70B (released in December) This remains astonishing to me. I thought a model with the capabilities and output quality of GPT-4 needed a datacenter class server with one or more $40,000+ GPUs. These models take up enough of my 64GB of RAM that I don‚Äôt run them often‚Äîthey don‚Äôt leave much room for anything else. The fact that they run at all is a testament to the incredible training and inference performance gains that we‚Äôve figured out over the past year. It turns out there was a lot of low-hanging fruit to be harvested in terms of model efficiency. I expect there‚Äôs still more to come. Meta‚Äôs Llama 3.2 models deserve a special mention. They may not be GPT-4 class, but at 1B and 3B sizes they punch massively above their weight. I run Llama 3.2 3B on my iPhone using the free MLC Chat iOS app and it‚Äôs a shockingly capable model for its tiny (<2GB) size. Try firing it up and asking it for ‚Äúa plot outline of a Netflix Christmas movie where a data journalist falls in love with a local ceramacist‚Äù. Here‚Äôs what I got, at a respectable 20 tokens per second: MLC Chat: Llama - [System] Ready to chat. a plot outline of a Netflix Christmas movie where a data journalist falls in love with a local ceramacist. Show as Markdown is turned on. Here\\'s a plot outline for a Netflix Christmas movie: Title: \"Love in the Clay\" Plot Outline: We meet our protagonist, JESSICA, a data journalist who has just returned to her hometown of Willow Creek, a small, charming town nestled in the snow-covered mountains. She\\'s back to work']",
                  "Meta's Llama 3.3 70B fine-tuning process incorporated over 25 million synthetically generated examples, highlighting the growing importance and advantages of synthetic data in training large language models. This approach allows for more structured and gradual learning compared to organic datasets. Additionally, the fact that Llama 3.3 70B‚Äîa model with GPT-4 class capabilities‚Äîcan now run on a personal laptop with 64GB of RAM demonstrates significant recent advances in model efficiency and inference performance. These improvements have made it possible to operate highly capable models outside of datacenter-class servers, reflecting major progress in the field.",
                  "multi_hop_specific_query_synthesizer"
                ],
                [
                  "11",
                  "What are some recent advanced features introduced in ChatGPT, and how do they compare to similar capabilities in competing models like Google Gemini?",
                  "['<1-hop>\\n\\nof the best descriptions I‚Äôve seen of this comes from the Phi-4 technical report, which included this: Synthetic data as a substantial component of pretraining is becoming increasingly common, and the Phi series of models has consistently emphasized the importance of synthetic data. Rather than serving as a cheap substitute for organic data, synthetic data has several direct advantages over organic data. Structured and Gradual Learning. In organic datasets, the relationship between tokens is often complex and indirect. Many reasoning steps may be required to connect the current token to the next, making it challenging for the model to learn effectively from next-token prediction. By contrast, each token generated by a language model is by definition predicted by the preceding tokens, making it easier for a model to follow the resulting reasoning patterns. Another common technique is to use larger models to help create training data for their smaller, cheaper alternatives‚Äîa trick used by an increasing number of labs. DeepSeek v3 used ‚Äúreasoning‚Äù data created by DeepSeek-R1. Meta‚Äôs Llama 3.3 70B fine-tuning used over 25M synthetically generated examples. Careful design of the training data that goes into an LLM appears to be the entire game for creating these models. The days of just grabbing a full scrape of the web and indiscriminately dumping it into a training run are long gone. LLMs somehow got even harder to use A drum I‚Äôve been banging for a while is that LLMs are power-user tools‚Äîthey‚Äôre chainsaws disguised as kitchen knives. They look deceptively simple to use‚Äîhow hard can it be to type messages to a chatbot?‚Äîbut in reality you need a huge depth of both understanding and experience to make the most of them and avoid their many pitfalls. If anything, this problem got worse in 2024. We‚Äôve built computer systems you can talk to in human language, that will answer your questions and usually get them right! ... depending on the question, and how you ask it, and whether it‚Äôs accurately reflected in the undocumented and secret training set. The number of available systems has exploded. Different systems have different tools they can apply to your problems‚Äîlike Python and JavaScript and web search and image generation and maybe even database lookups... so you‚Äôd better understand what those tools are, what they can do and how to tell if the LLM used them or not. Did you know ChatGPT has two entirely different ways of running Python now? Want to build a Claude Artifact that talks to an external API? You‚Äôd better understand CSP and CORS HTTP headers first. The models may have got more capable, but most of the limitations remained the same. OpenAI‚Äôs o1 may finally be able to (mostly) count the Rs in strawberry, but its abilities are still limited by its nature as an LLM and the constraints placed on it by the harness it‚Äôs running in. o1 can‚Äôt run web searches or use Code Interpreter, but GPT-4o can‚Äîboth in that same ChatGPT UI. (o1 will pretend to do those things if you ask it to, a regression to the URL hallucinations bug from early 2023). What are we doing about this? Not much. Most users are thrown in at the deep end. The default LLM chat UI is like taking brand new computer users, dropping them into a Linux terminal and expecting them to figure it all out. Meanwhile, it‚Äôs increasingly common for end users to develop wildly inaccurate mental models of how these things work and what they are capable of. I‚Äôve seen so many examples of people trying to win an argument with a screenshot from ChatGPT‚Äîan inherently ludicrous proposition, given the inherent unreliability of these models crossed with the fact that you can get them to say anything if you prompt them right. There‚Äôs a flipside to this too: a lot of better informed people have sworn off LLMs entirely because they can‚Äôt see how anyone could benefit from a tool with so many flaws. The key skill in getting the most out of LLMs is learning to work with tech that is both inherently unreliable and incredibly powerful at the same time. This is a decidedly non-obvious skill to acquire! There is so much space for helpful education content here, but we need to do do a lot better than outsourcing it all to AI grifters with bombastic Twitter threads. Knowledge is incredibly unevenly distributed Most people have heard of ChatGPT by now. How many have heard of Claude? The knowledge gap between the people who actively follow this stuff and the 99% of the population who do not is vast. The pace of change doesn‚Äôt help either. In just the past month we‚Äôve seen general availability of live interfaces where you can point your phone‚Äôs camera at something and talk about it with your voice... and optionally have it pretend to be Santa. Most self-certified nerds haven‚Äôt even tried that yet. Given the ongoing (and potential) impact on society that this technology has, I don‚Äôt think the size of this gap is healthy. I‚Äôd like to see a lot more effort put into improving this. LLMs need better criticism A lot of people absolutely hate this stuff. In some of the spaces I hang out (Mastodon, Bluesky, Lobste.rs, even Hacker News on occasion) even suggesting that ‚ÄúLLMs are useful‚Äù can be enough to kick off a huge fight. I get it. There are plenty of reasons to dislike this technology‚Äîthe environmental impact, the (lack of) ethics of the training data, the lack of reliability, the negative applications, the potential impact on people‚Äôs jobs. LLMs absolutely warrant criticism. We need to be talking through these problems, finding ways to mitigate them and helping people learn how to use these tools responsibly in ways where the positive applications outweigh the negative. I like people who are skeptical of this stuff. The hype has been deafening for more than two years now, and there are enormous quantities of snake oil and misinformation out there. A lot', '<2-hop>\\n\\nyou talk to me exclusively in Spanish. OpenAI aren‚Äôt the only group with a multi-modal audio model. Google‚Äôs Gemini also accepts audio input, and the Google Gemini apps can speak in a similar way to ChatGPT now. Amazon also pre-announced voice mode for Amazon Nova, but that‚Äôs meant to roll out in Q1 of 2025. Google‚Äôs NotebookLM, released in September, took audio output to a new level by producing spookily realistic conversations between two ‚Äúpodcast hosts‚Äù about anything you fed into their tool. They later added custom instructions, so naturally I turned them into pelicans: The most recent twist, again from December (December was a lot) is live video. ChatGPT voice mode now provides the option to share your camera feed with the model and talk about what you can see in real time. Google Gemini have a preview of the same feature, which they managed to ship the day before ChatGPT did. These abilities are just a few weeks old at this point, and I don‚Äôt think their impact has been fully felt yet. If you haven‚Äôt tried them out yet you really should. Both Gemini and OpenAI offer API access to these features as well. OpenAI started with a WebSocket API that was quite challenging to use, but in December they announced a new WebRTC API which is much easier to get started with. Building a web app that a user can talk to via voice is easy now! Prompt driven app generation is a commodity already This was possible with GPT-4 in 2023, but the value it provides became evident in 2024. We already knew LLMs were spookily good at writing code. If you prompt them right, it turns out they can build you a full interactive application using HTML, CSS and JavaScript (and tools like React if you wire up some extra supporting build mechanisms)‚Äîoften in a single prompt. Anthropic kicked this idea into high gear when they released Claude Artifacts, a groundbreaking new feature that was initially slightly lost in the noise due to being described half way through their announcement of the incredible Claude 3.5 Sonnet. With Artifacts, Claude can write you an on-demand interactive application and then let you use it directly inside the Claude interface. Here‚Äôs my Extract URLs app, entirely generated by Claude: Extract URLs tool. Content pasted. URLs extracted. Shows a list of extracted URLs. I‚Äôve found myself using this a lot. I noticed how much I was relying on it in October and wrote Everything I built with Claude Artifacts this week, describing 14 little tools I had put together in a seven day period. Since then, a whole bunch of other teams have built similar systems. GitHub announced their version of this‚ÄîGitHub Spark‚Äîin October. Mistral Chat added it as a feature called Canvas in November. Steve Krouse from Val Town built a version of it against Cerebras, showcasing how a 2,000 token/second LLM can iterate on an application with changes visible in less than a second. Then in December, the Chatbot Arena team introduced a whole new leaderboard for this feature, driven by users building the same interactive app twice with two different models and voting on the answer. Hard to come up with a more convincing argument that this feature is now a commodity that can be effectively implemented against all of the leading models. I‚Äôve been tinkering with a version of this myself for my Datasette project, with the goal of letting users use prompts to build and iterate on custom widgets and data visualizations against their own data. I also figured out a similar pattern for writing one-shot Python programs, enabled by uv. This prompt-driven custom interface feature is so powerful and easy to build (once you‚Äôve figured out the gnarly details of browser sandboxing) that I expect it to show up as a feature in a wide range of products in 2025. Universal access to the best models lasted for just a few short months For a few short months this year all three of the best available models‚ÄîGPT-4o, Claude 3.5 Sonnet and Gemini 1.5 Pro‚Äîwere freely available to most of the world. OpenAI made GPT-4o free for all users in May, and Claude 3.5 Sonnet was freely available from its launch in June. This was a momentus change, because for the previous year free users had mostly been restricted to GPT-3.5 level models, meaning new users got a very inaccurate mental model of what a capable LLM could actually do. That era appears to have ended, likely permanently, with OpenAI‚Äôs launch of ChatGPT Pro. This $200/month subscription service is the only way to access their most capable model, o1 Pro. Since the trick behind the o1 series (and the future models it will undoubtedly inspire) is to expend more compute time to get better results, I don‚Äôt think those days of free access to the best available models are likely to return. ‚ÄúAgents‚Äù still haven‚Äôt really happened yet I find the term ‚Äúagents‚Äù extremely frustrating. It lacks a single, clear and widely understood meaning... but the people who use the term never seem to acknowledge that. If you tell me that you are building ‚Äúagents‚Äù, you‚Äôve conveyed almost no information to me at all. Without reading your mind I have no way of telling which of the dozens of possible definitions you are talking about. The two main categories I see are people who think AI agents are obviously things that go and act on your behalf‚Äîthe travel agent model‚Äîand people who think in terms of LLMs that have been given access to tools which they can run in a loop as part of solving a problem. The term ‚Äúautonomy‚Äù is often thrown into the mix too, again without including a clear definition. (I also collected 211 definitions on Twitter a few months ago‚Äîhere they are in Datasette Lite‚Äîand had gemini-exp-1206 attempt to summarize them.) Whatever the term may mean, agents still have that feeling of perpetually ‚Äúcoming soon‚Äù. Terminology aside, I remain']",
                  "Recent advanced features introduced in ChatGPT include a voice mode that allows users to share their camera feed and have real-time conversations about what they see, as well as the ability to interact via voice. These features enable live video and audio interactions with the model. Google Gemini has introduced similar capabilities, such as accepting audio input and providing spoken responses, and also previewed live video features around the same time as ChatGPT. Both OpenAI and Google now offer API access to these multi-modal features, making it easier for developers to build applications that leverage voice and video interactions. While Amazon has announced a voice mode for Amazon Nova, it is scheduled for release in 2025. Overall, ChatGPT and Google Gemini are closely matched in rolling out these advanced multi-modal features, with both platforms providing users and developers with new ways to interact beyond text.",
                  "multi_hop_specific_query_synthesizer"
                ]
              ],
              "shape": {
                "columns": 4,
                "rows": 12
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_input</th>\n",
              "      <th>reference_contexts</th>\n",
              "      <th>reference</th>\n",
              "      <th>synthesizer_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Which organizations, including Stability AI, h...</td>\n",
              "      <td>[We don‚Äôt yet know how to build GPT-4 Vibes Ba...</td>\n",
              "      <td>Organizations that have produced better-than-G...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How does the use of Python by large language m...</td>\n",
              "      <td>[I‚Äôm surprised that no-one has beaten the now ...</td>\n",
              "      <td>According to the context, writing code is one ...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Wut is AI?</td>\n",
              "      <td>[Simon Willison‚Äôs Weblog Subscribe Stuff we fi...</td>\n",
              "      <td>AI refers to Large Language Models, which are ...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Whaat is the signifficance of OpenAI in the co...</td>\n",
              "      <td>[Microsoft over this issue. The 69 page PDF is...</td>\n",
              "      <td>According to the blog's 2023 tag cloud, 'opena...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Considering the applications of LLMs such as c...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nWe don‚Äôt yet know how to build GPT...</td>\n",
              "      <td>The rise of LLMs has significantly impacted so...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>How have large language models impacted softwa...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nWe don‚Äôt yet know how to build GPT...</td>\n",
              "      <td>Large language models (LLMs) have significantl...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>How does the use of synthetic training data pr...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nThe rise of inference-scaling ‚Äúrea...</td>\n",
              "      <td>Synthetic training data offers several direct ...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>How have improvements in LLM efficiency over t...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nThe rise of inference-scaling ‚Äúrea...</td>\n",
              "      <td>Improvements in LLM efficiency over the past y...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>How has ChatGPT been discussed in relation to ...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nof very bad decisions are being ma...</td>\n",
              "      <td>ChatGPT has been a recurring topic in blog pos...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Anthropic make LLMs, but what is problem with ...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nskeptical as to their utility base...</td>\n",
              "      <td>Anthropic is one of the organizations that has...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>How did Meta's Llama 3.3 70B utilize synthetic...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nof the best descriptions I‚Äôve seen...</td>\n",
              "      <td>Meta's Llama 3.3 70B fine-tuning process incor...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>What are some recent advanced features introdu...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nof the best descriptions I‚Äôve seen...</td>\n",
              "      <td>Recent advanced features introduced in ChatGPT...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           user_input  \\\n",
              "0   Which organizations, including Stability AI, h...   \n",
              "1   How does the use of Python by large language m...   \n",
              "2                                          Wut is AI?   \n",
              "3   Whaat is the signifficance of OpenAI in the co...   \n",
              "4   Considering the applications of LLMs such as c...   \n",
              "5   How have large language models impacted softwa...   \n",
              "6   How does the use of synthetic training data pr...   \n",
              "7   How have improvements in LLM efficiency over t...   \n",
              "8   How has ChatGPT been discussed in relation to ...   \n",
              "9   Anthropic make LLMs, but what is problem with ...   \n",
              "10  How did Meta's Llama 3.3 70B utilize synthetic...   \n",
              "11  What are some recent advanced features introdu...   \n",
              "\n",
              "                                   reference_contexts  \\\n",
              "0   [We don‚Äôt yet know how to build GPT-4 Vibes Ba...   \n",
              "1   [I‚Äôm surprised that no-one has beaten the now ...   \n",
              "2   [Simon Willison‚Äôs Weblog Subscribe Stuff we fi...   \n",
              "3   [Microsoft over this issue. The 69 page PDF is...   \n",
              "4   [<1-hop>\\n\\nWe don‚Äôt yet know how to build GPT...   \n",
              "5   [<1-hop>\\n\\nWe don‚Äôt yet know how to build GPT...   \n",
              "6   [<1-hop>\\n\\nThe rise of inference-scaling ‚Äúrea...   \n",
              "7   [<1-hop>\\n\\nThe rise of inference-scaling ‚Äúrea...   \n",
              "8   [<1-hop>\\n\\nof very bad decisions are being ma...   \n",
              "9   [<1-hop>\\n\\nskeptical as to their utility base...   \n",
              "10  [<1-hop>\\n\\nof the best descriptions I‚Äôve seen...   \n",
              "11  [<1-hop>\\n\\nof the best descriptions I‚Äôve seen...   \n",
              "\n",
              "                                            reference  \\\n",
              "0   Organizations that have produced better-than-G...   \n",
              "1   According to the context, writing code is one ...   \n",
              "2   AI refers to Large Language Models, which are ...   \n",
              "3   According to the blog's 2023 tag cloud, 'opena...   \n",
              "4   The rise of LLMs has significantly impacted so...   \n",
              "5   Large language models (LLMs) have significantl...   \n",
              "6   Synthetic training data offers several direct ...   \n",
              "7   Improvements in LLM efficiency over the past y...   \n",
              "8   ChatGPT has been a recurring topic in blog pos...   \n",
              "9   Anthropic is one of the organizations that has...   \n",
              "10  Meta's Llama 3.3 70B fine-tuning process incor...   \n",
              "11  Recent advanced features introduced in ChatGPT...   \n",
              "\n",
              "                        synthesizer_name  \n",
              "0   single_hop_specifc_query_synthesizer  \n",
              "1   single_hop_specifc_query_synthesizer  \n",
              "2   single_hop_specifc_query_synthesizer  \n",
              "3   single_hop_specifc_query_synthesizer  \n",
              "4   multi_hop_abstract_query_synthesizer  \n",
              "5   multi_hop_abstract_query_synthesizer  \n",
              "6   multi_hop_abstract_query_synthesizer  \n",
              "7   multi_hop_abstract_query_synthesizer  \n",
              "8   multi_hop_specific_query_synthesizer  \n",
              "9   multi_hop_specific_query_synthesizer  \n",
              "10  multi_hop_specific_query_synthesizer  \n",
              "11  multi_hop_specific_query_synthesizer  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset.to_csv('./data/dataset.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ni4Q14_arJYw"
      },
      "source": [
        "## LangChain RAG\n",
        "\n",
        "Now we'll construct our LangChain RAG, which we will be evaluating using the above created test data!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGy99jkVrVqX"
      },
      "source": [
        "### R - Retrieval\n",
        "\n",
        "Let's start with building our retrieval pipeline, which will involve loading the same data we used to create our synthetic test set above.\n",
        "\n",
        "> NOTE: We need to use the same data - as our test set is specifically designed for this data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "847933Htono8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
            "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n"
          ]
        }
      ],
      "source": [
        "path = \"data/\"\n",
        "loader = DirectoryLoader(path, glob=\"*.html\")\n",
        "docs = loader.load()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQv3Psil_D2A"
      },
      "source": [
        "Now that we have our data loaded, let's split it into chunks!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2U0eJ_prZhL",
        "outputId": "56070084-f147-4dbc-ea52-1d04196e65c0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "75"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "split_documents = text_splitter.split_documents(docs)\n",
        "len(split_documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Question: \n",
        "\n",
        "What is the purpose of the `chunk_overlap` parameter in the `RecursiveCharacterTextSplitter`?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `chunk_overlap` parameter in the `RecursiveCharacterTextSplitter` serves a crucial purpose in preserving context across adjacent chunks.\n",
        "\n",
        "**Purpose of `chunk_overlap`:**\n",
        "\n",
        "* **Maintains continuity** between adjacent text chunks\n",
        "* **Reduces the risk of context loss** when splitting long documents\n",
        "* Ensures that **overlapping information** (e.g., an important sentence or phrase that spans two chunks) is **present in both chunks**\n",
        "* Improves **retrieval and generation quality** in RAG pipelines, especially when working with embeddings that rely on semantic coherence\n",
        "\n",
        "**Example:**\n",
        "\n",
        "If you have:\n",
        "\n",
        "* `chunk_size = 1000`\n",
        "* `chunk_overlap = 200`\n",
        "\n",
        "Then:\n",
        "\n",
        "* Chunk 1 spans characters 0‚Äì999\n",
        "* Chunk 2 spans characters 800‚Äì1799 (i.e., 200-character overlap with Chunk 1)\n",
        "\n",
        "This overlap helps ensure that the **semantic glue between chunks** (e.g., sentences that start at the end of one chunk and finish at the beginning of another) is preserved during embedding and retrieval."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Factors to Consider**\n",
        "\n",
        "+ **1. LLM Context Window**\n",
        "\n",
        "  * Use chunk sizes **well below the model's token limit** to leave room for the prompt, context headers, and system messages.\n",
        "  * For example:\n",
        "\n",
        "    * `gpt-3.5-turbo`: \\~4,096 tokens ‚Üí Safe chunk size: **512‚Äì1,000 tokens**\n",
        "    * `gpt-4o` / `gpt-4`: \\~128k tokens ‚Üí Can handle **larger chunks**, up to 2,000‚Äì4,000 tokens if needed\n",
        "\n",
        "+ **2. Document Type**\n",
        "\n",
        "  | Document Type         | Recommended Chunk Size | Chunk Overlap | Reason                                         |\n",
        "  | --------------------- | ---------------------- | ------------- | ---------------------------------------------- |\n",
        "  | Legal contracts       | 512‚Äì1,024 chars        | 100‚Äì200       | Dense, needs precision                         |\n",
        "  | Web pages / Blogs     | 1,000‚Äì1,500 chars      | 200‚Äì300       | Semi-structured                                |\n",
        "  | Research papers       | 800‚Äì1,200 chars        | 150‚Äì200       | Technical language                             |\n",
        "  | Transcripts / Dialog  | 512‚Äì1,000 chars        | 100‚Äì300       | Important back-references                      |\n",
        "  | Code / Technical Docs | 300‚Äì800 chars          | 100‚Äì200       | Functions or classes often span multiple lines |\n",
        "\n",
        "+ **3. Embedding Model Limit**\n",
        "\n",
        "  * Some models (e.g., `text-embedding-3-small`) max out at 8,192 tokens; prefer **shorter chunks (512‚Äì768 tokens)** to ensure reliable embedding quality.\n",
        "\n",
        "---\n",
        "\n",
        "**General Best Practices**\n",
        "\n",
        "| Parameter         | Recommendation                                                               |\n",
        "| ----------------- | ---------------------------------------------------------------------------- |\n",
        "| `chunk_size`      | 500‚Äì1,500 characters for most cases                                          |\n",
        "| `chunk_overlap`   | 10‚Äì30% of chunk\\_size (e.g., 200 overlap for 1,000 chunk)                    |\n",
        "| Ensure boundaries | Split on semantic boundaries (sentences or paragraphs) using smart splitters |\n",
        "\n",
        "---\n",
        "\n",
        "**Example Configuration in LangChain**\n",
        "\n",
        "```python\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=200,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"]\n",
        ")\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EcbmBBC_G2s"
      },
      "source": [
        "Next up, we'll need to provide an embedding model that we can use to construct our vector store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "KY_CNAbfr9sY"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AP_VDgyx_MPq"
      },
      "source": [
        "Now we can build our in memory QDrant vector store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "AoxImnLJsC4Q"
      },
      "outputs": [],
      "source": [
        "from langchain_qdrant import QdrantVectorStore\n",
        "from qdrant_client import QdrantClient\n",
        "from qdrant_client.http.models import Distance, VectorParams\n",
        "\n",
        "client = QdrantClient(\":memory:\")\n",
        "\n",
        "client.create_collection(\n",
        "    collection_name=\"ai_across_years\",\n",
        "    vectors_config=VectorParams(size=1536, distance=Distance.COSINE),\n",
        ")\n",
        "\n",
        "vector_store = QdrantVectorStore(\n",
        "    client=client,\n",
        "    collection_name=\"ai_across_years\",\n",
        "    embedding=embeddings,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUSCXe7x_h0O"
      },
      "source": [
        "We can now add our documents to our vector store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vckrosgpsfq2",
        "outputId": "799a7b56-d273-42f8-f0cc-56066ed6a772"
      },
      "outputs": [],
      "source": [
        "_ = vector_store.add_documents(documents=split_documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBgsT5_m_lOD"
      },
      "source": [
        "Let's define our retriever."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "qmxRJeMbskTS"
      },
      "outputs": [],
      "source": [
        "retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZX68nle_nUm"
      },
      "source": [
        "Now we can produce a node for retrieval!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "RMuKChk8vmCv"
      },
      "outputs": [],
      "source": [
        "def retrieve(state):\n",
        "  retrieved_docs = retriever.invoke(state[\"question\"])\n",
        "  return {\"context\" : retrieved_docs}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48-mJHgUsvDG"
      },
      "source": [
        "### Augmented\n",
        "\n",
        "Let's create a simple RAG prompt!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "C0masYYKsxLg"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "RAG_PROMPT = \"\"\"\\\n",
        "You are a helpful assistant who answers questions based on provided context. You must only use the provided context, and cannot use your own knowledge.\n",
        "\n",
        "### Question\n",
        "{question}\n",
        "\n",
        "### Context\n",
        "{context}\n",
        "\"\"\"\n",
        "\n",
        "rag_prompt = ChatPromptTemplate.from_template(RAG_PROMPT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cznU20c0uY9j"
      },
      "source": [
        "### Generation\n",
        "\n",
        "We'll also need an LLM to generate responses - we'll use `gpt-4.1-nano` to avoid using the same model as our judge model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ZVHBcNGptdZt"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4.1-nano\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTpV7-b7_44n"
      },
      "source": [
        "Then we can create a `generate` node!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "trgefAs-wX84"
      },
      "outputs": [],
      "source": [
        "def generate(state):\n",
        "  docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
        "  messages = rag_prompt.format_messages(question=state[\"question\"], context=docs_content)\n",
        "  response = llm.invoke(messages)\n",
        "  return {\"response\" : response.content}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhD1IxvXu2zX"
      },
      "source": [
        "### Building RAG Graph with LangGraph\n",
        "\n",
        "Let's create some state for our LangGraph RAG graph!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "5-o5r2mqu8Og"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import START, StateGraph\n",
        "from typing_extensions import List, TypedDict\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "class State(TypedDict):\n",
        "  question: str\n",
        "  context: List[Document]\n",
        "  response: str"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFEqEQje_--V"
      },
      "source": [
        "Now we can build our simple graph!\n",
        "\n",
        "> NOTE: We're using `add_sequence` since we will always move from retrieval to generation. This is essentially building a chain in LangGraph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "8kMJ_bgWvU-q"
      },
      "outputs": [],
      "source": [
        "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
        "graph_builder.add_edge(START, \"retrieve\")\n",
        "graph = graph_builder.compile()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKX8yupqAIeQ"
      },
      "source": [
        "Let's do a test to make sure it's doing what we'd expect."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "PXdB5pdbwzIF"
      },
      "outputs": [],
      "source": [
        "response = graph.invoke({\"question\" : \"How are LLM agents useful?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "JPuemnQQw5Y2",
        "outputId": "2f10c9c3-4a64-44d9-b3cc-741a41b70bc8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'LLM agents are useful because they can act on your behalf, such as functioning as a travel agent or digital assistant. They can also be given access to tools and run in loops to help solve problems. Additionally, they are quite easy to build if you have the right data and resources, and can be run on personal devices, making them accessible. Their effectiveness is notable, especially in tasks like code generation, where they can even execute and test their own output to improve accuracy. Despite concerns about their reliability and potential drawbacks, LLM agents demonstrate significant utility in automating tasks and assisting with problem-solving.'"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response[\"response\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nK5gyOlixWr4"
      },
      "source": [
        "## Evaluating the App with Ragas\n",
        "\n",
        "Now we can finally do our evaluation!\n",
        "\n",
        "We'll start by running the queries we generated using SDG above through our application to get context and responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "tzstmZmfxYP2"
      },
      "outputs": [],
      "source": [
        "for test_row in dataset:\n",
        "  response = graph.invoke({\"question\" : test_row.eval_sample.user_input})\n",
        "  test_row.eval_sample.response = response[\"response\"]\n",
        "  test_row.eval_sample.retrieved_contexts = [context.page_content for context in response[\"context\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VLXEuORVxd0l",
        "outputId": "c5f7ee36-fc43-4fe2-db5a-6639178756dc"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "user_input",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "retrieved_contexts",
                  "rawType": "object",
                  "type": "unknown"
                },
                {
                  "name": "reference_contexts",
                  "rawType": "object",
                  "type": "unknown"
                },
                {
                  "name": "response",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "reference",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "synthesizer_name",
                  "rawType": "object",
                  "type": "string"
                }
              ],
              "conversionMethod": "pd.DataFrame",
              "ref": "82a56a31-c5cb-4245-b7d9-be915ba1f9b3",
              "rows": [
                [
                  "0",
                  "Which organizations, including Stability AI, have produced better-than-GPT-3 class large language models?",
                  "['I‚Äôm relieved that this has changed completely in the past twelve months. 18 organizations now have models on the Chatbot Arena Leaderboard that rank higher than the original GPT-4 from March 2023 (GPT-4-0314 on the board)‚Äî70 models in total.\\n\\nScreenshot of a comparison table showing AI model rankings. Table headers: Rank (UB), Rank (StyleCtrl), Model, Arena Score, 95% CI, Votes, Organization, License. Shows 12 models including GLM-4-0520, Llama-3-70B-Instruct, Gemini-1.5-Flash-8B-Exp-0827, with rankings, scores, and licensing details. Models range from rank 52-69 with Arena scores between 1186-1207.\\n\\nThe earliest of those was Google‚Äôs Gemini 1.5 Pro, released in February. In addition to producing GPT-4 level outputs, it introduced several brand new capabilities to the field‚Äîmost notably its 1 million (and then later 2 million) token input context length, and the ability to input video.', 'If you can gather the right data, and afford to pay for the GPUs to train it, you can build an LLM.\\n\\nA year ago, the only organization that had released a generally useful LLM was OpenAI. We‚Äôve now seen better-than-GPT-3 class models produced by Anthropic, Mistral, Google, Meta, EleutherAI, Stability AI, TII in Abu Dhabi (Falcon), Microsoft Research, xAI, Replit, Baidu and a bunch of other organizations.\\n\\nThe training cost (hardware and electricity) is still significant‚Äîinitially millions of dollars, but that seems to have dropped to the tens of thousands already. Microsoft‚Äôs Phi-2 claims to have used ‚Äú14 days on 96 A100 GPUs‚Äù, which works out at around $35,000 using current Lambda pricing.', 'This is a huge advantage for open over closed models: the closed, hosted models don‚Äôt have thousands of researchers and hobbyists around the world collaborating and competing to improve them.\\n\\nWe don‚Äôt yet know how to build GPT-4\\n\\nFrustratingly, despite the enormous leaps ahead we‚Äôve had this year, we are yet to see an alternative model that‚Äôs better than GPT-4.\\n\\nOpenAI released GPT-4 in March, though it later turned out we had a sneak peak of it in February when Microsoft used it as part of the new Bing.\\n\\nThis may well change in the next few weeks: Google‚Äôs Gemini Ultra has big claims, but isn‚Äôt yet available for us to try out.\\n\\nThe team behind Mistral are working to beat GPT-4 as well, and their track record is already extremely strong considering their first public model only came out in September, and they‚Äôve released two significant improvements since then.', 'Getting back to models that beat GPT-4: Anthropic‚Äôs Claude 3 series launched in March, and Claude 3 Opus quickly became my new favourite daily-driver. They upped the ante even more in June with the launch of Claude 3.5 Sonnet‚Äîa model that is still my favourite six months later (though it got a significant upgrade on October 22, confusingly keeping the same 3.5 version number. Anthropic fans have since taken to calling it Claude 3.6).\\n\\nThen there‚Äôs the rest. If you browse the Chatbot Arena leaderboard today‚Äîstill the most useful single place to get a vibes-based evaluation of models‚Äîyou‚Äôll see that GPT-4-0314 has fallen to around 70th place. The 18 organizations with higher scoring models are Google, OpenAI, Alibaba, Anthropic, Meta, Reka AI, 01 AI, Amazon, Cohere, DeepSeek, Nvidia, Mistral, NexusFlow, Zhipu AI, xAI, AI21 Labs, Princeton and Tencent.', 'OpenAI are not the only game in town here. Google released their first entrant in the category, gemini-2.0-flash-thinking-exp, on December 19th.\\n\\nAlibaba‚Äôs Qwen team released their QwQ model on November 28th‚Äîunder an Apache 2.0 license, and that one I could run on my own machine. They followed that up with a vision reasoning model called QvQ on December 24th, which I also ran locally.\\n\\nDeepSeek made their DeepSeek-R1-Lite-Preview model available to try out through their chat interface on November 20th.\\n\\nTo understand more about inference scaling I recommend Is AI progress slowing down? by Arvind Narayanan and Sayash Kapoor.\\n\\nNothing yet from Anthropic or Meta but I would be very surprised if they don‚Äôt have their own inference-scaling models in the works. Meta published a relevant paper Training Large Language Models to Reason in a Continuous Latent Space in December.\\n\\nWas the best currently available LLM trained in China for less than $6m?']",
                  "['We don‚Äôt yet know how to build GPT-4 Vibes Based Development LLMs are really smart, and also really, really dumb Gullibility is the biggest unsolved problem Code may be the best application The ethics of this space remain diabolically complex My blog in 2023 Here‚Äôs the sequel to this post: Things we learned about LLMs in 2024. Large Language Models In the past 24-36 months, our species has discovered that you can take a GIANT corpus of text, run it through a pile of GPUs, and use it to create a fascinating new kind of software. LLMs can do a lot of things. They can answer questions, summarize documents, translate from one language to another, extract information and even write surprisingly competent code. They can also help you cheat at your homework, generate unlimited streams of fake content and be used for all manner of nefarious purposes. So far, I think they‚Äôre a net positive. I‚Äôve used them on a personal level to improve my productivity (and entertain myself) in all sorts of different ways. I think people who learn how to use them effectively can gain a significant boost to their quality of life. A lot of people are yet to be sold on their value! Some think their negatives outweigh their positives, some think they are all hot air, and some even think they represent an existential threat to humanity. They‚Äôre actually quite easy to build The most surprising thing we‚Äôve learned about LLMs this year is that they‚Äôre actually quite easy to build. Intuitively, one would expect that systems this powerful would take millions of lines of complex code. Instead, it turns out a few hundred lines of Python is genuinely enough to train a basic version! What matters most is the training data. You need a lot of data to make these things work, and the quantity and quality of the training data appears to be the most important factor in how good the resulting model is. If you can gather the right data, and afford to pay for the GPUs to train it, you can build an LLM. A year ago, the only organization that had released a generally useful LLM was OpenAI. We‚Äôve now seen better-than-GPT-3 class models produced by Anthropic, Mistral, Google, Meta, EleutherAI, Stability AI, TII in Abu Dhabi (Falcon), Microsoft Research, xAI, Replit, Baidu and a bunch of other organizations. The training cost (hardware and electricity) is still significant‚Äîinitially millions of dollars, but that seems to have dropped to the tens of thousands already. Microsoft‚Äôs Phi-2 claims to have used ‚Äú14 days on 96 A100 GPUs‚Äù, which works out at around $35,000 using current Lambda pricing. So training an LLM still isn‚Äôt something a hobbyist can afford, but it‚Äôs no longer the sole domain of the super-rich. I like to compare the difficulty of training an LLM to that of building a suspension bridge‚Äînot trivial, but hundreds of countries around the world have figured out how to do it. (Correction: Wikipedia‚Äôs Suspension bridges by country category lists 44 countries). You can run LLMs on your own devices In January of this year, I thought it would be years before I could run a useful LLM on my own computer. GPT-3 and 3.5 were pretty much the only games in town, and I thought that even if the model weights were available it would take a $10,000+ server to run them. Then in February, Meta released Llama. And a few weeks later in March, Georgi Gerganov released code that got it working on a MacBook. I wrote about how Large language models are having their Stable Diffusion moment, and with hindsight that was a very good call! This unleashed a whirlwind of innovation, which was accelerated further in July when Meta released Llama 2‚Äîan improved version which, crucially, included permission for commercial use. Today there are literally thousands of LLMs that can be run locally, on all manner of different devices. I run a bunch of them on my laptop. I run Mistral 7B (a surprisingly great model) on my iPhone. You can install several different apps to get your own, local, completely private LLM. My own LLM project provides a CLI tool for running an array of different models via plugins. You can even run them entirely in your browser using WebAssembly and the latest Chrome! Hobbyists can build their own fine-tuned models I said earlier that building an LLM was still out of reach of hobbyists. That may be true for training from scratch, but fine-tuning one of those models is another matter entirely. There‚Äôs now a fascinating ecosystem of people training their own models on top of these foundations, publishing those models, building fine-tuning datasets and sharing those too. The Hugging Face Open LLM Leaderboard is one place that tracks these. I can‚Äôt even attempt to count them, and any count would be out-of-date within a few hours. The best overall openly licensed LLM at any time is rarely a foundation model: instead, it‚Äôs whichever fine-tuned community model has most recently discovered the best combination of fine-tuning data. This is a huge advantage for open over closed models: the closed, hosted models don‚Äôt have thousands of researchers and hobbyists around the world collaborating and competing to improve them. We don‚Äôt yet know how to build GPT-4 Frustratingly, despite the enormous leaps ahead we‚Äôve had this year, we are yet to see an alternative model that‚Äôs better than GPT-4. OpenAI released GPT-4 in March, though it later turned out we had a sneak peak of it in February when Microsoft used it as part of the new Bing. This may well change in the next few weeks: Google‚Äôs Gemini Ultra has big claims, but isn‚Äôt yet available for us to try out. The team behind Mistral are working to beat GPT-4 as well, and their track record is already extremely strong considering their first public model only came out in September, and they‚Äôve released two significant improvements since then. Still,']",
                  "Yes, according to the provided context, organizations including Stability AI, Google, Anthropic, Mistral, Meta, EleutherAI, TII (Falcon), Microsoft Research, xAI, Replit, Baidu, and others have produced large language models that are better-than-GPT-3 class.",
                  "Organizations that have produced better-than-GPT-3 class large language models include Anthropic, Mistral, Google, Meta, EleutherAI, Stability AI, TII in Abu Dhabi (Falcon), Microsoft Research, xAI, Replit, and Baidu.",
                  "single_hop_specifc_query_synthesizer"
                ],
                [
                  "1",
                  "How does the use of Python by large language models (LLMs) impact their code generation capabilities, and what are the implications for evaluating LLM performance in coding tasks?",
                  "['Code may be the best application\\n\\nThe ethics of this space remain diabolically complex\\n\\nMy blog in 2023\\n\\nHere‚Äôs the sequel to this post: Things we learned about LLMs in 2024.\\n\\nLarge Language Models\\n\\nIn the past 24-36 months, our species has discovered that you can take a GIANT corpus of text, run it through a pile of GPUs, and use it to create a fascinating new kind of software.\\n\\nLLMs can do a lot of things. They can answer questions, summarize documents, translate from one language to another, extract information and even write surprisingly competent code.\\n\\nThey can also help you cheat at your homework, generate unlimited streams of fake content and be used for all manner of nefarious purposes.\\n\\nSo far, I think they‚Äôre a net positive. I‚Äôve used them on a personal level to improve my productivity (and entertain myself) in all sorts of different ways. I think people who learn how to use them effectively can gain a significant boost to their quality of life.', 'It‚Äôs still astonishing to me how effective they are though.\\n\\nOne of the great weaknesses of LLMs is their tendency to hallucinate‚Äîto imagine things that don‚Äôt correspond to reality. You would expect this to be a particularly bad problem for code‚Äîif an LLM hallucinates a method that doesn‚Äôt exist, the code should be useless.\\n\\nExcept... you can run generated code to see if it‚Äôs correct. And with patterns like ChatGPT Code Interpreter the LLM can execute the code itself, process the error message, then rewrite it and keep trying until it works!\\n\\nSo hallucination is a much lesser problem for code generation than for anything else. If only we had the equivalent of Code Interpreter for fact-checking natural language!\\n\\nHow should we feel about this as software engineers?\\n\\nOn the one hand, this feels like a threat: who needs a programmer if ChatGPT can write code for you?', 'Another common technique is to use larger models to help create training data for their smaller, cheaper alternatives‚Äîa trick used by an increasing number of labs. DeepSeek v3 used ‚Äúreasoning‚Äù data created by DeepSeek-R1. Meta‚Äôs Llama 3.3 70B fine-tuning used over 25M synthetically generated examples.\\n\\nCareful design of the training data that goes into an LLM appears to be the entire game for creating these models. The days of just grabbing a full scrape of the web and indiscriminately dumping it into a training run are long gone.\\n\\nLLMs somehow got even harder to use\\n\\nA drum I‚Äôve been banging for a while is that LLMs are power-user tools‚Äîthey‚Äôre chainsaws disguised as kitchen knives. They look deceptively simple to use‚Äîhow hard can it be to type messages to a chatbot?‚Äîbut in reality you need a huge depth of both understanding and experience to make the most of them and avoid their many pitfalls.\\n\\nIf anything, this problem got worse in 2024.', 'A lot of people are yet to be sold on their value! Some think their negatives outweigh their positives, some think they are all hot air, and some even think they represent an existential threat to humanity.\\n\\nThey‚Äôre actually quite easy to build\\n\\nThe most surprising thing we‚Äôve learned about LLMs this year is that they‚Äôre actually quite easy to build.\\n\\nIntuitively, one would expect that systems this powerful would take millions of lines of complex code. Instead, it turns out a few hundred lines of Python is genuinely enough to train a basic version!\\n\\nWhat matters most is the training data. You need a lot of data to make these things work, and the quantity and quality of the training data appears to be the most important factor in how good the resulting model is.\\n\\nIf you can gather the right data, and afford to pay for the GPUs to train it, you can build an LLM.', 'So training an LLM still isn‚Äôt something a hobbyist can afford, but it‚Äôs no longer the sole domain of the super-rich. I like to compare the difficulty of training an LLM to that of building a suspension bridge‚Äînot trivial, but hundreds of countries around the world have figured out how to do it. (Correction: Wikipedia‚Äôs Suspension bridges by country category lists 44 countries).\\n\\nYou can run LLMs on your own devices\\n\\nIn January of this year, I thought it would be years before I could run a useful LLM on my own computer. GPT-3 and 3.5 were pretty much the only games in town, and I thought that even if the model weights were available it would take a $10,000+ server to run them.\\n\\nThen in February, Meta released Llama. And a few weeks later in March, Georgi Gerganov released code that got it working on a MacBook.\\n\\nI wrote about how Large language models are having their Stable Diffusion moment, and with hindsight that was a very good call!']",
                  "['I‚Äôm surprised that no-one has beaten the now almost year old GPT-4 by now. OpenAI clearly have some substantial tricks that they haven‚Äôt shared yet. Vibes Based Development As a computer scientist and software engineer, LLMs are infuriating. Even the openly licensed ones are still the world‚Äôs most convoluted black boxes. We continue to have very little idea what they can do, how exactly they work and how best to control them. I‚Äôm used to programming where the computer does exactly what I tell it to do. Prompting an LLM is decidedly not that! The worst part is the challenge of evaluating them. There are plenty of benchmarks, but no benchmark is going to tell you if an LLM actually ‚Äúfeels‚Äù right when you try it for a given task. I find I have to work with an LLM for a few weeks in order to get a good intuition for it‚Äôs strengths and weaknesses. This greatly limits how many I can evaluate myself! The most frustrating thing for me is at the level of individual prompting. Sometimes I‚Äôll tweak a prompt and capitalize some of the words in it, to emphasize that I really want it to OUTPUT VALID MARKDOWN or similar. Did capitalizing those words make a difference? I still don‚Äôt have a good methodology for figuring that out. We‚Äôre left with what‚Äôs effectively Vibes Based Development. It‚Äôs vibes all the way down. I‚Äôd love to see us move beyond vibes in 2024! LLMs are really smart, and also really, really dumb On the one hand, we keep on finding new things that LLMs can do that we didn‚Äôt expect‚Äîand that the people who trained the models didn‚Äôt expect either. That‚Äôs usually really fun! But on the other hand, the things you sometimes have to do to get the models to behave are often incredibly dumb. Does ChatGPT get lazy in December, because its hidden system prompt includes the current date and its training data shows that people provide less useful answers coming up to the holidays? The honest answer is ‚Äúmaybe‚Äù! No-one is entirely sure, but if you give it a different date its answers may skew slightly longer. Sometimes it omits sections of code and leaves you to fill them in, but if you tell it you can‚Äôt type because you don‚Äôt have any fingers it produces the full code for you instead. There are so many more examples like this. Offer it cash tips for better answers. Tell it your career depends on it. Give it positive reinforcement. It‚Äôs all so dumb, but it works! Gullibility is the biggest unsolved problem I coined the term prompt injection in September last year. 15 months later, I regret to say that we‚Äôre still no closer to a robust, dependable solution to this problem. I‚Äôve written a ton about this already. Beyond that specific class of security vulnerabilities, I‚Äôve started seeing this as a wider problem of gullibility. Language Models are gullible. They ‚Äúbelieve‚Äù what we tell them‚Äîwhat‚Äôs in their training data, then what‚Äôs in the fine-tuning data, then what‚Äôs in the prompt. In order to be useful tools for us, we need them to believe what we feed them! But it turns out a lot of the things we want to build need them not to be gullible. Everyone wants an AI personal assistant. If you hired a real-world personal assistant who believed everything that anyone told them, you would quickly find that their ability to positively impact your life was severely limited. A lot of people are excited about AI agents‚Äîan infuriatingly vague term that seems to be converging on ‚ÄúAI systems that can go away and act on your behalf‚Äù. We‚Äôve been talking about them all year, but I‚Äôve seen few if any examples of them running in production, despite lots of exciting prototypes. I think this is because of gullibility. Can we solve this? Honestly, I‚Äôm beginning to suspect that you can‚Äôt fully solve gullibility without achieving AGI. So it may be quite a while before those agent dreams can really start to come true! Code may be the best application Over the course of the year, it‚Äôs become increasingly clear that writing code is one of the things LLMs are most capable of. If you think about what they do, this isn‚Äôt such a big surprise. The grammar rules of programming languages like Python and JavaScript are massively less complicated than the grammar of Chinese, Spanish or English. It‚Äôs still astonishing to me how effective they are though. One of the great weaknesses of LLMs is their tendency to hallucinate‚Äîto imagine things that don‚Äôt correspond to reality. You would expect this to be a particularly bad problem for code‚Äîif an LLM hallucinates a method that doesn‚Äôt exist, the code should be useless. Except... you can run generated code to see if it‚Äôs correct. And with patterns like ChatGPT Code Interpreter the LLM can execute the code itself, process the error message, then rewrite it and keep trying until it works! So hallucination is a much lesser problem for code generation than for anything else. If only we had the equivalent of Code Interpreter for fact-checking natural language! How should we feel about this as software engineers? On the one hand, this feels like a threat: who needs a programmer if ChatGPT can write code for you? On the other hand, as software engineers we are better placed to take advantage of this than anyone else. We‚Äôve all been given weird coding interns‚Äîwe can use our deep knowledge to prompt them to solve coding problems more effectively than anyone else can. The ethics of this space remain diabolically complex In September last year Andy Baio and I produced the first major story on the unlicensed training data behind Stable Diffusion. Since then, almost every major LLM (and most of the image generation models) have also been trained on unlicensed data. Just this week, the New York Times launched a landmark lawsuit against OpenAI and']",
                  "The use of Python in building and training large language models (LLMs) significantly impacts their code generation capabilities and has important implications for evaluating their performance in coding tasks. According to the provided context, training an LLM requires only a few hundred lines of Python code, emphasizing that these models are relatively accessible to build with the right training data and computational resources. This accessibility means that LLMs can be developed and refined more widely, potentially leading to improvements in their code generation abilities.\n\nFurthermore, the context highlights that LLMs can write surprisingly competent code and that their tendency to hallucinate‚Äîimagine things that don‚Äôt exist‚Äî is less problematic for code generation because generated code can be executed to verify correctness. Techniques like ChatGPT Code Interpreter enable the model to run code snippets, process errors, and iteratively improve the output, which enhances their practical utility in coding tasks.\n\nThe implications for evaluating LLM performance in coding are therefore nuanced. Since these models can be tested by executing their generated code, performance assessments can go beyond static correctness checks and include dynamic testing through code execution. This interactive evaluation process can provide more reliable insights into the models‚Äô coding capabilities. Additionally, because training and fine-tuning often involve Python scripts and datasets, the quality of training data directly influences the models‚Äô proficiency, making data curation a critical factor in performance evaluation.\n\nIn summary, Python‚Äôs role in the development and operation of LLMs facilitates more effective code generation and dynamic evaluation methods, which are essential for accurately assessing their performance in coding tasks.",
                  "According to the context, writing code is one of the things LLMs are most capable of, and this is partly because the grammar rules of programming languages like Python are massively less complicated than those of natural languages such as Chinese, Spanish, or English. This makes it less surprising that LLMs are effective at generating code in Python. Although LLMs have a tendency to hallucinate, this issue is less problematic for code generation because generated code can be run to check its correctness. Additionally, tools like ChatGPT Code Interpreter allow the LLM to execute Python code, process error messages, and iteratively rewrite the code until it works. This means that hallucination is a much lesser problem for code generation than for other tasks. However, evaluating LLM performance in coding tasks remains challenging, as benchmarks may not fully capture whether an LLM 'feels' right for a given task, and developing a good methodology for prompt engineering and evaluation is still an open problem.",
                  "single_hop_specifc_query_synthesizer"
                ],
                [
                  "2",
                  "Wut is AI?",
                  "['A lot of people are excited about AI agents‚Äîan infuriatingly vague term that seems to be converging on ‚ÄúAI systems that can go away and act on your behalf‚Äù. We‚Äôve been talking about them all year, but I‚Äôve seen few if any examples of them running in production, despite lots of exciting prototypes.\\n\\nI think this is because of gullibility.\\n\\nCan we solve this? Honestly, I‚Äôm beginning to suspect that you can‚Äôt fully solve gullibility without achieving AGI. So it may be quite a while before those agent dreams can really start to come true!\\n\\nCode may be the best application\\n\\nOver the course of the year, it‚Äôs become increasingly clear that writing code is one of the things LLMs are most capable of.\\n\\nIf you think about what they do, this isn‚Äôt such a big surprise. The grammar rules of programming languages like Python and JavaScript are massively less complicated than the grammar of Chinese, Spanish or English.\\n\\nIt‚Äôs still astonishing to me how effective they are though.', 'The two main categories I see are people who think AI agents are obviously things that go and act on your behalf‚Äîthe travel agent model‚Äîand people who think in terms of LLMs that have been given access to tools which they can run in a loop as part of solving a problem. The term ‚Äúautonomy‚Äù is often thrown into the mix too, again without including a clear definition.\\n\\n(I also collected 211 definitions on Twitter a few months ago‚Äîhere they are in Datasette Lite‚Äîand had gemini-exp-1206 attempt to summarize them.)\\n\\nWhatever the term may mean, agents still have that feeling of perpetually ‚Äúcoming soon‚Äù.\\n\\nTerminology aside, I remain skeptical as to their utility based, once again, on the challenge of gullibility. LLMs believe anything you tell them. Any systems that attempts to make meaningful decisions on your behalf will run into the same roadblock: how good is a travel agent, or a digital assistant, or even a research tool if it can‚Äôt distinguish truth from fiction?', 'OpenAI are not the only game in town here. Google released their first entrant in the category, gemini-2.0-flash-thinking-exp, on December 19th.\\n\\nAlibaba‚Äôs Qwen team released their QwQ model on November 28th‚Äîunder an Apache 2.0 license, and that one I could run on my own machine. They followed that up with a vision reasoning model called QvQ on December 24th, which I also ran locally.\\n\\nDeepSeek made their DeepSeek-R1-Lite-Preview model available to try out through their chat interface on November 20th.\\n\\nTo understand more about inference scaling I recommend Is AI progress slowing down? by Arvind Narayanan and Sayash Kapoor.\\n\\nNothing yet from Anthropic or Meta but I would be very surprised if they don‚Äôt have their own inference-scaling models in the works. Meta published a relevant paper Training Large Language Models to Reason in a Continuous Latent Space in December.\\n\\nWas the best currently available LLM trained in China for less than $6m?', 'That era appears to have ended, likely permanently, with OpenAI‚Äôs launch of ChatGPT Pro. This $200/month subscription service is the only way to access their most capable model, o1 Pro.\\n\\nSince the trick behind the o1 series (and the future models it will undoubtedly inspire) is to expend more compute time to get better results, I don‚Äôt think those days of free access to the best available models are likely to return.\\n\\n‚ÄúAgents‚Äù still haven‚Äôt really happened yet\\n\\nI find the term ‚Äúagents‚Äù extremely frustrating. It lacks a single, clear and widely understood meaning... but the people who use the term never seem to acknowledge that.\\n\\nIf you tell me that you are building ‚Äúagents‚Äù, you‚Äôve conveyed almost no information to me at all. Without reading your mind I have no way of telling which of the dozens of possible definitions you are talking about.', 'The top five: ai (342), generativeai (300), llms (287), openai (86), chatgpt (78).\\n\\nI‚Äôve written a lot about this stuff!\\n\\nI grabbed a screenshot of my Plausible analytics for the year, fed that to ChatGPT Vision, told it to extract the data into a table, then got it to mix in entry titles (from a SQL query it wrote) and produced this table with it. Here are my top entries this year by amount of traffic:']",
                  "['Simon Willison‚Äôs Weblog Subscribe Stuff we figured out about AI in 2023 31st December 2023 2023 was the breakthrough year for Large Language Models (LLMs). I think it‚Äôs OK to call these AI‚Äîthey‚Äôre the latest and (currently) most interesting development in the academic field of Artificial Intelligence that dates back to the 1950s. Here‚Äôs my attempt to round up the highlights in one place! Large Language Models They‚Äôre actually quite easy to build You can run LLMs on your own devices Hobbyists can build their own fine-tuned models']",
                  "AI, based on the provided context, refers to artificial intelligence systems that can act on your behalf, often called AI agents. These are systems that are envisioned to perform tasks or make decisions autonomously, such as travel agents or digital assistants. However, the term \"agents\" is often used vaguely and lacks a clear, widely accepted definition. The context also discusses the capabilities of large language models (LLMs) in coding and problem-solving, as well as the challenges in making AI systems truly autonomous or capable of meaningful decision-making due to issues like gullibility and the difficulty in distinguishing truth from fiction.",
                  "AI refers to Large Language Models, which are the latest and most interesting development in the academic field of Artificial Intelligence.",
                  "single_hop_specifc_query_synthesizer"
                ],
                [
                  "3",
                  "Whaat is the signifficance of OpenAI in the context of LLMs and AI discusionns acccording to the blog's 2023 tag cloud and traffic data?",
                  "['Law is not ethics. Is it OK to train models on people‚Äôs content without their permission, when those models will then be used in ways that compete with those people?\\n\\nAs the quality of results produced by AI models has increased over the year, these questions have become even more pressing.\\n\\nThe impact on human society in terms of these models is already huge, if difficult to objectively measure.\\n\\nPeople have certainly lost work to them‚Äîanecdotally, I‚Äôve seen this for copywriters, artists and translators.\\n\\nThere are a great deal of untold stories here. I‚Äôm hoping 2024 sees significant amounts of dedicated journalism on this topic.\\n\\nMy blog in 2023\\n\\nHere‚Äôs a tag cloud for content I posted to my blog in 2023 (generated using Django SQL Dashboard):\\n\\nTag cloud words in order of size: ai, generativeai, llms, openai, chatgpt, projects, python, datasette, ethics, llama, homebrewllms, sqlite, gpt3, promptengineering, promptinjection, llm, security, opensource, gpt4, weeknotes', 'Since then, almost every major LLM (and most of the image generation models) have also been trained on unlicensed data.\\n\\nJust this week, the New York Times launched a landmark lawsuit against OpenAI and Microsoft over this issue. The 69 page PDF is genuinely worth reading‚Äîespecially the first few pages, which lay out the issues in a way that‚Äôs surprisingly easy to follow. The rest of the document includes some of the clearest explanations of what LLMs are, how they work and how they are built that I‚Äôve read anywhere.\\n\\nThe legal arguments here are complex. I‚Äôm not a lawyer, but I don‚Äôt think this one will be easily decided. Whichever way it goes, I expect this case to have a profound impact on how this technology develops in the future.\\n\\nLaw is not ethics. Is it OK to train models on people‚Äôs content without their permission, when those models will then be used in ways that compete with those people?', \"This is Things we learned about LLMs in 2024 by Simon Willison, posted on 31st December 2024.\\n\\nPart of series LLMs annual review\\n\\nStuff we figured out about AI in 2023 - Dec. 31, 2023, 11:59 p.m.\\n\\nThings we learned about LLMs in 2024 - Dec. 31, 2024, 6:07 p.m.\\n\\ngoogle 360 ai 1262 openai 289 generative-ai 1089 local-llms 113 llms 1076 anthropic 136 gemini 80 meta 32 llm-reasoning 44 long-context 15 ai-energy-usage 5\\n\\nNext: Ending a year long posting streak\\n\\nPrevious: Trying out QvQ - Qwen's new visual reasoning model\\n\\nColophon\\n\\n¬©\\n\\n2002\\n\\n2003\\n\\n2004\\n\\n2005\\n\\n2006\\n\\n2007\\n\\n2008\\n\\n2009\\n\\n2010\\n\\n2011\\n\\n2012\\n\\n2013\\n\\n2014\\n\\n2015\\n\\n2016\\n\\n2017\\n\\n2018\\n\\n2019\\n\\n2020\\n\\n2021\\n\\n2022\\n\\n2023\\n\\n2024\\n\\n2025\", 'Simon Willison‚Äôs Weblog\\n\\nSubscribe\\n\\nStuff we figured out about AI in 2023\\n\\n31st December 2023\\n\\n2023 was the breakthrough year for Large Language Models (LLMs). I think it‚Äôs OK to call these AI‚Äîthey‚Äôre the latest and (currently) most interesting development in the academic field of Artificial Intelligence that dates back to the 1950s.\\n\\nHere‚Äôs my attempt to round up the highlights in one place!\\n\\nLarge Language Models\\n\\nThey‚Äôre actually quite easy to build\\n\\nYou can run LLMs on your own devices\\n\\nHobbyists can build their own fine-tuned models\\n\\nWe don‚Äôt yet know how to build GPT-4\\n\\nVibes Based Development\\n\\nLLMs are really smart, and also really, really dumb\\n\\nGullibility is the biggest unsolved problem\\n\\nCode may be the best application\\n\\nThe ethics of this space remain diabolically complex\\n\\nMy blog in 2023\\n\\nHere‚Äôs the sequel to this post: Things we learned about LLMs in 2024.\\n\\nLarge Language Models', '‚ÄúAgents‚Äù still haven‚Äôt really happened yet\\n\\nEvals really matter\\n\\nApple Intelligence is bad, Apple‚Äôs MLX library is excellent\\n\\nThe rise of inference-scaling ‚Äúreasoning‚Äù models\\n\\nWas the best currently available LLM trained in China for less than $6m?\\n\\nThe environmental impact got better\\n\\nThe environmental impact got much, much worse\\n\\nThe year of slop\\n\\nSynthetic training data works great\\n\\nLLMs somehow got even harder to use\\n\\nKnowledge is incredibly unevenly distributed\\n\\nLLMs need better criticism\\n\\nEverything tagged ‚Äúllms‚Äù on my blog in 2024\\n\\nThe GPT-4 barrier was comprehensively broken\\n\\nIn my December 2023 review I wrote about how We don‚Äôt yet know how to build GPT-4‚ÄîOpenAI‚Äôs best model was almost a year old at that point, yet no other AI lab had produced anything better. What did OpenAI know that the rest of us didn‚Äôt?']",
                  "['Microsoft over this issue. The 69 page PDF is genuinely worth reading‚Äîespecially the first few pages, which lay out the issues in a way that‚Äôs surprisingly easy to follow. The rest of the document includes some of the clearest explanations of what LLMs are, how they work and how they are built that I‚Äôve read anywhere. The legal arguments here are complex. I‚Äôm not a lawyer, but I don‚Äôt think this one will be easily decided. Whichever way it goes, I expect this case to have a profound impact on how this technology develops in the future. Law is not ethics. Is it OK to train models on people‚Äôs content without their permission, when those models will then be used in ways that compete with those people? As the quality of results produced by AI models has increased over the year, these questions have become even more pressing. The impact on human society in terms of these models is already huge, if difficult to objectively measure. People have certainly lost work to them‚Äîanecdotally, I‚Äôve seen this for copywriters, artists and translators. There are a great deal of untold stories here. I‚Äôm hoping 2024 sees significant amounts of dedicated journalism on this topic. My blog in 2023 Here‚Äôs a tag cloud for content I posted to my blog in 2023 (generated using Django SQL Dashboard): Tag cloud words in order of size: ai, generativeai, llms, openai, chatgpt, projects, python, datasette, ethics, llama, homebrewllms, sqlite, gpt3, promptengineering, promptinjection, llm, security, opensource, gpt4, weeknotes The top five: ai (342), generativeai (300), llms (287), openai (86), chatgpt (78). I‚Äôve written a lot about this stuff! I grabbed a screenshot of my Plausible analytics for the year, fed that to ChatGPT Vision, told it to extract the data into a table, then got it to mix in entry titles (from a SQL query it wrote) and produced this table with it. Here are my top entries this year by amount of traffic: Article Visitors Pageviews Bing: ‚ÄúI will not harm you unless you harm me first‚Äù 1.1M 1.3M Leaked Google document: ‚ÄúWe Have No Moat, And Neither Does OpenAI‚Äù 132k 162k Large language models are having their Stable Diffusion moment 121k 150k Prompt injection: What‚Äôs the worst that can happen? 79.8k 95.9k Embeddings: What they are and why they matter 61.7k 79.3k Catching up on the weird world of LLMs 61.6k 85.9k llamafile is the new best way to run an LLM on your own computer 52k 66k Prompt injection explained, with video, slides, and a transcript 51k 61.9k AI-enhanced development makes me more ambitious with my projects 49.6k 60.1k Understanding GPT tokenizers 49.5k 61.1k Exploring GPTs: ChatGPT in a trench coat? 46.4k 58.5k Could you train a ChatGPT-beating model for $85,000 and run it in a browser? 40.5k 49.2k How to implement Q&A against your documentation with GPT3, embeddings and Datasette 37.3k 44.9k Lawyer cites fake cases invented by ChatGPT, judge is not amused 37.1k 47.4k Now add a walrus: Prompt engineering in DALL-E 3 32.8k 41.2k Web LLM runs the vicuna-7b Large Language Model entirely in your browser, and it‚Äôs very impressive 32.5k 38.2k ChatGPT can‚Äôt access the internet, even though it really looks like it can 30.5k 34.2k Stanford Alpaca, and the acceleration of on-device large language model development 29.7k 35.7k Run Llama 2 on your own Mac using LLM and Homebrew 27.9k 33.6k Midjourney 5.1 26.7k 33.4k Think of language models like ChatGPT as a ‚Äúcalculator for words‚Äù 25k 31.8k Multi-modal prompt injection image attacks against GPT-4V 23.7k 27.4k I also gave a bunch of talks and podcast appearances. I‚Äôve started habitually turning my talks into annotated presentations‚Äîhere are my best from 2023: Prompt injection explained, with video, slides, and a transcript Catching up on the weird world of LLMs Making Large Language Models work for you Open questions for AI engineering Embeddings: What they are and why they matter Financial sustainability for open source projects at GitHub Universe And in podcasts: What AI can do for you on the Theory of Change Working in public on Path to Citus Con LLMs break the internet on the Changelog Talking Large Language Models on Rooftop Ruby Thoughts on the OpenAI board situation on Newsroom Robots Industry‚Äôs Tardy Response to the AI Prompt Injection Vulnerability on RedMonk Conversations Posted 31st December 2023 at 11:59 pm ¬∑ Follow me on Mastodon, Bluesky, Twitter or subscribe to my newsletter More recent articles Feed a video to a vision LLM as a sequence of JPEG frames on the CLI (also LLM 0.25) - 5th May 2025 Two publishers and three authors fail to understand what \"vibe coding\" means - 1st May 2025 Understanding the recent criticism of the Chatbot Arena - 30th April 2025 This is Stuff we figured out about AI in 2023 by Simon Willison, posted on 31st December 2023. Part of series LLMs annual review Stuff we figured out about AI in 2023 - Dec. 31, 2023, 11:59 p.m. Things we learned about LLMs in 2024 - Dec. 31, 2024, 6:07 p.m. blogging 105 ai 1262 generative-ai 1089 llms 1076 Next: Tom Scott, and the formidable power of escalating streaks Previous: Last weeknotes of 2023 Colophon ¬© 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 2025']",
                  "According to the blog's 2023 tag cloud and traffic data, OpenAI is a significant entity in the context of LLMs and AI discussions. It is prominently featured in the tag cloud, with the word \"openai\" appearing among the most notable words, indicating high relevance and interest. Additionally, traffic data shows that \"openai\" received 2,892 mentions, making it a major focus in the AI discourse on the blog during 2023. This prominence reflects OpenAI's influential role in the development and conversation surrounding large language models and AI advancements during that year.",
                  "According to the blog's 2023 tag cloud, 'openai' was one of the top five most used tags, with 86 mentions, indicating its prominence in discussions about LLMs and AI. Additionally, one of the top traffic articles was titled 'Leaked Google document: ‚ÄúWe Have No Moat, And Neither Does OpenAI‚Äù', which received 132k visitors and 162k pageviews, further highlighting OpenAI's significant role in the AI and LLM conversation on the blog.",
                  "single_hop_specifc_query_synthesizer"
                ],
                [
                  "4",
                  "Considering the applications of LLMs such as code generation and productivity enhancement, how has the rise of LLMs impacted software engineering and programming roles, particularly in terms of both opportunities and perceived threats, as discussed in the context?",
                  "['Code may be the best application\\n\\nThe ethics of this space remain diabolically complex\\n\\nMy blog in 2023\\n\\nHere‚Äôs the sequel to this post: Things we learned about LLMs in 2024.\\n\\nLarge Language Models\\n\\nIn the past 24-36 months, our species has discovered that you can take a GIANT corpus of text, run it through a pile of GPUs, and use it to create a fascinating new kind of software.\\n\\nLLMs can do a lot of things. They can answer questions, summarize documents, translate from one language to another, extract information and even write surprisingly competent code.\\n\\nThey can also help you cheat at your homework, generate unlimited streams of fake content and be used for all manner of nefarious purposes.\\n\\nSo far, I think they‚Äôre a net positive. I‚Äôve used them on a personal level to improve my productivity (and entertain myself) in all sorts of different ways. I think people who learn how to use them effectively can gain a significant boost to their quality of life.', 'It‚Äôs still astonishing to me how effective they are though.\\n\\nOne of the great weaknesses of LLMs is their tendency to hallucinate‚Äîto imagine things that don‚Äôt correspond to reality. You would expect this to be a particularly bad problem for code‚Äîif an LLM hallucinates a method that doesn‚Äôt exist, the code should be useless.\\n\\nExcept... you can run generated code to see if it‚Äôs correct. And with patterns like ChatGPT Code Interpreter the LLM can execute the code itself, process the error message, then rewrite it and keep trying until it works!\\n\\nSo hallucination is a much lesser problem for code generation than for anything else. If only we had the equivalent of Code Interpreter for fact-checking natural language!\\n\\nHow should we feel about this as software engineers?\\n\\nOn the one hand, this feels like a threat: who needs a programmer if ChatGPT can write code for you?', 'LLMs need better criticism\\n\\nA lot of people absolutely hate this stuff. In some of the spaces I hang out (Mastodon, Bluesky, Lobste.rs, even Hacker News on occasion) even suggesting that ‚ÄúLLMs are useful‚Äù can be enough to kick off a huge fight.\\n\\nI get it. There are plenty of reasons to dislike this technology‚Äîthe environmental impact, the (lack of) ethics of the training data, the lack of reliability, the negative applications, the potential impact on people‚Äôs jobs.\\n\\nLLMs absolutely warrant criticism. We need to be talking through these problems, finding ways to mitigate them and helping people learn how to use these tools responsibly in ways where the positive applications outweigh the negative.\\n\\nI like people who are skeptical of this stuff. The hype has been deafening for more than two years now, and there are enormous quantities of snake oil and misinformation out there. A lot of very bad decisions are being made based on that hype. Being critical is a virtue.', 'So training an LLM still isn‚Äôt something a hobbyist can afford, but it‚Äôs no longer the sole domain of the super-rich. I like to compare the difficulty of training an LLM to that of building a suspension bridge‚Äînot trivial, but hundreds of countries around the world have figured out how to do it. (Correction: Wikipedia‚Äôs Suspension bridges by country category lists 44 countries).\\n\\nYou can run LLMs on your own devices\\n\\nIn January of this year, I thought it would be years before I could run a useful LLM on my own computer. GPT-3 and 3.5 were pretty much the only games in town, and I thought that even if the model weights were available it would take a $10,000+ server to run them.\\n\\nThen in February, Meta released Llama. And a few weeks later in March, Georgi Gerganov released code that got it working on a MacBook.\\n\\nI wrote about how Large language models are having their Stable Diffusion moment, and with hindsight that was a very good call!', 'A lot of people are yet to be sold on their value! Some think their negatives outweigh their positives, some think they are all hot air, and some even think they represent an existential threat to humanity.\\n\\nThey‚Äôre actually quite easy to build\\n\\nThe most surprising thing we‚Äôve learned about LLMs this year is that they‚Äôre actually quite easy to build.\\n\\nIntuitively, one would expect that systems this powerful would take millions of lines of complex code. Instead, it turns out a few hundred lines of Python is genuinely enough to train a basic version!\\n\\nWhat matters most is the training data. You need a lot of data to make these things work, and the quantity and quality of the training data appears to be the most important factor in how good the resulting model is.\\n\\nIf you can gather the right data, and afford to pay for the GPUs to train it, you can build an LLM.']",
                  "['<1-hop>\\n\\nWe don‚Äôt yet know how to build GPT-4 Vibes Based Development LLMs are really smart, and also really, really dumb Gullibility is the biggest unsolved problem Code may be the best application The ethics of this space remain diabolically complex My blog in 2023 Here‚Äôs the sequel to this post: Things we learned about LLMs in 2024. Large Language Models In the past 24-36 months, our species has discovered that you can take a GIANT corpus of text, run it through a pile of GPUs, and use it to create a fascinating new kind of software. LLMs can do a lot of things. They can answer questions, summarize documents, translate from one language to another, extract information and even write surprisingly competent code. They can also help you cheat at your homework, generate unlimited streams of fake content and be used for all manner of nefarious purposes. So far, I think they‚Äôre a net positive. I‚Äôve used them on a personal level to improve my productivity (and entertain myself) in all sorts of different ways. I think people who learn how to use them effectively can gain a significant boost to their quality of life. A lot of people are yet to be sold on their value! Some think their negatives outweigh their positives, some think they are all hot air, and some even think they represent an existential threat to humanity. They‚Äôre actually quite easy to build The most surprising thing we‚Äôve learned about LLMs this year is that they‚Äôre actually quite easy to build. Intuitively, one would expect that systems this powerful would take millions of lines of complex code. Instead, it turns out a few hundred lines of Python is genuinely enough to train a basic version! What matters most is the training data. You need a lot of data to make these things work, and the quantity and quality of the training data appears to be the most important factor in how good the resulting model is. If you can gather the right data, and afford to pay for the GPUs to train it, you can build an LLM. A year ago, the only organization that had released a generally useful LLM was OpenAI. We‚Äôve now seen better-than-GPT-3 class models produced by Anthropic, Mistral, Google, Meta, EleutherAI, Stability AI, TII in Abu Dhabi (Falcon), Microsoft Research, xAI, Replit, Baidu and a bunch of other organizations. The training cost (hardware and electricity) is still significant‚Äîinitially millions of dollars, but that seems to have dropped to the tens of thousands already. Microsoft‚Äôs Phi-2 claims to have used ‚Äú14 days on 96 A100 GPUs‚Äù, which works out at around $35,000 using current Lambda pricing. So training an LLM still isn‚Äôt something a hobbyist can afford, but it‚Äôs no longer the sole domain of the super-rich. I like to compare the difficulty of training an LLM to that of building a suspension bridge‚Äînot trivial, but hundreds of countries around the world have figured out how to do it. (Correction: Wikipedia‚Äôs Suspension bridges by country category lists 44 countries). You can run LLMs on your own devices In January of this year, I thought it would be years before I could run a useful LLM on my own computer. GPT-3 and 3.5 were pretty much the only games in town, and I thought that even if the model weights were available it would take a $10,000+ server to run them. Then in February, Meta released Llama. And a few weeks later in March, Georgi Gerganov released code that got it working on a MacBook. I wrote about how Large language models are having their Stable Diffusion moment, and with hindsight that was a very good call! This unleashed a whirlwind of innovation, which was accelerated further in July when Meta released Llama 2‚Äîan improved version which, crucially, included permission for commercial use. Today there are literally thousands of LLMs that can be run locally, on all manner of different devices. I run a bunch of them on my laptop. I run Mistral 7B (a surprisingly great model) on my iPhone. You can install several different apps to get your own, local, completely private LLM. My own LLM project provides a CLI tool for running an array of different models via plugins. You can even run them entirely in your browser using WebAssembly and the latest Chrome! Hobbyists can build their own fine-tuned models I said earlier that building an LLM was still out of reach of hobbyists. That may be true for training from scratch, but fine-tuning one of those models is another matter entirely. There‚Äôs now a fascinating ecosystem of people training their own models on top of these foundations, publishing those models, building fine-tuning datasets and sharing those too. The Hugging Face Open LLM Leaderboard is one place that tracks these. I can‚Äôt even attempt to count them, and any count would be out-of-date within a few hours. The best overall openly licensed LLM at any time is rarely a foundation model: instead, it‚Äôs whichever fine-tuned community model has most recently discovered the best combination of fine-tuning data. This is a huge advantage for open over closed models: the closed, hosted models don‚Äôt have thousands of researchers and hobbyists around the world collaborating and competing to improve them. We don‚Äôt yet know how to build GPT-4 Frustratingly, despite the enormous leaps ahead we‚Äôve had this year, we are yet to see an alternative model that‚Äôs better than GPT-4. OpenAI released GPT-4 in March, though it later turned out we had a sneak peak of it in February when Microsoft used it as part of the new Bing. This may well change in the next few weeks: Google‚Äôs Gemini Ultra has big claims, but isn‚Äôt yet available for us to try out. The team behind Mistral are working to beat GPT-4 as well, and their track record is already extremely strong considering their first public model only came out in September, and they‚Äôve released two significant improvements since then. Still,', '<2-hop>\\n\\nI‚Äôm surprised that no-one has beaten the now almost year old GPT-4 by now. OpenAI clearly have some substantial tricks that they haven‚Äôt shared yet. Vibes Based Development As a computer scientist and software engineer, LLMs are infuriating. Even the openly licensed ones are still the world‚Äôs most convoluted black boxes. We continue to have very little idea what they can do, how exactly they work and how best to control them. I‚Äôm used to programming where the computer does exactly what I tell it to do. Prompting an LLM is decidedly not that! The worst part is the challenge of evaluating them. There are plenty of benchmarks, but no benchmark is going to tell you if an LLM actually ‚Äúfeels‚Äù right when you try it for a given task. I find I have to work with an LLM for a few weeks in order to get a good intuition for it‚Äôs strengths and weaknesses. This greatly limits how many I can evaluate myself! The most frustrating thing for me is at the level of individual prompting. Sometimes I‚Äôll tweak a prompt and capitalize some of the words in it, to emphasize that I really want it to OUTPUT VALID MARKDOWN or similar. Did capitalizing those words make a difference? I still don‚Äôt have a good methodology for figuring that out. We‚Äôre left with what‚Äôs effectively Vibes Based Development. It‚Äôs vibes all the way down. I‚Äôd love to see us move beyond vibes in 2024! LLMs are really smart, and also really, really dumb On the one hand, we keep on finding new things that LLMs can do that we didn‚Äôt expect‚Äîand that the people who trained the models didn‚Äôt expect either. That‚Äôs usually really fun! But on the other hand, the things you sometimes have to do to get the models to behave are often incredibly dumb. Does ChatGPT get lazy in December, because its hidden system prompt includes the current date and its training data shows that people provide less useful answers coming up to the holidays? The honest answer is ‚Äúmaybe‚Äù! No-one is entirely sure, but if you give it a different date its answers may skew slightly longer. Sometimes it omits sections of code and leaves you to fill them in, but if you tell it you can‚Äôt type because you don‚Äôt have any fingers it produces the full code for you instead. There are so many more examples like this. Offer it cash tips for better answers. Tell it your career depends on it. Give it positive reinforcement. It‚Äôs all so dumb, but it works! Gullibility is the biggest unsolved problem I coined the term prompt injection in September last year. 15 months later, I regret to say that we‚Äôre still no closer to a robust, dependable solution to this problem. I‚Äôve written a ton about this already. Beyond that specific class of security vulnerabilities, I‚Äôve started seeing this as a wider problem of gullibility. Language Models are gullible. They ‚Äúbelieve‚Äù what we tell them‚Äîwhat‚Äôs in their training data, then what‚Äôs in the fine-tuning data, then what‚Äôs in the prompt. In order to be useful tools for us, we need them to believe what we feed them! But it turns out a lot of the things we want to build need them not to be gullible. Everyone wants an AI personal assistant. If you hired a real-world personal assistant who believed everything that anyone told them, you would quickly find that their ability to positively impact your life was severely limited. A lot of people are excited about AI agents‚Äîan infuriatingly vague term that seems to be converging on ‚ÄúAI systems that can go away and act on your behalf‚Äù. We‚Äôve been talking about them all year, but I‚Äôve seen few if any examples of them running in production, despite lots of exciting prototypes. I think this is because of gullibility. Can we solve this? Honestly, I‚Äôm beginning to suspect that you can‚Äôt fully solve gullibility without achieving AGI. So it may be quite a while before those agent dreams can really start to come true! Code may be the best application Over the course of the year, it‚Äôs become increasingly clear that writing code is one of the things LLMs are most capable of. If you think about what they do, this isn‚Äôt such a big surprise. The grammar rules of programming languages like Python and JavaScript are massively less complicated than the grammar of Chinese, Spanish or English. It‚Äôs still astonishing to me how effective they are though. One of the great weaknesses of LLMs is their tendency to hallucinate‚Äîto imagine things that don‚Äôt correspond to reality. You would expect this to be a particularly bad problem for code‚Äîif an LLM hallucinates a method that doesn‚Äôt exist, the code should be useless. Except... you can run generated code to see if it‚Äôs correct. And with patterns like ChatGPT Code Interpreter the LLM can execute the code itself, process the error message, then rewrite it and keep trying until it works! So hallucination is a much lesser problem for code generation than for anything else. If only we had the equivalent of Code Interpreter for fact-checking natural language! How should we feel about this as software engineers? On the one hand, this feels like a threat: who needs a programmer if ChatGPT can write code for you? On the other hand, as software engineers we are better placed to take advantage of this than anyone else. We‚Äôve all been given weird coding interns‚Äîwe can use our deep knowledge to prompt them to solve coding problems more effectively than anyone else can. The ethics of this space remain diabolically complex In September last year Andy Baio and I produced the first major story on the unlicensed training data behind Stable Diffusion. Since then, almost every major LLM (and most of the image generation models) have also been trained on unlicensed data. Just this week, the New York Times launched a landmark lawsuit against OpenAI and']",
                  "The rise of LLMs has significantly impacted software engineering and programming roles by presenting both opportunities and perceived threats, as discussed in the context.\n\nOpportunities:\n- LLMs are capable of writing surprisingly competent code, which can enhance productivity for developers.\n- They can assist in code generation, making it easier and faster to develop software.\n- LLMs can be used to run and test generated code through tools like Code Interpreter, allowing for iterative improvement and verification.\n- The accessibility of building and running LLMs has increased, with models like Llama being available to run on personal devices, broadening participation in AI development.\n- The ease of building LLMs, requiring only a few hundred lines of Python and sufficient data, suggests that more individuals and organizations can develop their own models, potentially democratizing software creation.\n\nPerceived threats:\n- There is a concern that LLMs could replace programmers, with some viewing the ability of ChatGPT to generate code as a threat to traditional programming roles.\n- The hype surrounding LLMs has led to misinformation and bad decisions, fueling fears about over-reliance on these tools.\n- Ethical issues, environmental impacts, and the potential for negative applications add to the apprehension about widespread adoption.\n- Skepticism persists about whether these tools will fully replace human programmers or merely augment their capabilities.\n\nOverall, while LLMs are seen as powerful tools that can significantly boost productivity and lower the barriers to software development, there is also cautious skepticism about their limitations and the societal implications, making the impact on programming roles a nuanced mix of opportunity and threat.",
                  "The rise of LLMs has significantly impacted software engineering and programming roles, especially through their applications in code generation and productivity enhancement. According to the context, writing code has emerged as one of the most effective applications of LLMs, largely because programming languages have simpler grammar rules compared to natural languages. LLMs can generate surprisingly competent code, and tools like ChatGPT Code Interpreter allow the model to execute and iteratively improve its own code, reducing the impact of hallucinations that might otherwise render generated code useless. This capability presents both opportunities and threats for software engineers. On one hand, there is a perceived threat that LLMs could replace programmers, as they can automate many coding tasks. On the other hand, software engineers are uniquely positioned to leverage LLMs as powerful tools or 'weird coding interns,' using their expertise to prompt LLMs more effectively than non-experts. This duality means that while LLMs may automate certain aspects of programming, they also offer significant productivity boosts and new ways for engineers to enhance their work, provided they adapt to and integrate these tools into their workflows.",
                  "multi_hop_abstract_query_synthesizer"
                ],
                [
                  "5",
                  "How have large language models impacted software engineering roles, particularly through applications like code generation, and what challenges do software engineers face when working with these models?",
                  "['Code may be the best application\\n\\nThe ethics of this space remain diabolically complex\\n\\nMy blog in 2023\\n\\nHere‚Äôs the sequel to this post: Things we learned about LLMs in 2024.\\n\\nLarge Language Models\\n\\nIn the past 24-36 months, our species has discovered that you can take a GIANT corpus of text, run it through a pile of GPUs, and use it to create a fascinating new kind of software.\\n\\nLLMs can do a lot of things. They can answer questions, summarize documents, translate from one language to another, extract information and even write surprisingly competent code.\\n\\nThey can also help you cheat at your homework, generate unlimited streams of fake content and be used for all manner of nefarious purposes.\\n\\nSo far, I think they‚Äôre a net positive. I‚Äôve used them on a personal level to improve my productivity (and entertain myself) in all sorts of different ways. I think people who learn how to use them effectively can gain a significant boost to their quality of life.', 'How should we feel about this as software engineers?\\n\\nOn the one hand, this feels like a threat: who needs a programmer if ChatGPT can write code for you?\\n\\nOn the other hand, as software engineers we are better placed to take advantage of this than anyone else. We‚Äôve all been given weird coding interns‚Äîwe can use our deep knowledge to prompt them to solve coding problems more effectively than anyone else can.\\n\\nThe ethics of this space remain diabolically complex\\n\\nIn September last year Andy Baio and I produced the first major story on the unlicensed training data behind Stable Diffusion.\\n\\nSince then, almost every major LLM (and most of the image generation models) have also been trained on unlicensed data.', 'It‚Äôs still astonishing to me how effective they are though.\\n\\nOne of the great weaknesses of LLMs is their tendency to hallucinate‚Äîto imagine things that don‚Äôt correspond to reality. You would expect this to be a particularly bad problem for code‚Äîif an LLM hallucinates a method that doesn‚Äôt exist, the code should be useless.\\n\\nExcept... you can run generated code to see if it‚Äôs correct. And with patterns like ChatGPT Code Interpreter the LLM can execute the code itself, process the error message, then rewrite it and keep trying until it works!\\n\\nSo hallucination is a much lesser problem for code generation than for anything else. If only we had the equivalent of Code Interpreter for fact-checking natural language!\\n\\nHow should we feel about this as software engineers?\\n\\nOn the one hand, this feels like a threat: who needs a programmer if ChatGPT can write code for you?', 'Another common technique is to use larger models to help create training data for their smaller, cheaper alternatives‚Äîa trick used by an increasing number of labs. DeepSeek v3 used ‚Äúreasoning‚Äù data created by DeepSeek-R1. Meta‚Äôs Llama 3.3 70B fine-tuning used over 25M synthetically generated examples.\\n\\nCareful design of the training data that goes into an LLM appears to be the entire game for creating these models. The days of just grabbing a full scrape of the web and indiscriminately dumping it into a training run are long gone.\\n\\nLLMs somehow got even harder to use\\n\\nA drum I‚Äôve been banging for a while is that LLMs are power-user tools‚Äîthey‚Äôre chainsaws disguised as kitchen knives. They look deceptively simple to use‚Äîhow hard can it be to type messages to a chatbot?‚Äîbut in reality you need a huge depth of both understanding and experience to make the most of them and avoid their many pitfalls.\\n\\nIf anything, this problem got worse in 2024.', 'a browser? 40.5k 49.2k How to implement Q&A against your documentation with GPT3, embeddings and Datasette 37.3k 44.9k Lawyer cites fake cases invented by ChatGPT, judge is not amused 37.1k 47.4k Now add a walrus: Prompt engineering in DALL-E 3 32.8k 41.2k Web LLM runs the vicuna-7b Large Language Model entirely in your browser, and it‚Äôs very impressive 32.5k 38.2k ChatGPT can‚Äôt access the internet, even though it really looks like it can 30.5k 34.2k Stanford Alpaca, and the acceleration of on-device large language model development 29.7k 35.7k Run Llama 2 on your own Mac using LLM and Homebrew 27.9k 33.6k Midjourney 5.1 26.7k 33.4k Think of language models like ChatGPT as a ‚Äúcalculator for words‚Äù 25k 31.8k Multi-modal prompt injection image attacks against GPT-4V 23.7k 27.4k']",
                  "['<1-hop>\\n\\nWe don‚Äôt yet know how to build GPT-4 Vibes Based Development LLMs are really smart, and also really, really dumb Gullibility is the biggest unsolved problem Code may be the best application The ethics of this space remain diabolically complex My blog in 2023 Here‚Äôs the sequel to this post: Things we learned about LLMs in 2024. Large Language Models In the past 24-36 months, our species has discovered that you can take a GIANT corpus of text, run it through a pile of GPUs, and use it to create a fascinating new kind of software. LLMs can do a lot of things. They can answer questions, summarize documents, translate from one language to another, extract information and even write surprisingly competent code. They can also help you cheat at your homework, generate unlimited streams of fake content and be used for all manner of nefarious purposes. So far, I think they‚Äôre a net positive. I‚Äôve used them on a personal level to improve my productivity (and entertain myself) in all sorts of different ways. I think people who learn how to use them effectively can gain a significant boost to their quality of life. A lot of people are yet to be sold on their value! Some think their negatives outweigh their positives, some think they are all hot air, and some even think they represent an existential threat to humanity. They‚Äôre actually quite easy to build The most surprising thing we‚Äôve learned about LLMs this year is that they‚Äôre actually quite easy to build. Intuitively, one would expect that systems this powerful would take millions of lines of complex code. Instead, it turns out a few hundred lines of Python is genuinely enough to train a basic version! What matters most is the training data. You need a lot of data to make these things work, and the quantity and quality of the training data appears to be the most important factor in how good the resulting model is. If you can gather the right data, and afford to pay for the GPUs to train it, you can build an LLM. A year ago, the only organization that had released a generally useful LLM was OpenAI. We‚Äôve now seen better-than-GPT-3 class models produced by Anthropic, Mistral, Google, Meta, EleutherAI, Stability AI, TII in Abu Dhabi (Falcon), Microsoft Research, xAI, Replit, Baidu and a bunch of other organizations. The training cost (hardware and electricity) is still significant‚Äîinitially millions of dollars, but that seems to have dropped to the tens of thousands already. Microsoft‚Äôs Phi-2 claims to have used ‚Äú14 days on 96 A100 GPUs‚Äù, which works out at around $35,000 using current Lambda pricing. So training an LLM still isn‚Äôt something a hobbyist can afford, but it‚Äôs no longer the sole domain of the super-rich. I like to compare the difficulty of training an LLM to that of building a suspension bridge‚Äînot trivial, but hundreds of countries around the world have figured out how to do it. (Correction: Wikipedia‚Äôs Suspension bridges by country category lists 44 countries). You can run LLMs on your own devices In January of this year, I thought it would be years before I could run a useful LLM on my own computer. GPT-3 and 3.5 were pretty much the only games in town, and I thought that even if the model weights were available it would take a $10,000+ server to run them. Then in February, Meta released Llama. And a few weeks later in March, Georgi Gerganov released code that got it working on a MacBook. I wrote about how Large language models are having their Stable Diffusion moment, and with hindsight that was a very good call! This unleashed a whirlwind of innovation, which was accelerated further in July when Meta released Llama 2‚Äîan improved version which, crucially, included permission for commercial use. Today there are literally thousands of LLMs that can be run locally, on all manner of different devices. I run a bunch of them on my laptop. I run Mistral 7B (a surprisingly great model) on my iPhone. You can install several different apps to get your own, local, completely private LLM. My own LLM project provides a CLI tool for running an array of different models via plugins. You can even run them entirely in your browser using WebAssembly and the latest Chrome! Hobbyists can build their own fine-tuned models I said earlier that building an LLM was still out of reach of hobbyists. That may be true for training from scratch, but fine-tuning one of those models is another matter entirely. There‚Äôs now a fascinating ecosystem of people training their own models on top of these foundations, publishing those models, building fine-tuning datasets and sharing those too. The Hugging Face Open LLM Leaderboard is one place that tracks these. I can‚Äôt even attempt to count them, and any count would be out-of-date within a few hours. The best overall openly licensed LLM at any time is rarely a foundation model: instead, it‚Äôs whichever fine-tuned community model has most recently discovered the best combination of fine-tuning data. This is a huge advantage for open over closed models: the closed, hosted models don‚Äôt have thousands of researchers and hobbyists around the world collaborating and competing to improve them. We don‚Äôt yet know how to build GPT-4 Frustratingly, despite the enormous leaps ahead we‚Äôve had this year, we are yet to see an alternative model that‚Äôs better than GPT-4. OpenAI released GPT-4 in March, though it later turned out we had a sneak peak of it in February when Microsoft used it as part of the new Bing. This may well change in the next few weeks: Google‚Äôs Gemini Ultra has big claims, but isn‚Äôt yet available for us to try out. The team behind Mistral are working to beat GPT-4 as well, and their track record is already extremely strong considering their first public model only came out in September, and they‚Äôve released two significant improvements since then. Still,', '<2-hop>\\n\\nI‚Äôm surprised that no-one has beaten the now almost year old GPT-4 by now. OpenAI clearly have some substantial tricks that they haven‚Äôt shared yet. Vibes Based Development As a computer scientist and software engineer, LLMs are infuriating. Even the openly licensed ones are still the world‚Äôs most convoluted black boxes. We continue to have very little idea what they can do, how exactly they work and how best to control them. I‚Äôm used to programming where the computer does exactly what I tell it to do. Prompting an LLM is decidedly not that! The worst part is the challenge of evaluating them. There are plenty of benchmarks, but no benchmark is going to tell you if an LLM actually ‚Äúfeels‚Äù right when you try it for a given task. I find I have to work with an LLM for a few weeks in order to get a good intuition for it‚Äôs strengths and weaknesses. This greatly limits how many I can evaluate myself! The most frustrating thing for me is at the level of individual prompting. Sometimes I‚Äôll tweak a prompt and capitalize some of the words in it, to emphasize that I really want it to OUTPUT VALID MARKDOWN or similar. Did capitalizing those words make a difference? I still don‚Äôt have a good methodology for figuring that out. We‚Äôre left with what‚Äôs effectively Vibes Based Development. It‚Äôs vibes all the way down. I‚Äôd love to see us move beyond vibes in 2024! LLMs are really smart, and also really, really dumb On the one hand, we keep on finding new things that LLMs can do that we didn‚Äôt expect‚Äîand that the people who trained the models didn‚Äôt expect either. That‚Äôs usually really fun! But on the other hand, the things you sometimes have to do to get the models to behave are often incredibly dumb. Does ChatGPT get lazy in December, because its hidden system prompt includes the current date and its training data shows that people provide less useful answers coming up to the holidays? The honest answer is ‚Äúmaybe‚Äù! No-one is entirely sure, but if you give it a different date its answers may skew slightly longer. Sometimes it omits sections of code and leaves you to fill them in, but if you tell it you can‚Äôt type because you don‚Äôt have any fingers it produces the full code for you instead. There are so many more examples like this. Offer it cash tips for better answers. Tell it your career depends on it. Give it positive reinforcement. It‚Äôs all so dumb, but it works! Gullibility is the biggest unsolved problem I coined the term prompt injection in September last year. 15 months later, I regret to say that we‚Äôre still no closer to a robust, dependable solution to this problem. I‚Äôve written a ton about this already. Beyond that specific class of security vulnerabilities, I‚Äôve started seeing this as a wider problem of gullibility. Language Models are gullible. They ‚Äúbelieve‚Äù what we tell them‚Äîwhat‚Äôs in their training data, then what‚Äôs in the fine-tuning data, then what‚Äôs in the prompt. In order to be useful tools for us, we need them to believe what we feed them! But it turns out a lot of the things we want to build need them not to be gullible. Everyone wants an AI personal assistant. If you hired a real-world personal assistant who believed everything that anyone told them, you would quickly find that their ability to positively impact your life was severely limited. A lot of people are excited about AI agents‚Äîan infuriatingly vague term that seems to be converging on ‚ÄúAI systems that can go away and act on your behalf‚Äù. We‚Äôve been talking about them all year, but I‚Äôve seen few if any examples of them running in production, despite lots of exciting prototypes. I think this is because of gullibility. Can we solve this? Honestly, I‚Äôm beginning to suspect that you can‚Äôt fully solve gullibility without achieving AGI. So it may be quite a while before those agent dreams can really start to come true! Code may be the best application Over the course of the year, it‚Äôs become increasingly clear that writing code is one of the things LLMs are most capable of. If you think about what they do, this isn‚Äôt such a big surprise. The grammar rules of programming languages like Python and JavaScript are massively less complicated than the grammar of Chinese, Spanish or English. It‚Äôs still astonishing to me how effective they are though. One of the great weaknesses of LLMs is their tendency to hallucinate‚Äîto imagine things that don‚Äôt correspond to reality. You would expect this to be a particularly bad problem for code‚Äîif an LLM hallucinates a method that doesn‚Äôt exist, the code should be useless. Except... you can run generated code to see if it‚Äôs correct. And with patterns like ChatGPT Code Interpreter the LLM can execute the code itself, process the error message, then rewrite it and keep trying until it works! So hallucination is a much lesser problem for code generation than for anything else. If only we had the equivalent of Code Interpreter for fact-checking natural language! How should we feel about this as software engineers? On the one hand, this feels like a threat: who needs a programmer if ChatGPT can write code for you? On the other hand, as software engineers we are better placed to take advantage of this than anyone else. We‚Äôve all been given weird coding interns‚Äîwe can use our deep knowledge to prompt them to solve coding problems more effectively than anyone else can. The ethics of this space remain diabolically complex In September last year Andy Baio and I produced the first major story on the unlicensed training data behind Stable Diffusion. Since then, almost every major LLM (and most of the image generation models) have also been trained on unlicensed data. Just this week, the New York Times launched a landmark lawsuit against OpenAI and']",
                  "Large language models have significantly impacted software engineering roles, particularly through their application in code generation. They can write surprisingly competent code, assist in answering questions, summarizing documents, translating languages, and extracting information. Because of these capabilities, LLMs are seen as powerful tools that can enhance productivity and serve as \"powerful coding interns,\" enabling engineers to leverage their deep domain knowledge to prompt and utilize these models effectively.\n\nHowever, working with LLMs also presents notable challenges. They are complex power-user tools that require substantial understanding and experience to use effectively, making their deployment and integration less straightforward than it might initially seem. The models can hallucinate or generate incorrect code or information, although this issue is somewhat mitigated in code generation because generated code can be executed and tested, allowing for iterative refinement. Despite this, the complexity of designing effective prompts and understanding the models‚Äô limitations remains a significant hurdle for software engineers. Additionally, the use of large models has become more sophisticated, involving careful curation of training data rather than simple web scrapes, further emphasizing the need for expertise in utilizing these tools effectively.",
                  "Large language models (LLMs) have significantly impacted software engineering roles, especially through their strong capabilities in code generation. As noted, writing code is one of the tasks LLMs are most capable of, due to the relatively simple grammar of programming languages compared to natural languages. This has led to LLMs being used to write surprisingly competent code, and tools like ChatGPT Code Interpreter can even execute and iteratively improve generated code, reducing issues like hallucination. However, this advancement presents both opportunities and challenges for software engineers. On one hand, LLMs can be seen as a threat to traditional programming roles, since they can automate parts of the coding process. On the other hand, software engineers are uniquely positioned to leverage LLMs effectively, using their expertise to prompt and guide these models to solve complex coding problems. Despite these benefits, engineers face challenges such as the 'black box' nature of LLMs, difficulties in evaluating their outputs, and the need for 'Vibes Based Development'‚Äîrelying on intuition and trial-and-error when prompting models. Additionally, issues like model gullibility and the lack of robust methodologies for prompt engineering remain unresolved, complicating the integration of LLMs into software engineering workflows.",
                  "multi_hop_abstract_query_synthesizer"
                ],
                [
                  "6",
                  "How does the use of synthetic training data provide advantages over organic data in the development of large language models, and what are some examples of these advantages as described in recent model training practices?",
                  "['One of the best descriptions I‚Äôve seen of this comes from the Phi-4 technical report, which included this:\\n\\nSynthetic data as a substantial component of pretraining is becoming increasingly common, and the Phi series of models has consistently emphasized the importance of synthetic data. Rather than serving as a cheap substitute for organic data, synthetic data has several direct advantages over organic data.\\n\\nStructured and Gradual Learning. In organic datasets, the relationship between tokens is often complex and indirect. Many reasoning steps may be required to connect the current token to the next, making it challenging for the model to learn effectively from next-token prediction. By contrast, each token generated by a language model is by definition predicted by the preceding tokens, making it easier for a model to follow the resulting reasoning patterns.', 'Slop was even in the running for Oxford Word of the Year 2024, but it lost to brain rot.\\n\\nSynthetic training data works great\\n\\nAn idea that surprisingly seems to have stuck in the public consciousness is that of ‚Äúmodel collapse‚Äù. This was first described in the paper The Curse of Recursion: Training on Generated Data Makes Models Forget in May 2023, and repeated in Nature in July 2024 with the more eye-catching headline AI models collapse when trained on recursively generated data.\\n\\nThe idea is seductive: as the internet floods with AI-generated slop the models themselves will degenerate, feeding on their own output in a way that leads to their inevitable demise!\\n\\nThat‚Äôs clearly not happening. Instead, we are seeing AI labs increasingly train on synthetic content‚Äîdeliberately creating artificial data to help steer their models in the right way.\\n\\nOne of the best descriptions I‚Äôve seen of this comes from the Phi-4 technical report, which included this:', 'Another common technique is to use larger models to help create training data for their smaller, cheaper alternatives‚Äîa trick used by an increasing number of labs. DeepSeek v3 used ‚Äúreasoning‚Äù data created by DeepSeek-R1. Meta‚Äôs Llama 3.3 70B fine-tuning used over 25M synthetically generated examples.\\n\\nCareful design of the training data that goes into an LLM appears to be the entire game for creating these models. The days of just grabbing a full scrape of the web and indiscriminately dumping it into a training run are long gone.\\n\\nLLMs somehow got even harder to use\\n\\nA drum I‚Äôve been banging for a while is that LLMs are power-user tools‚Äîthey‚Äôre chainsaws disguised as kitchen knives. They look deceptively simple to use‚Äîhow hard can it be to type messages to a chatbot?‚Äîbut in reality you need a huge depth of both understanding and experience to make the most of them and avoid their many pitfalls.\\n\\nIf anything, this problem got worse in 2024.', 'The rise of inference-scaling ‚Äúreasoning‚Äù models\\n\\nThe most interesting development in the final quarter of 2024 was the introduction of a new shape of LLM, exemplified by OpenAI‚Äôs o1 models‚Äîinitially released as o1-preview and o1-mini on September 12th.\\n\\nOne way to think about these models is an extension of the chain-of-thought prompting trick, first explored in the May 2022 paper Large Language Models are Zero-Shot Reasoners.\\n\\nThis is that trick where, if you get a model to talk out loud about a problem it‚Äôs solving, you often get a result which the model would not have achieved otherwise.\\n\\no1 takes this process and further bakes it into the model itself. The details are somewhat obfuscated: o1 models spend ‚Äúreasoning tokens‚Äù thinking through the problem that are not directly visible to the user (though the ChatGPT UI shows a summary of them), then outputs a final result.', 'Code may be the best application\\n\\nThe ethics of this space remain diabolically complex\\n\\nMy blog in 2023\\n\\nHere‚Äôs the sequel to this post: Things we learned about LLMs in 2024.\\n\\nLarge Language Models\\n\\nIn the past 24-36 months, our species has discovered that you can take a GIANT corpus of text, run it through a pile of GPUs, and use it to create a fascinating new kind of software.\\n\\nLLMs can do a lot of things. They can answer questions, summarize documents, translate from one language to another, extract information and even write surprisingly competent code.\\n\\nThey can also help you cheat at your homework, generate unlimited streams of fake content and be used for all manner of nefarious purposes.\\n\\nSo far, I think they‚Äôre a net positive. I‚Äôve used them on a personal level to improve my productivity (and entertain myself) in all sorts of different ways. I think people who learn how to use them effectively can gain a significant boost to their quality of life.']",
                  "['<1-hop>\\n\\nThe rise of inference-scaling ‚Äúreasoning‚Äù models Was the best currently available LLM trained in China for less than $6m? The environmental impact got better The environmental impact got much, much worse The year of slop Synthetic training data works great LLMs somehow got even harder to use Knowledge is incredibly unevenly distributed LLMs need better criticism Everything tagged ‚Äúllms‚Äù on my blog in 2024 The GPT-4 barrier was comprehensively broken In my December 2023 review I wrote about how We don‚Äôt yet know how to build GPT-4‚ÄîOpenAI‚Äôs best model was almost a year old at that point, yet no other AI lab had produced anything better. What did OpenAI know that the rest of us didn‚Äôt? I‚Äôm relieved that this has changed completely in the past twelve months. 18 organizations now have models on the Chatbot Arena Leaderboard that rank higher than the original GPT-4 from March 2023 (GPT-4-0314 on the board)‚Äî70 models in total. Screenshot of a comparison table showing AI model rankings. Table headers: Rank (UB), Rank (StyleCtrl), Model, Arena Score, 95% CI, Votes, Organization, License. Shows 12 models including GLM-4-0520, Llama-3-70B-Instruct, Gemini-1.5-Flash-8B-Exp-0827, with rankings, scores, and licensing details. Models range from rank 52-69 with Arena scores between 1186-1207. The earliest of those was Google‚Äôs Gemini 1.5 Pro, released in February. In addition to producing GPT-4 level outputs, it introduced several brand new capabilities to the field‚Äîmost notably its 1 million (and then later 2 million) token input context length, and the ability to input video. I wrote about this at the time in The killer app of Gemini Pro 1.5 is video, which earned me a short appearance as a talking head in the Google I/O opening keynote in May. Gemini 1.5 Pro also illustrated one of the key themes of 2024: increased context lengths. Last year most models accepted 4,096 or 8,192 tokens, with the notable exception of Claude 2.1 which accepted 200,000. Today every serious provider has a 100,000+ token model, and Google‚Äôs Gemini series accepts up to 2 million. Longer inputs dramatically increase the scope of problems that can be solved with an LLM: you can now throw in an entire book and ask questions about its contents, but more importantly you can feed in a lot of example code to help the model correctly solve a coding problem. LLM use-cases that involve long inputs are far more interesting to me than short prompts that rely purely on the information already baked into the model weights. Many of my tools were built using this pattern. Getting back to models that beat GPT-4: Anthropic‚Äôs Claude 3 series launched in March, and Claude 3 Opus quickly became my new favourite daily-driver. They upped the ante even more in June with the launch of Claude 3.5 Sonnet‚Äîa model that is still my favourite six months later (though it got a significant upgrade on October 22, confusingly keeping the same 3.5 version number. Anthropic fans have since taken to calling it Claude 3.6). Then there‚Äôs the rest. If you browse the Chatbot Arena leaderboard today‚Äîstill the most useful single place to get a vibes-based evaluation of models‚Äîyou‚Äôll see that GPT-4-0314 has fallen to around 70th place. The 18 organizations with higher scoring models are Google, OpenAI, Alibaba, Anthropic, Meta, Reka AI, 01 AI, Amazon, Cohere, DeepSeek, Nvidia, Mistral, NexusFlow, Zhipu AI, xAI, AI21 Labs, Princeton and Tencent. Training a GPT-4 beating model was a huge deal in 2023. In 2024 it‚Äôs an achievement that isn‚Äôt even particularly notable, though I personally still celebrate any time a new organization joins that list. Some of those GPT-4 models run on my laptop My personal laptop is a 64GB M2 MacBook Pro from 2023. It‚Äôs a powerful machine, but it‚Äôs also nearly two years old now‚Äîand crucially it‚Äôs the same laptop I‚Äôve been using ever since I first ran an LLM on my computer back in March 2023 (see Large language models are having their Stable Diffusion moment). That same laptop that could just about run a GPT-3-class model in March last year has now run multiple GPT-4 class models! Some of my notes on that: Qwen2.5-Coder-32B is an LLM that can code well that runs on my Mac talks about Qwen2.5-Coder-32B in November‚Äîan Apache 2.0 licensed model! I can now run a GPT-4 class model on my laptop talks about running Meta‚Äôs Llama 3.3 70B (released in December) This remains astonishing to me. I thought a model with the capabilities and output quality of GPT-4 needed a datacenter class server with one or more $40,000+ GPUs. These models take up enough of my 64GB of RAM that I don‚Äôt run them often‚Äîthey don‚Äôt leave much room for anything else. The fact that they run at all is a testament to the incredible training and inference performance gains that we‚Äôve figured out over the past year. It turns out there was a lot of low-hanging fruit to be harvested in terms of model efficiency. I expect there‚Äôs still more to come. Meta‚Äôs Llama 3.2 models deserve a special mention. They may not be GPT-4 class, but at 1B and 3B sizes they punch massively above their weight. I run Llama 3.2 3B on my iPhone using the free MLC Chat iOS app and it‚Äôs a shockingly capable model for its tiny (<2GB) size. Try firing it up and asking it for ‚Äúa plot outline of a Netflix Christmas movie where a data journalist falls in love with a local ceramacist‚Äù. Here‚Äôs what I got, at a respectable 20 tokens per second: MLC Chat: Llama - [System] Ready to chat. a plot outline of a Netflix Christmas movie where a data journalist falls in love with a local ceramacist. Show as Markdown is turned on. Here\\'s a plot outline for a Netflix Christmas movie: Title: \"Love in the Clay\" Plot Outline: We meet our protagonist, JESSICA, a data journalist who has just returned to her hometown of Willow Creek, a small, charming town nestled in the snow-covered mountains. She\\'s back to work', '<2-hop>\\n\\nmodel available to try out through their chat interface on November 20th. To understand more about inference scaling I recommend Is AI progress slowing down? by Arvind Narayanan and Sayash Kapoor. Nothing yet from Anthropic or Meta but I would be very surprised if they don‚Äôt have their own inference-scaling models in the works. Meta published a relevant paper Training Large Language Models to Reason in a Continuous Latent Space in December. Was the best currently available LLM trained in China for less than $6m? Not quite, but almost! It does make for a great attention-grabbing headline. The big news to end the year was the release of DeepSeek v3‚Äîdropped on Hugging Face on Christmas Day without so much as a README file, then followed by documentation and a paper the day after that. DeepSeek v3 is a huge 685B parameter model‚Äîone of the largest openly licensed models currently available, significantly bigger than the largest of Meta‚Äôs Llama series, Llama 3.1 405B. Benchmarks put it up there with Claude 3.5 Sonnet. Vibe benchmarks (aka the Chatbot Arena) currently rank it 7th, just behind the Gemini 2.0 and OpenAI 4o/o1 models. This is by far the highest ranking openly licensed model. The really impressive thing about DeepSeek v3 is the training cost. The model was trained on 2,788,000 H800 GPU hours at an estimated cost of $5,576,000. Llama 3.1 405B trained 30,840,000 GPU hours‚Äî11x that used by DeepSeek v3, for a model that benchmarks slightly worse. Those US export regulations on GPUs to China seem to have inspired some very effective training optimizations! The environmental impact got better A welcome result of the increased efficiency of the models‚Äîboth the hosted ones and the ones I can run locally‚Äîis that the energy usage and environmental impact of running a prompt has dropped enormously over the past couple of years. OpenAI themselves are charging 100x less for a prompt compared to the GPT-3 days. I have it on good authority that neither Google Gemini nor Amazon Nova (two of the least expensive model providers) are running prompts at a loss. I think this means that, as individual users, we don‚Äôt need to feel any guilt at all for the energy consumed by the vast majority of our prompts. The impact is likely neglible compared to driving a car down the street or maybe even watching a video on YouTube. Likewise, training. DeepSeek v3 training for less than $6m is a fantastic sign that training costs can and should continue to drop. For less efficient models I find it useful to compare their energy usage to commercial flights. The largest Llama 3 model cost about the same as a single digit number of fully loaded passenger flights from New York to London. That‚Äôs certainly not nothing, but once trained that model can be used by millions of people at no extra training cost. The environmental impact got much, much worse The much bigger problem here is the enormous competitive buildout of the infrastructure that is imagined to be necessary for these models in the future. Companies like Google, Meta, Microsoft and Amazon are all spending billions of dollars rolling out new datacenters, with a very material impact on the electricity grid and the environment. There‚Äôs even talk of spinning up new nuclear power stations, but those can take decades. Is this infrastructure necessary? DeepSeek v3‚Äôs $6m training cost and the continued crash in LLM prices might hint that it‚Äôs not. But would you want to be the big tech executive that argued NOT to build out this infrastructure only to be proven wrong in a few years‚Äô time? An interesting point of comparison here could be the way railways rolled out around the world in the 1800s. Constructing these required enormous investments and had a massive environmental impact, and many of the lines that were built turned out to be unnecessary‚Äîsometimes multiple lines from different companies serving the exact same routes! The resulting bubbles contributed to several financial crashes, see Wikipedia for Panic of 1873, Panic of 1893, Panic of 1901 and the UK‚Äôs Railway Mania. They left us with a lot of useful infrastructure and a great deal of bankruptcies and environmental damage. The year of slop 2024 was the year that the word \"slop\" became a term of art. I wrote about this in May, expanding on this tweet by @deepfates: Watching in real time as ‚Äúslop‚Äù becomes a term of art. the way that ‚Äúspam‚Äù became the term for unwanted emails, ‚Äúslop‚Äù is going in the dictionary as the term for unwanted AI generated content I expanded that definition a tiny bit to this: Slop describes AI-generated content that is both unrequested and unreviewed. I ended up getting quoted talking about slop in both the Guardian and the NY Times. Here‚Äôs what I said in the NY TImes: Society needs concise ways to talk about modern A.I. ‚Äî both the positives and the negatives. ‚ÄòIgnore that email, it‚Äôs spam,‚Äô and ‚ÄòIgnore that article, it‚Äôs slop,‚Äô are both useful lessons. I love the term ‚Äúslop‚Äù because it so succinctly captures one of the ways we should not be using generative AI! Slop was even in the running for Oxford Word of the Year 2024, but it lost to brain rot. Synthetic training data works great An idea that surprisingly seems to have stuck in the public consciousness is that of ‚Äúmodel collapse‚Äù. This was first described in the paper The Curse of Recursion: Training on Generated Data Makes Models Forget in May 2023, and repeated in Nature in July 2024 with the more eye-catching headline AI models collapse when trained on recursively generated data. The idea is seductive: as the internet floods with AI-generated slop the models themselves will degenerate, feeding on their own output in a way that leads to their inevitable demise! That‚Äôs clearly not happening. Instead, we are seeing AI labs increasingly train on synthetic content‚Äîdeliberately creating artificial data to help steer their models in the right way. One', '<3-hop>\\n\\nof the best descriptions I‚Äôve seen of this comes from the Phi-4 technical report, which included this: Synthetic data as a substantial component of pretraining is becoming increasingly common, and the Phi series of models has consistently emphasized the importance of synthetic data. Rather than serving as a cheap substitute for organic data, synthetic data has several direct advantages over organic data. Structured and Gradual Learning. In organic datasets, the relationship between tokens is often complex and indirect. Many reasoning steps may be required to connect the current token to the next, making it challenging for the model to learn effectively from next-token prediction. By contrast, each token generated by a language model is by definition predicted by the preceding tokens, making it easier for a model to follow the resulting reasoning patterns. Another common technique is to use larger models to help create training data for their smaller, cheaper alternatives‚Äîa trick used by an increasing number of labs. DeepSeek v3 used ‚Äúreasoning‚Äù data created by DeepSeek-R1. Meta‚Äôs Llama 3.3 70B fine-tuning used over 25M synthetically generated examples. Careful design of the training data that goes into an LLM appears to be the entire game for creating these models. The days of just grabbing a full scrape of the web and indiscriminately dumping it into a training run are long gone. LLMs somehow got even harder to use A drum I‚Äôve been banging for a while is that LLMs are power-user tools‚Äîthey‚Äôre chainsaws disguised as kitchen knives. They look deceptively simple to use‚Äîhow hard can it be to type messages to a chatbot?‚Äîbut in reality you need a huge depth of both understanding and experience to make the most of them and avoid their many pitfalls. If anything, this problem got worse in 2024. We‚Äôve built computer systems you can talk to in human language, that will answer your questions and usually get them right! ... depending on the question, and how you ask it, and whether it‚Äôs accurately reflected in the undocumented and secret training set. The number of available systems has exploded. Different systems have different tools they can apply to your problems‚Äîlike Python and JavaScript and web search and image generation and maybe even database lookups... so you‚Äôd better understand what those tools are, what they can do and how to tell if the LLM used them or not. Did you know ChatGPT has two entirely different ways of running Python now? Want to build a Claude Artifact that talks to an external API? You‚Äôd better understand CSP and CORS HTTP headers first. The models may have got more capable, but most of the limitations remained the same. OpenAI‚Äôs o1 may finally be able to (mostly) count the Rs in strawberry, but its abilities are still limited by its nature as an LLM and the constraints placed on it by the harness it‚Äôs running in. o1 can‚Äôt run web searches or use Code Interpreter, but GPT-4o can‚Äîboth in that same ChatGPT UI. (o1 will pretend to do those things if you ask it to, a regression to the URL hallucinations bug from early 2023). What are we doing about this? Not much. Most users are thrown in at the deep end. The default LLM chat UI is like taking brand new computer users, dropping them into a Linux terminal and expecting them to figure it all out. Meanwhile, it‚Äôs increasingly common for end users to develop wildly inaccurate mental models of how these things work and what they are capable of. I‚Äôve seen so many examples of people trying to win an argument with a screenshot from ChatGPT‚Äîan inherently ludicrous proposition, given the inherent unreliability of these models crossed with the fact that you can get them to say anything if you prompt them right. There‚Äôs a flipside to this too: a lot of better informed people have sworn off LLMs entirely because they can‚Äôt see how anyone could benefit from a tool with so many flaws. The key skill in getting the most out of LLMs is learning to work with tech that is both inherently unreliable and incredibly powerful at the same time. This is a decidedly non-obvious skill to acquire! There is so much space for helpful education content here, but we need to do do a lot better than outsourcing it all to AI grifters with bombastic Twitter threads. Knowledge is incredibly unevenly distributed Most people have heard of ChatGPT by now. How many have heard of Claude? The knowledge gap between the people who actively follow this stuff and the 99% of the population who do not is vast. The pace of change doesn‚Äôt help either. In just the past month we‚Äôve seen general availability of live interfaces where you can point your phone‚Äôs camera at something and talk about it with your voice... and optionally have it pretend to be Santa. Most self-certified nerds haven‚Äôt even tried that yet. Given the ongoing (and potential) impact on society that this technology has, I don‚Äôt think the size of this gap is healthy. I‚Äôd like to see a lot more effort put into improving this. LLMs need better criticism A lot of people absolutely hate this stuff. In some of the spaces I hang out (Mastodon, Bluesky, Lobste.rs, even Hacker News on occasion) even suggesting that ‚ÄúLLMs are useful‚Äù can be enough to kick off a huge fight. I get it. There are plenty of reasons to dislike this technology‚Äîthe environmental impact, the (lack of) ethics of the training data, the lack of reliability, the negative applications, the potential impact on people‚Äôs jobs. LLMs absolutely warrant criticism. We need to be talking through these problems, finding ways to mitigate them and helping people learn how to use these tools responsibly in ways where the positive applications outweigh the negative. I like people who are skeptical of this stuff. The hype has been deafening for more than two years now, and there are enormous quantities of snake oil and misinformation out there. A lot']",
                  "The use of synthetic training data offers several advantages over organic data in the development of large language models (LLMs). According to the Phi-4 technical report, synthetic data is not merely a cheaper substitute but provides specific benefits that enhance model training. \n\nOne key advantage is **structured and gradual learning**. Synthetic data can be designed to make the relationship between tokens clearer and more direct, simplifying the reasoning process for the model. Unlike organic datasets, where complex and indirect token relationships can make learning difficult, synthetic data allows each token to be predicted based on preceding tokens in a way that makes reasoning patterns easier for the model to learn.\n\nAnother advantage is **careful design and targeted creation of training data**. The report highlights that instead of indiscriminately scraping web data, modern training involves using larger models to generate synthetic data tailored for training smaller or cheaper models. Examples include DeepSeek v3, which used reasoning data created by a larger model, and Meta‚Äôs Llama 3.3 70B, which employed over 25 million synthetically generated examples. This deliberate crafting of training data helps steer models in desired directions and improves their capabilities.\n\nIn summary, synthetic data enhances model training by enabling structured, reasoning-friendly data, and by allowing precise, purpose-built datasets that improve the efficiency and effectiveness of large language model development.",
                  "Synthetic training data offers several direct advantages over organic data in the development of large language models. According to the Phi-4 technical report, synthetic data enables structured and gradual learning because each token generated is predicted by the preceding tokens, making it easier for models to follow reasoning patterns. In contrast, organic datasets often have complex and indirect relationships between tokens, which can make effective learning more challenging. Additionally, synthetic data allows for deliberate design and curation, helping steer models in desired directions. Recent model training practices illustrate these benefits: for example, DeepSeek v3 used 'reasoning' data created by DeepSeek-R1, and Meta‚Äôs Llama 3.3 70B fine-tuning involved over 25 million synthetically generated examples. These practices show that synthetic data is not just a substitute for organic data but a tool for more effective and targeted model training.",
                  "multi_hop_abstract_query_synthesizer"
                ],
                [
                  "7",
                  "How have improvements in LLM efficiency over the past year influenced both the environmental impact of AI model training and the cost of using large language models, according to recent trends?",
                  "['If you can gather the right data, and afford to pay for the GPUs to train it, you can build an LLM.\\n\\nA year ago, the only organization that had released a generally useful LLM was OpenAI. We‚Äôve now seen better-than-GPT-3 class models produced by Anthropic, Mistral, Google, Meta, EleutherAI, Stability AI, TII in Abu Dhabi (Falcon), Microsoft Research, xAI, Replit, Baidu and a bunch of other organizations.\\n\\nThe training cost (hardware and electricity) is still significant‚Äîinitially millions of dollars, but that seems to have dropped to the tens of thousands already. Microsoft‚Äôs Phi-2 claims to have used ‚Äú14 days on 96 A100 GPUs‚Äù, which works out at around $35,000 using current Lambda pricing.', 'LLM prices crashed, thanks to competition and increased efficiency\\n\\nThe past twelve months have seen a dramatic collapse in the cost of running a prompt through the top tier hosted LLMs.\\n\\nIn December 2023 (here‚Äôs the Internet Archive for the OpenAI pricing page) OpenAI were charging $30/million input tokens for GPT-4, $10/mTok for the then-new GPT-4 Turbo and $1/mTok for GPT-3.5 Turbo.\\n\\nToday $30/mTok gets you OpenAI‚Äôs most expensive model, o1. GPT-4o is $2.50 (12x cheaper than GPT-4) and GPT-4o mini is $0.15/mTok‚Äî200x cheaper than GPT-4, nearly 7x cheaper than GPT-3.5 and massively more capable than that model.\\n\\nOther model providers charge even less. Anthropic‚Äôs Claude 3 Haiku (from March, but still their cheapest model) is $0.25/mTok. Google‚Äôs Gemini 1.5 Flash is $0.075/mTok and their Gemini 1.5 Flash 8B is $0.0375/mTok‚Äîthat‚Äôs 27x cheaper than GPT-3.5 Turbo last year.\\n\\nI‚Äôve been tracking these pricing changes under my llm-pricing tag.', 'So training an LLM still isn‚Äôt something a hobbyist can afford, but it‚Äôs no longer the sole domain of the super-rich. I like to compare the difficulty of training an LLM to that of building a suspension bridge‚Äînot trivial, but hundreds of countries around the world have figured out how to do it. (Correction: Wikipedia‚Äôs Suspension bridges by country category lists 44 countries).\\n\\nYou can run LLMs on your own devices\\n\\nIn January of this year, I thought it would be years before I could run a useful LLM on my own computer. GPT-3 and 3.5 were pretty much the only games in town, and I thought that even if the model weights were available it would take a $10,000+ server to run them.\\n\\nThen in February, Meta released Llama. And a few weeks later in March, Georgi Gerganov released code that got it working on a MacBook.\\n\\nI wrote about how Large language models are having their Stable Diffusion moment, and with hindsight that was a very good call!', 'I‚Äôve been tracking these pricing changes under my llm-pricing tag.\\n\\nThese price drops are driven by two factors: increased competition and increased efficiency. The efficiency thing is really important for everyone who is concerned about the environmental impact of LLMs. These price drops tie directly to how much energy is being used for running prompts.\\n\\nThere‚Äôs still plenty to worry about with respect to the environmental impact of the great AI datacenter buildout, but a lot of the concerns over the energy cost of individual prompts are no longer credible.\\n\\nHere‚Äôs a fun napkin calculation: how much would it cost to generate short descriptions of every one of the 68,000 photos in my personal photo library using Google‚Äôs Gemini 1.5 Flash 8B (released in October), their cheapest model?\\n\\nEach photo would need 260 input tokens and around 100 output tokens.', 'Since then, almost every major LLM (and most of the image generation models) have also been trained on unlicensed data.\\n\\nJust this week, the New York Times launched a landmark lawsuit against OpenAI and Microsoft over this issue. The 69 page PDF is genuinely worth reading‚Äîespecially the first few pages, which lay out the issues in a way that‚Äôs surprisingly easy to follow. The rest of the document includes some of the clearest explanations of what LLMs are, how they work and how they are built that I‚Äôve read anywhere.\\n\\nThe legal arguments here are complex. I‚Äôm not a lawyer, but I don‚Äôt think this one will be easily decided. Whichever way it goes, I expect this case to have a profound impact on how this technology develops in the future.\\n\\nLaw is not ethics. Is it OK to train models on people‚Äôs content without their permission, when those models will then be used in ways that compete with those people?']",
                  "['<1-hop>\\n\\nThe rise of inference-scaling ‚Äúreasoning‚Äù models Was the best currently available LLM trained in China for less than $6m? The environmental impact got better The environmental impact got much, much worse The year of slop Synthetic training data works great LLMs somehow got even harder to use Knowledge is incredibly unevenly distributed LLMs need better criticism Everything tagged ‚Äúllms‚Äù on my blog in 2024 The GPT-4 barrier was comprehensively broken In my December 2023 review I wrote about how We don‚Äôt yet know how to build GPT-4‚ÄîOpenAI‚Äôs best model was almost a year old at that point, yet no other AI lab had produced anything better. What did OpenAI know that the rest of us didn‚Äôt? I‚Äôm relieved that this has changed completely in the past twelve months. 18 organizations now have models on the Chatbot Arena Leaderboard that rank higher than the original GPT-4 from March 2023 (GPT-4-0314 on the board)‚Äî70 models in total. Screenshot of a comparison table showing AI model rankings. Table headers: Rank (UB), Rank (StyleCtrl), Model, Arena Score, 95% CI, Votes, Organization, License. Shows 12 models including GLM-4-0520, Llama-3-70B-Instruct, Gemini-1.5-Flash-8B-Exp-0827, with rankings, scores, and licensing details. Models range from rank 52-69 with Arena scores between 1186-1207. The earliest of those was Google‚Äôs Gemini 1.5 Pro, released in February. In addition to producing GPT-4 level outputs, it introduced several brand new capabilities to the field‚Äîmost notably its 1 million (and then later 2 million) token input context length, and the ability to input video. I wrote about this at the time in The killer app of Gemini Pro 1.5 is video, which earned me a short appearance as a talking head in the Google I/O opening keynote in May. Gemini 1.5 Pro also illustrated one of the key themes of 2024: increased context lengths. Last year most models accepted 4,096 or 8,192 tokens, with the notable exception of Claude 2.1 which accepted 200,000. Today every serious provider has a 100,000+ token model, and Google‚Äôs Gemini series accepts up to 2 million. Longer inputs dramatically increase the scope of problems that can be solved with an LLM: you can now throw in an entire book and ask questions about its contents, but more importantly you can feed in a lot of example code to help the model correctly solve a coding problem. LLM use-cases that involve long inputs are far more interesting to me than short prompts that rely purely on the information already baked into the model weights. Many of my tools were built using this pattern. Getting back to models that beat GPT-4: Anthropic‚Äôs Claude 3 series launched in March, and Claude 3 Opus quickly became my new favourite daily-driver. They upped the ante even more in June with the launch of Claude 3.5 Sonnet‚Äîa model that is still my favourite six months later (though it got a significant upgrade on October 22, confusingly keeping the same 3.5 version number. Anthropic fans have since taken to calling it Claude 3.6). Then there‚Äôs the rest. If you browse the Chatbot Arena leaderboard today‚Äîstill the most useful single place to get a vibes-based evaluation of models‚Äîyou‚Äôll see that GPT-4-0314 has fallen to around 70th place. The 18 organizations with higher scoring models are Google, OpenAI, Alibaba, Anthropic, Meta, Reka AI, 01 AI, Amazon, Cohere, DeepSeek, Nvidia, Mistral, NexusFlow, Zhipu AI, xAI, AI21 Labs, Princeton and Tencent. Training a GPT-4 beating model was a huge deal in 2023. In 2024 it‚Äôs an achievement that isn‚Äôt even particularly notable, though I personally still celebrate any time a new organization joins that list. Some of those GPT-4 models run on my laptop My personal laptop is a 64GB M2 MacBook Pro from 2023. It‚Äôs a powerful machine, but it‚Äôs also nearly two years old now‚Äîand crucially it‚Äôs the same laptop I‚Äôve been using ever since I first ran an LLM on my computer back in March 2023 (see Large language models are having their Stable Diffusion moment). That same laptop that could just about run a GPT-3-class model in March last year has now run multiple GPT-4 class models! Some of my notes on that: Qwen2.5-Coder-32B is an LLM that can code well that runs on my Mac talks about Qwen2.5-Coder-32B in November‚Äîan Apache 2.0 licensed model! I can now run a GPT-4 class model on my laptop talks about running Meta‚Äôs Llama 3.3 70B (released in December) This remains astonishing to me. I thought a model with the capabilities and output quality of GPT-4 needed a datacenter class server with one or more $40,000+ GPUs. These models take up enough of my 64GB of RAM that I don‚Äôt run them often‚Äîthey don‚Äôt leave much room for anything else. The fact that they run at all is a testament to the incredible training and inference performance gains that we‚Äôve figured out over the past year. It turns out there was a lot of low-hanging fruit to be harvested in terms of model efficiency. I expect there‚Äôs still more to come. Meta‚Äôs Llama 3.2 models deserve a special mention. They may not be GPT-4 class, but at 1B and 3B sizes they punch massively above their weight. I run Llama 3.2 3B on my iPhone using the free MLC Chat iOS app and it‚Äôs a shockingly capable model for its tiny (<2GB) size. Try firing it up and asking it for ‚Äúa plot outline of a Netflix Christmas movie where a data journalist falls in love with a local ceramacist‚Äù. Here‚Äôs what I got, at a respectable 20 tokens per second: MLC Chat: Llama - [System] Ready to chat. a plot outline of a Netflix Christmas movie where a data journalist falls in love with a local ceramacist. Show as Markdown is turned on. Here\\'s a plot outline for a Netflix Christmas movie: Title: \"Love in the Clay\" Plot Outline: We meet our protagonist, JESSICA, a data journalist who has just returned to her hometown of Willow Creek, a small, charming town nestled in the snow-covered mountains. She\\'s back to work', \"<2-hop>\\n\\non a story about the town's history and the effects of gentrification on the local community. Here‚Äôs the rest of the transcript. It‚Äôs bland and generic, but my phone can pitch bland and generic Christmas movies to Netflix now! LLM prices crashed, thanks to competition and increased efficiency The past twelve months have seen a dramatic collapse in the cost of running a prompt through the top tier hosted LLMs. In December 2023 (here‚Äôs the Internet Archive for the OpenAI pricing page) OpenAI were charging $30/million input tokens for GPT-4, $10/mTok for the then-new GPT-4 Turbo and $1/mTok for GPT-3.5 Turbo. Today $30/mTok gets you OpenAI‚Äôs most expensive model, o1. GPT-4o is $2.50 (12x cheaper than GPT-4) and GPT-4o mini is $0.15/mTok‚Äî200x cheaper than GPT-4, nearly 7x cheaper than GPT-3.5 and massively more capable than that model. Other model providers charge even less. Anthropic‚Äôs Claude 3 Haiku (from March, but still their cheapest model) is $0.25/mTok. Google‚Äôs Gemini 1.5 Flash is $0.075/mTok and their Gemini 1.5 Flash 8B is $0.0375/mTok‚Äîthat‚Äôs 27x cheaper than GPT-3.5 Turbo last year. I‚Äôve been tracking these pricing changes under my llm-pricing tag. These price drops are driven by two factors: increased competition and increased efficiency. The efficiency thing is really important for everyone who is concerned about the environmental impact of LLMs. These price drops tie directly to how much energy is being used for running prompts. There‚Äôs still plenty to worry about with respect to the environmental impact of the great AI datacenter buildout, but a lot of the concerns over the energy cost of individual prompts are no longer credible. Here‚Äôs a fun napkin calculation: how much would it cost to generate short descriptions of every one of the 68,000 photos in my personal photo library using Google‚Äôs Gemini 1.5 Flash 8B (released in October), their cheapest model? Each photo would need 260 input tokens and around 100 output tokens. 260 * 68,000 = 17,680,000 input tokens 17,680,000 * $0.0375/million = $0.66 100 * 68,000 = 6,800,000 output tokens 6,800,000 * $0.15/million = $1.02 That‚Äôs a total cost of $1.68 to process 68,000 images. That‚Äôs so absurdly cheap I had to run the numbers three times to confirm I got it right. How good are those descriptions? Here‚Äôs what I got from this command: llm -m gemini-1.5-flash-8b-latest describe -a IMG_1825.jpeg Against this photo of butterflies at the California Academy of Sciences: A photo of two butterflies feeding on a red tray A shallow dish, likely a hummingbird or butterfly feeder, is red. Pieces of orange slices of fruit are visible inside the dish. Two butterflies are positioned in the feeder, one is a dark brown/black butterfly with white/cream-colored markings. The other is a large, brown butterfly with patterns of lighter brown, beige, and black markings, including prominent eye spots. The larger brown butterfly appears to be feeding on the fruit. 260 input tokens, 92 output tokens. Cost approximately 0.0024 cents (that‚Äôs less than a 400th of a cent). This increase in efficiency and reduction in price is my single favourite trend from 2024. I want the utility of LLMs at a fraction of the energy cost and it looks like that‚Äôs what we‚Äôre getting. Multimodal vision is common, audio and video are starting to emerge My butterfly example above illustrates another key trend from 2024: the rise of multi-modal LLMs. A year ago the single most notable example of these was GPT-4 Vision, released at OpenAI‚Äôs DevDay in November 2023. Google‚Äôs multi-modal Gemini 1.0 was announced on December 7th 2023 so it also (just) makes it into the 2023 window. In 2024, almost every significant model vendor released multi-modal models. We saw the Claude 3 series from Anthropic in March, Gemini 1.5 Pro in April (images, audio and video), then September brought Qwen2-VL and Mistral‚Äôs Pixtral 12B and Meta‚Äôs Llama 3.2 11B and 90B vision models. We got audio input and output from OpenAI in October, then November saw SmolVLM from Hugging Face and December saw image and video models from Amazon Nova. In October I upgraded my LLM CLI tool to support multi-modal models via attachments. It now has plugins for a whole collection of different vision models. I think people who complain that LLM improvement has slowed are often missing the enormous advances in these multi-modal models. Being able to run prompts against images (and audio and video) is a fascinating new way to apply these models. Voice and live camera mode are science fiction come to life The audio and live video modes that have started to emerge deserve a special mention. The ability to talk to ChatGPT first arrived in September 2023, but it was mostly an illusion: OpenAI used their excellent Whisper speech-to-text model and a new text-to-speech model (creatively named tts-1) to enable conversations with the ChatGPT mobile apps, but the actual model just saw text. The May 13th announcement of GPT-4o included a demo of a brand new voice mode, where the true multi-modal GPT-4o (the o is for ‚Äúomni‚Äù) model could accept audio input and output incredibly realistic sounding speech without needing separate TTS or STT models. The demo also sounded conspicuously similar to Scarlett Johansson... and after she complained the voice from the demo, Skye, never made it to a production product. The delay in releasing the new voice mode after the initial demo caused quite a lot of confusion. I wrote about that in ChatGPT in ‚Äú4o‚Äù mode is not running the new features yet. When ChatGPT Advanced Voice mode finally did roll out (a slow roll from August through September) it was spectacular. I‚Äôve been using it extensively on walks with my dog and it‚Äôs amazing how much the improvement in intonation elevates the material. I‚Äôve also had a lot of fun experimenting with the OpenAI audio APIs. Even more fun: Advanced Voice mode can do accents! Here‚Äôs what happened when I told it I need you to pretend to be a California brown pelican with a very thick Russian accent, but\"]",
                  "Improvements in LLM efficiency over the past year have significantly influenced both the environmental impact of AI model training and the cost of using large language models. According to recent trends, increased efficiency has contributed to a dramatic decrease in the costs associated with running and training LLMs. The training costs, which initially were in the millions of dollars, have already dropped to tens of thousands, making training an LLM more accessible beyond just the super-rich. For example, Microsoft‚Äôs Phi-2 reportedly used around $35,000 worth of hardware and electricity for training over 14 days, indicating that costs are now more manageable.\n\nOn the usage side, the cost of deploying and prompting LLMs has plummeted due to competition and efficiency gains. Prices for API access to top-tier models like GPT-4 Turbo, GPT-3.5 Turbo, and others have decreased by factors of 7 to 200 times, with some models now costing as little as $0.0375 per million tokens. This reduction in cost makes using large language models more affordable for a broader range of users.\n\nRegarding environmental impact, increased efficiency means that less energy is required to generate prompts. The trend suggests that concerns about the energy costs of individual prompts are less credible now, as the efficiency improvements have led to lower energy consumption per task. While concerns about the environmental footprint of large datacenter infrastructure remain, the direct energy cost associated with running prompts has become much lower, mitigating some of the previous environmental worries tied to AI's energy use.",
                  "Improvements in LLM efficiency over the past year have significantly reduced both the environmental impact of AI model training and the cost of using large language models. As described, the dramatic collapse in the cost of running prompts through top-tier hosted LLMs is directly tied to increased efficiency and competition. For example, OpenAI‚Äôs GPT-4o is now 12 times cheaper than GPT-4, and other providers like Google and Anthropic offer even lower prices. This efficiency means that the energy cost per prompt has dropped, alleviating many concerns about the environmental impact of individual LLM usage. While the overall environmental impact of large-scale AI datacenter buildouts remains a concern, the energy required for each prompt is now much lower, making LLMs more accessible and environmentally sustainable. These trends are exemplified by the ability to process large datasets, such as generating descriptions for 68,000 photos, at a negligible cost and energy footprint.",
                  "multi_hop_abstract_query_synthesizer"
                ],
                [
                  "8",
                  "How has ChatGPT been discussed in relation to both its practical applications and its societal impact, including concerns about job displacement and ethical considerations, as reflected in the 2024 and 2023 blog posts and analytics?",
                  "['How should we feel about this as software engineers?\\n\\nOn the one hand, this feels like a threat: who needs a programmer if ChatGPT can write code for you?\\n\\nOn the other hand, as software engineers we are better placed to take advantage of this than anyone else. We‚Äôve all been given weird coding interns‚Äîwe can use our deep knowledge to prompt them to solve coding problems more effectively than anyone else can.\\n\\nThe ethics of this space remain diabolically complex\\n\\nIn September last year Andy Baio and I produced the first major story on the unlicensed training data behind Stable Diffusion.\\n\\nSince then, almost every major LLM (and most of the image generation models) have also been trained on unlicensed data.', 'Law is not ethics. Is it OK to train models on people‚Äôs content without their permission, when those models will then be used in ways that compete with those people?\\n\\nAs the quality of results produced by AI models has increased over the year, these questions have become even more pressing.\\n\\nThe impact on human society in terms of these models is already huge, if difficult to objectively measure.\\n\\nPeople have certainly lost work to them‚Äîanecdotally, I‚Äôve seen this for copywriters, artists and translators.\\n\\nThere are a great deal of untold stories here. I‚Äôm hoping 2024 sees significant amounts of dedicated journalism on this topic.\\n\\nMy blog in 2023\\n\\nHere‚Äôs a tag cloud for content I posted to my blog in 2023 (generated using Django SQL Dashboard):\\n\\nTag cloud words in order of size: ai, generativeai, llms, openai, chatgpt, projects, python, datasette, ethics, llama, homebrewllms, sqlite, gpt3, promptengineering, promptinjection, llm, security, opensource, gpt4, weeknotes', 'Did you know ChatGPT has two entirely different ways of running Python now?\\n\\nWant to build a Claude Artifact that talks to an external API? You‚Äôd better understand CSP and CORS HTTP headers first.\\n\\nThe models may have got more capable, but most of the limitations remained the same. OpenAI‚Äôs o1 may finally be able to (mostly) count the Rs in strawberry, but its abilities are still limited by its nature as an LLM and the constraints placed on it by the harness it‚Äôs running in. o1 can‚Äôt run web searches or use Code Interpreter, but GPT-4o can‚Äîboth in that same ChatGPT UI. (o1 will pretend to do those things if you ask it to, a regression to the URL hallucinations bug from early 2023).\\n\\nWhat are we doing about this? Not much. Most users are thrown in at the deep end. The default LLM chat UI is like taking brand new computer users, dropping them into a Linux terminal and expecting them to figure it all out.', 'The most recent twist, again from December (December was a lot) is live video. ChatGPT voice mode now provides the option to share your camera feed with the model and talk about what you can see in real time. Google Gemini have a preview of the same feature, which they managed to ship the day before ChatGPT did.\\n\\nThese abilities are just a few weeks old at this point, and I don‚Äôt think their impact has been fully felt yet. If you haven‚Äôt tried them out yet you really should.\\n\\nBoth Gemini and OpenAI offer API access to these features as well. OpenAI started with a WebSocket API that was quite challenging to use, but in December they announced a new WebRTC API which is much easier to get started with. Building a web app that a user can talk to via voice is easy now!\\n\\nPrompt driven app generation is a commodity already\\n\\nThis was possible with GPT-4 in 2023, but the value it provides became evident in 2024.', 'Article Visitors Pageviews Bing: ‚ÄúI will not harm you unless you harm me first‚Äù 1.1M 1.3M Leaked Google document: ‚ÄúWe Have No Moat, And Neither Does OpenAI‚Äù 132k 162k Large language models are having their Stable Diffusion moment 121k 150k Prompt injection: What‚Äôs the worst that can happen? 79.8k 95.9k Embeddings: What they are and why they matter 61.7k 79.3k Catching up on the weird world of LLMs 61.6k 85.9k llamafile is the new best way to run an LLM on your own computer 52k 66k Prompt injection explained, with video, slides, and a transcript 51k 61.9k AI-enhanced development makes me more ambitious with my projects 49.6k 60.1k Understanding GPT tokenizers 49.5k 61.1k Exploring GPTs: ChatGPT in a trench coat? 46.4k 58.5k Could you train a ChatGPT-beating model for $85,000 and run it in a browser? 40.5k 49.2k How to implement Q&A against your documentation with GPT3, embeddings and Datasette 37.3k 44.9k Lawyer cites fake cases invented by ChatGPT, judge is not amused 37.1k 47.4k Now']",
                  "['<1-hop>\\n\\nof very bad decisions are being made based on that hype. Being critical is a virtue. If we want people with decision-making authority to make good decisions about how to apply these tools we first need to acknowledge that there ARE good applications, and then help explain how to put those into practice while avoiding the many unintiutive traps. (If you still don‚Äôt think there are any good applications at all I‚Äôm not sure why you made it to this point in the article!) I think telling people that this whole field is environmentally catastrophic plagiarism machines that constantly make things up is doing those people a disservice, no matter how much truth that represents. There is genuine value to be had here, but getting to that value is unintuitive and needs guidance. Those of us who understand this stuff have a duty to help everyone else figure it out. Everything tagged ‚Äúllms‚Äù on my blog in 2024 Because I undoubtedly missed a whole bunch of things, here‚Äôs every long-form post I wrote in 2024 that I tagged with llms: January 7th: It‚Äôs OK to call it Artificial Intelligence 9th: What I should have said about the term Artificial Intelligence 17th: Talking about Open Source LLMs on Oxide and Friends 26th: LLM 0.13: The annotated release notes February 21st: The killer app of Gemini Pro 1.5 is video March 5th: Prompt injection and jailbreaking are not the same thing 8th: The GPT-4 barrier has finally been broken 22nd: Claude and ChatGPT for ad-hoc sidequests 23rd: Building and testing C extensions for SQLite with ChatGPT Code Interpreter 26th: llm cmd undo last git commit‚Äîa new plugin for LLM April 8th: Building files-to-prompt entirely using Claude 3 Opus 10th: Three major LLM releases in 24 hours (plus weeknotes) 17th: AI for Data Journalism: demonstrating what we can do with this stuff right now 22nd: Options for accessing Llama 3 from the terminal using LLM May 8th: Slop is the new name for unwanted AI-generated content 15th: ChatGPT in ‚Äú4o‚Äù mode is not running the new features yet 29th: Training is not the same as chatting: ChatGPT and other LLMs don‚Äôt remember everything you say June 6th: Accidental prompt injection against RAG applications 10th: Thoughts on the WWDC 2024 keynote on Apple Intelligence 17th: Language models on the command-line 21st: Building search-based RAG using Claude, Datasette and Val Town 27th: Open challenges for AI engineering July 14th: Imitation Intelligence, my keynote for PyCon US 2024 19th: Weeknotes: GPT-4o mini, LLM 0.15, sqlite-utils 3.37 and building a staging environment August 6th: Weeknotes: a staging environment, a Datasette alpha and a bunch of new LLMs 8th: django-http-debug, a new Django app mostly written by Claude 23rd: Claude‚Äôs API now supports CORS requests, enabling client-side applications 26th: Building a tool showing how Gemini Pro can return bounding boxes for objects in images September 6th: Calling LLMs from client-side JavaScript, converting PDFs to HTML + weeknotes 10th: Notes from my appearance on the Software Misadventures Podcast 12th: Notes on OpenAI‚Äôs new o1 chain-of-thought models 20th: Notes on using LLMs for code 29th: NotebookLM‚Äôs automatically generated podcasts are surprisingly effective 30th: Weeknotes: Three podcasts, two trips and a new plugin system October 1st: OpenAI DevDay 2024 live blog 2nd: OpenAI DevDay: Let‚Äôs build developer tools, not digital God 15th: ChatGPT will happily write you a thinly disguised horoscope 17th: Video scraping: extracting JSON data from a 35 second screen capture for less than 1/10th of a cent 18th: Experimenting with audio input and output for the OpenAI Chat Completion API 19th: Running Llama 3.2 Vision and Phi-3.5 Vision on a Mac with mistral.rs 21st: Everything I built with Claude Artifacts this week 22nd: Initial explorations of Anthropic‚Äôs new Computer Use capability 24th: Notes on the new Claude analysis JavaScript code execution tool 27th: Run a prompt to generate and execute jq programs using llm-jq 29th: You can now run prompts against images, audio and video in your terminal using LLM 30th: WÃ∂eÃ∂eÃ∂kÃ∂nÃ∂oÃ∂tÃ∂eÃ∂sÃ∂ Monthnotes for October November 4th: Claude 3.5 Haiku 7th: Project: VERDAD‚Äîtracking misinformation in radio broadcasts using Gemini 1.5 12th: Qwen2.5-Coder-32B is an LLM that can code well that runs on my Mac 19th: Notes from Bing Chat‚ÄîOur First Encounter With Manipulative AI 25th: Ask questions of SQLite databases and CSV/JSON files in your terminal December 4th: First impressions of the new Amazon Nova LLMs (via a new llm-bedrock plugin) 7th: Prompts.js 9th: I can now run a GPT-4 class model on my laptop 10th: ChatGPT Canvas can make API requests now, but it‚Äôs complicated 11th: Gemini 2.0 Flash: An outstanding multi-modal LLM with a sci-fi streaming mode 19th: Building Python tools with a one-shot prompt using uv run and Claude Projects 19th: Gemini 2.0 Flash ‚ÄúThinking mode‚Äù 20th: December in LLMs has been a lot 20th: Live blog: the 12th day of OpenAI‚Äî‚ÄúEarly evals for OpenAI o3‚Äù 24th: Trying out QvQ‚ÄîQwen‚Äôs new visual reasoning model 31st: Things we learned about LLMs in 2024 (This list generated using Django SQL Dashboard with a SQL query written for me by Claude.) Posted 31st December 2024 at 6:07 pm ¬∑ Follow me on Mastodon, Bluesky, Twitter or subscribe to my newsletter More recent articles Feed a video to a vision LLM as a sequence of JPEG frames on the CLI (also LLM 0.25) - 5th May 2025 Two publishers and three authors fail to understand what \"vibe coding\" means - 1st May 2025 Understanding the recent criticism of the Chatbot Arena - 30th April 2025 This is Things we learned about LLMs in 2024 by Simon Willison, posted on 31st December 2024. Part of series LLMs annual review Stuff we figured out about AI in 2023 - Dec. 31, 2023, 11:59 p.m. Things we learned about LLMs in 2024 - Dec. 31, 2024, 6:07 p.m. google 360 ai 1262 openai 289 generative-ai 1089 local-llms 113 llms 1076 anthropic 136 gemini 80 meta 32 llm-reasoning 44 long-context 15 ai-energy-usage 5 Next: Ending a year long posting streak Previous: Trying out', '<2-hop>\\n\\nMicrosoft over this issue. The 69 page PDF is genuinely worth reading‚Äîespecially the first few pages, which lay out the issues in a way that‚Äôs surprisingly easy to follow. The rest of the document includes some of the clearest explanations of what LLMs are, how they work and how they are built that I‚Äôve read anywhere. The legal arguments here are complex. I‚Äôm not a lawyer, but I don‚Äôt think this one will be easily decided. Whichever way it goes, I expect this case to have a profound impact on how this technology develops in the future. Law is not ethics. Is it OK to train models on people‚Äôs content without their permission, when those models will then be used in ways that compete with those people? As the quality of results produced by AI models has increased over the year, these questions have become even more pressing. The impact on human society in terms of these models is already huge, if difficult to objectively measure. People have certainly lost work to them‚Äîanecdotally, I‚Äôve seen this for copywriters, artists and translators. There are a great deal of untold stories here. I‚Äôm hoping 2024 sees significant amounts of dedicated journalism on this topic. My blog in 2023 Here‚Äôs a tag cloud for content I posted to my blog in 2023 (generated using Django SQL Dashboard): Tag cloud words in order of size: ai, generativeai, llms, openai, chatgpt, projects, python, datasette, ethics, llama, homebrewllms, sqlite, gpt3, promptengineering, promptinjection, llm, security, opensource, gpt4, weeknotes The top five: ai (342), generativeai (300), llms (287), openai (86), chatgpt (78). I‚Äôve written a lot about this stuff! I grabbed a screenshot of my Plausible analytics for the year, fed that to ChatGPT Vision, told it to extract the data into a table, then got it to mix in entry titles (from a SQL query it wrote) and produced this table with it. Here are my top entries this year by amount of traffic: Article Visitors Pageviews Bing: ‚ÄúI will not harm you unless you harm me first‚Äù 1.1M 1.3M Leaked Google document: ‚ÄúWe Have No Moat, And Neither Does OpenAI‚Äù 132k 162k Large language models are having their Stable Diffusion moment 121k 150k Prompt injection: What‚Äôs the worst that can happen? 79.8k 95.9k Embeddings: What they are and why they matter 61.7k 79.3k Catching up on the weird world of LLMs 61.6k 85.9k llamafile is the new best way to run an LLM on your own computer 52k 66k Prompt injection explained, with video, slides, and a transcript 51k 61.9k AI-enhanced development makes me more ambitious with my projects 49.6k 60.1k Understanding GPT tokenizers 49.5k 61.1k Exploring GPTs: ChatGPT in a trench coat? 46.4k 58.5k Could you train a ChatGPT-beating model for $85,000 and run it in a browser? 40.5k 49.2k How to implement Q&A against your documentation with GPT3, embeddings and Datasette 37.3k 44.9k Lawyer cites fake cases invented by ChatGPT, judge is not amused 37.1k 47.4k Now add a walrus: Prompt engineering in DALL-E 3 32.8k 41.2k Web LLM runs the vicuna-7b Large Language Model entirely in your browser, and it‚Äôs very impressive 32.5k 38.2k ChatGPT can‚Äôt access the internet, even though it really looks like it can 30.5k 34.2k Stanford Alpaca, and the acceleration of on-device large language model development 29.7k 35.7k Run Llama 2 on your own Mac using LLM and Homebrew 27.9k 33.6k Midjourney 5.1 26.7k 33.4k Think of language models like ChatGPT as a ‚Äúcalculator for words‚Äù 25k 31.8k Multi-modal prompt injection image attacks against GPT-4V 23.7k 27.4k I also gave a bunch of talks and podcast appearances. I‚Äôve started habitually turning my talks into annotated presentations‚Äîhere are my best from 2023: Prompt injection explained, with video, slides, and a transcript Catching up on the weird world of LLMs Making Large Language Models work for you Open questions for AI engineering Embeddings: What they are and why they matter Financial sustainability for open source projects at GitHub Universe And in podcasts: What AI can do for you on the Theory of Change Working in public on Path to Citus Con LLMs break the internet on the Changelog Talking Large Language Models on Rooftop Ruby Thoughts on the OpenAI board situation on Newsroom Robots Industry‚Äôs Tardy Response to the AI Prompt Injection Vulnerability on RedMonk Conversations Posted 31st December 2023 at 11:59 pm ¬∑ Follow me on Mastodon, Bluesky, Twitter or subscribe to my newsletter More recent articles Feed a video to a vision LLM as a sequence of JPEG frames on the CLI (also LLM 0.25) - 5th May 2025 Two publishers and three authors fail to understand what \"vibe coding\" means - 1st May 2025 Understanding the recent criticism of the Chatbot Arena - 30th April 2025 This is Stuff we figured out about AI in 2023 by Simon Willison, posted on 31st December 2023. Part of series LLMs annual review Stuff we figured out about AI in 2023 - Dec. 31, 2023, 11:59 p.m. Things we learned about LLMs in 2024 - Dec. 31, 2024, 6:07 p.m. blogging 105 ai 1262 generative-ai 1089 llms 1076 Next: Tom Scott, and the formidable power of escalating streaks Previous: Last weeknotes of 2023 Colophon ¬© 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 2025']",
                  "The discussion of ChatGPT in relation to practical applications and societal impact, including concerns about job displacement and ethical considerations, is reflected in several ways within the provided context.\n\n**Practical Applications:**\n- The blog posts from 2023 highlight advancements such as ChatGPT's ability to run Python in two different ways and the integration of features like live video and voice mode, which allows users to share their camera feed and interact with the model in real time.\n- There is mention of prompt-driven app generation becoming a commodity, indicating widespread use of ChatGPT for building applications with minimal coding.\n- Specific projects and technical implementations, such as building a Claude Artifact that communicates with external APIs or running LLMs locally with \"llamafile,\" demonstrate how practitioners are leveraging ChatGPT's capabilities for development and integration.\n- The analytics feature shows significant interest in topics like prompt injection, embeddings, and GPT tokenizers, emphasizing active engagement with the practical aspects of ChatGPT and related models.\n\n**Societal Impact and Concerns:**\n- The author explicitly discusses the societal impact, noting that AI models have already caused job displacement, with anecdotal evidence of copywriters, artists, and translators losing work.\n- Concerns about the ethics of training models on unlicensed data without permission are raised, especially as the quality of results improves, making these issues more urgent.\n- The mention of major stories on unlicensed training data, such as the one on Stable Diffusion, reflects ongoing societal debates about legality and ethics.\n- The blog from 2023 also emphasizes the complexity of AI ethics and the need for journalism to explore these stories further in 2024.\n- The discussion about the potential threat to programmers‚Äîwho might be replaced by ChatGPT‚Äîversus the opportunity for software engineers to utilize their expertise to leverage AI effectively underscores societal concerns about employment and ethical use.\n\n**In summary:**\nThe reflection from the blog posts and analytics shows that ChatGPT is actively discussed as a transformative tool with significant practical applications in development and user interaction, while simultaneously raising societal concerns about job displacement, ethics surrounding data use, and the broader impact on human society. The narrative balances optimism about technological opportunities with caution about ethical challenges and societal consequences.",
                  "ChatGPT has been a recurring topic in blog posts and analytics throughout 2023 and 2024, reflecting both its practical applications and its broader societal impact. In 2024, ChatGPT was featured in discussions about ad-hoc sidequests, code interpretation, and its evolving features, such as the '4o' mode and the distinction between training and chatting. The blog highlights the need for critical evaluation of AI tools like ChatGPT, emphasizing that while there are unintuitive traps and potential for misuse, there is also genuine value that requires guidance to realize. Ethical concerns are raised, particularly regarding the training of models on people's content without permission and the resulting competition with human workers, which has led to job losses among copywriters, artists, and translators. The analytics from 2023 show that 'chatgpt' was among the top tags and most visited articles, including topics like 'Lawyer cites fake cases invented by ChatGPT' and 'ChatGPT can‚Äôt access the internet, even though it really looks like it can.' These entries illustrate both the capabilities and limitations of ChatGPT, as well as the legal and ethical debates surrounding its use. Overall, the blog posts and analytics demonstrate that ChatGPT is at the center of ongoing discussions about practical utility, ethical challenges, and its significant, if sometimes difficult to measure, impact on society.",
                  "multi_hop_specific_query_synthesizer"
                ],
                [
                  "9",
                  "Anthropic make LLMs, but what is problem with LLMs and what is needed to make them useful, Anthropic way?",
                  "['LLMs need better criticism\\n\\nA lot of people absolutely hate this stuff. In some of the spaces I hang out (Mastodon, Bluesky, Lobste.rs, even Hacker News on occasion) even suggesting that ‚ÄúLLMs are useful‚Äù can be enough to kick off a huge fight.\\n\\nI get it. There are plenty of reasons to dislike this technology‚Äîthe environmental impact, the (lack of) ethics of the training data, the lack of reliability, the negative applications, the potential impact on people‚Äôs jobs.\\n\\nLLMs absolutely warrant criticism. We need to be talking through these problems, finding ways to mitigate them and helping people learn how to use these tools responsibly in ways where the positive applications outweigh the negative.\\n\\nI like people who are skeptical of this stuff. The hype has been deafening for more than two years now, and there are enormous quantities of snake oil and misinformation out there. A lot of very bad decisions are being made based on that hype. Being critical is a virtue.', 'A lot of people are yet to be sold on their value! Some think their negatives outweigh their positives, some think they are all hot air, and some even think they represent an existential threat to humanity.\\n\\nThey‚Äôre actually quite easy to build\\n\\nThe most surprising thing we‚Äôve learned about LLMs this year is that they‚Äôre actually quite easy to build.\\n\\nIntuitively, one would expect that systems this powerful would take millions of lines of complex code. Instead, it turns out a few hundred lines of Python is genuinely enough to train a basic version!\\n\\nWhat matters most is the training data. You need a lot of data to make these things work, and the quantity and quality of the training data appears to be the most important factor in how good the resulting model is.\\n\\nIf you can gather the right data, and afford to pay for the GPUs to train it, you can build an LLM.', 'Meanwhile, it‚Äôs increasingly common for end users to develop wildly inaccurate mental models of how these things work and what they are capable of. I‚Äôve seen so many examples of people trying to win an argument with a screenshot from ChatGPT‚Äîan inherently ludicrous proposition, given the inherent unreliability of these models crossed with the fact that you can get them to say anything if you prompt them right.\\n\\nThere‚Äôs a flipside to this too: a lot of better informed people have sworn off LLMs entirely because they can‚Äôt see how anyone could benefit from a tool with so many flaws. The key skill in getting the most out of LLMs is learning to work with tech that is both inherently unreliable and incredibly powerful at the same time. This is a decidedly non-obvious skill to acquire!\\n\\nThere is so much space for helpful education content here, but we need to do do a lot better than outsourcing it all to AI grifters with bombastic Twitter threads.', 'So training an LLM still isn‚Äôt something a hobbyist can afford, but it‚Äôs no longer the sole domain of the super-rich. I like to compare the difficulty of training an LLM to that of building a suspension bridge‚Äînot trivial, but hundreds of countries around the world have figured out how to do it. (Correction: Wikipedia‚Äôs Suspension bridges by country category lists 44 countries).\\n\\nYou can run LLMs on your own devices\\n\\nIn January of this year, I thought it would be years before I could run a useful LLM on my own computer. GPT-3 and 3.5 were pretty much the only games in town, and I thought that even if the model weights were available it would take a $10,000+ server to run them.\\n\\nThen in February, Meta released Llama. And a few weeks later in March, Georgi Gerganov released code that got it working on a MacBook.\\n\\nI wrote about how Large language models are having their Stable Diffusion moment, and with hindsight that was a very good call!', 'If you can gather the right data, and afford to pay for the GPUs to train it, you can build an LLM.\\n\\nA year ago, the only organization that had released a generally useful LLM was OpenAI. We‚Äôve now seen better-than-GPT-3 class models produced by Anthropic, Mistral, Google, Meta, EleutherAI, Stability AI, TII in Abu Dhabi (Falcon), Microsoft Research, xAI, Replit, Baidu and a bunch of other organizations.\\n\\nThe training cost (hardware and electricity) is still significant‚Äîinitially millions of dollars, but that seems to have dropped to the tens of thousands already. Microsoft‚Äôs Phi-2 claims to have used ‚Äú14 days on 96 A100 GPUs‚Äù, which works out at around $35,000 using current Lambda pricing.']",
                  "['<1-hop>\\n\\nskeptical as to their utility based, once again, on the challenge of gullibility. LLMs believe anything you tell them. Any systems that attempts to make meaningful decisions on your behalf will run into the same roadblock: how good is a travel agent, or a digital assistant, or even a research tool if it can‚Äôt distinguish truth from fiction? Just the other day Google Search was caught serving up an entirely fake description of the non-existant movie ‚ÄúEncanto 2‚Äù. It turned out to be summarizing an imagined movie listing from a fan fiction wiki. Prompt injection is a natural consequence of this gulibility. I‚Äôve seen precious little progress on tackling that problem in 2024, and we‚Äôve been talking about it since September 2022. I‚Äôm beginning to see the most popular idea of ‚Äúagents‚Äù as dependent on AGI itself. A model that‚Äôs robust against gulliblity is a very tall order indeed. Evals really matter Anthropic‚Äôs Amanda Askell (responsible for much of the work behind Claude‚Äôs Character): The boring yet crucial secret behind good system prompts is test-driven development. You don‚Äôt write down a system prompt and find ways to test it. You write down tests and find a system prompt that passes them. It‚Äôs become abundantly clear over the course of 2024 that writing good automated evals for LLM-powered systems is the skill that‚Äôs most needed to build useful applications on top of these models. If you have a strong eval suite you can adopt new models faster, iterate better and build more reliable and useful product features than your competition. Vercel‚Äôs Malte Ubl: When @v0 first came out we were paranoid about protecting the prompt with all kinds of pre and post processing complexity. We completely pivoted to let it rip. A prompt without the evals, models, and especially UX is like getting a broken ASML machine without a manual I‚Äôm still trying to figure out the best patterns for doing this for my own work. Everyone knows that evals are important, but there remains a lack of great guidance for how to best implement them‚ÄîI‚Äôm tracking this under my evals tag. My SVG pelican riding a bicycle benchmark is a pale imitation of what a real eval suite should look like. Apple Intelligence is bad, Apple‚Äôs MLX library is excellent As a Mac user I‚Äôve been feeling a lot better about my choice of platform this year. Last year it felt like my lack of a Linux/Windows machine with an NVIDIA GPU was a huge disadvantage in terms of trying out new models. On paper, a 64GB Mac should be a great machine for running models due to the way the CPU and GPU can share the same memory. In practice, many models are released as model weights and libraries that reward NVIDIA‚Äôs CUDA over other platforms. The llama.cpp ecosystem helped a lot here, but the real breakthrough has been Apple‚Äôs MLX library, ‚Äúan array framework for Apple Silicon‚Äù. It‚Äôs fantastic. Apple‚Äôs mlx-lm Python library supports running a wide range of MLX-compatible models on my Mac, with excellent performance. mlx-community on Hugging Face offers more than 1,000 models that have been converted to the necessary format. Prince Canuma‚Äôs excellent, fast moving mlx-vlm project brings vision LLMs to Apple Silicon as well. I used that recently to run Qwen‚Äôs QvQ. While MLX is a game changer, Apple‚Äôs own ‚ÄúApple Intelligence‚Äù features have mostly been a disappointment. I wrote about their initial announcement in June, and I was optimistic that Apple had focused hard on the subset of LLM applications that preserve user privacy and minimize the chance of users getting mislead by confusing features. Now that those features are rolling out they‚Äôre pretty weak. As an LLM power-user I know what these models are capable of, and Apple‚Äôs LLM features offer a pale imitation of what a frontier LLM can do. Instead we‚Äôre getting notification summaries that misrepresent news headlines and writing assistant tools that I‚Äôve not found useful at all. Genmoji are kind of fun though. The rise of inference-scaling ‚Äúreasoning‚Äù models The most interesting development in the final quarter of 2024 was the introduction of a new shape of LLM, exemplified by OpenAI‚Äôs o1 models‚Äîinitially released as o1-preview and o1-mini on September 12th. One way to think about these models is an extension of the chain-of-thought prompting trick, first explored in the May 2022 paper Large Language Models are Zero-Shot Reasoners. This is that trick where, if you get a model to talk out loud about a problem it‚Äôs solving, you often get a result which the model would not have achieved otherwise. o1 takes this process and further bakes it into the model itself. The details are somewhat obfuscated: o1 models spend ‚Äúreasoning tokens‚Äù thinking through the problem that are not directly visible to the user (though the ChatGPT UI shows a summary of them), then outputs a final result. The biggest innovation here is that it opens up a new way to scale a model: instead of improving model performance purely through additional compute at training time, models can now take on harder problems by spending more compute on inference. The sequel to o1, o3 (they skipped ‚Äúo2‚Äù for European trademark reasons) was announced on 20th December with an impressive result against the ARC-AGI benchmark, albeit one that likely involved more than $1,000,000 of compute time expense! o3 is expected to ship in January. I doubt many people have real-world problems that would benefit from that level of compute expenditure‚ÄîI certainly don‚Äôt!‚Äîbut it appears to be a genuine next step in LLM architecture for taking on much harder problems. OpenAI are not the only game in town here. Google released their first entrant in the category, gemini-2.0-flash-thinking-exp, on December 19th. Alibaba‚Äôs Qwen team released their QwQ model on November 28th‚Äîunder an Apache 2.0 license, and that one I could run on my own machine. They followed that up with a vision reasoning model called QvQ on December 24th, which I also ran locally. DeepSeek made their DeepSeek-R1-Lite-Preview', '<2-hop>\\n\\nWe don‚Äôt yet know how to build GPT-4 Vibes Based Development LLMs are really smart, and also really, really dumb Gullibility is the biggest unsolved problem Code may be the best application The ethics of this space remain diabolically complex My blog in 2023 Here‚Äôs the sequel to this post: Things we learned about LLMs in 2024. Large Language Models In the past 24-36 months, our species has discovered that you can take a GIANT corpus of text, run it through a pile of GPUs, and use it to create a fascinating new kind of software. LLMs can do a lot of things. They can answer questions, summarize documents, translate from one language to another, extract information and even write surprisingly competent code. They can also help you cheat at your homework, generate unlimited streams of fake content and be used for all manner of nefarious purposes. So far, I think they‚Äôre a net positive. I‚Äôve used them on a personal level to improve my productivity (and entertain myself) in all sorts of different ways. I think people who learn how to use them effectively can gain a significant boost to their quality of life. A lot of people are yet to be sold on their value! Some think their negatives outweigh their positives, some think they are all hot air, and some even think they represent an existential threat to humanity. They‚Äôre actually quite easy to build The most surprising thing we‚Äôve learned about LLMs this year is that they‚Äôre actually quite easy to build. Intuitively, one would expect that systems this powerful would take millions of lines of complex code. Instead, it turns out a few hundred lines of Python is genuinely enough to train a basic version! What matters most is the training data. You need a lot of data to make these things work, and the quantity and quality of the training data appears to be the most important factor in how good the resulting model is. If you can gather the right data, and afford to pay for the GPUs to train it, you can build an LLM. A year ago, the only organization that had released a generally useful LLM was OpenAI. We‚Äôve now seen better-than-GPT-3 class models produced by Anthropic, Mistral, Google, Meta, EleutherAI, Stability AI, TII in Abu Dhabi (Falcon), Microsoft Research, xAI, Replit, Baidu and a bunch of other organizations. The training cost (hardware and electricity) is still significant‚Äîinitially millions of dollars, but that seems to have dropped to the tens of thousands already. Microsoft‚Äôs Phi-2 claims to have used ‚Äú14 days on 96 A100 GPUs‚Äù, which works out at around $35,000 using current Lambda pricing. So training an LLM still isn‚Äôt something a hobbyist can afford, but it‚Äôs no longer the sole domain of the super-rich. I like to compare the difficulty of training an LLM to that of building a suspension bridge‚Äînot trivial, but hundreds of countries around the world have figured out how to do it. (Correction: Wikipedia‚Äôs Suspension bridges by country category lists 44 countries). You can run LLMs on your own devices In January of this year, I thought it would be years before I could run a useful LLM on my own computer. GPT-3 and 3.5 were pretty much the only games in town, and I thought that even if the model weights were available it would take a $10,000+ server to run them. Then in February, Meta released Llama. And a few weeks later in March, Georgi Gerganov released code that got it working on a MacBook. I wrote about how Large language models are having their Stable Diffusion moment, and with hindsight that was a very good call! This unleashed a whirlwind of innovation, which was accelerated further in July when Meta released Llama 2‚Äîan improved version which, crucially, included permission for commercial use. Today there are literally thousands of LLMs that can be run locally, on all manner of different devices. I run a bunch of them on my laptop. I run Mistral 7B (a surprisingly great model) on my iPhone. You can install several different apps to get your own, local, completely private LLM. My own LLM project provides a CLI tool for running an array of different models via plugins. You can even run them entirely in your browser using WebAssembly and the latest Chrome! Hobbyists can build their own fine-tuned models I said earlier that building an LLM was still out of reach of hobbyists. That may be true for training from scratch, but fine-tuning one of those models is another matter entirely. There‚Äôs now a fascinating ecosystem of people training their own models on top of these foundations, publishing those models, building fine-tuning datasets and sharing those too. The Hugging Face Open LLM Leaderboard is one place that tracks these. I can‚Äôt even attempt to count them, and any count would be out-of-date within a few hours. The best overall openly licensed LLM at any time is rarely a foundation model: instead, it‚Äôs whichever fine-tuned community model has most recently discovered the best combination of fine-tuning data. This is a huge advantage for open over closed models: the closed, hosted models don‚Äôt have thousands of researchers and hobbyists around the world collaborating and competing to improve them. We don‚Äôt yet know how to build GPT-4 Frustratingly, despite the enormous leaps ahead we‚Äôve had this year, we are yet to see an alternative model that‚Äôs better than GPT-4. OpenAI released GPT-4 in March, though it later turned out we had a sneak peak of it in February when Microsoft used it as part of the new Bing. This may well change in the next few weeks: Google‚Äôs Gemini Ultra has big claims, but isn‚Äôt yet available for us to try out. The team behind Mistral are working to beat GPT-4 as well, and their track record is already extremely strong considering their first public model only came out in September, and they‚Äôve released two significant improvements since then. Still,']",
                  "The main problems with LLMs, according to the context, are their negative aspects that warrant criticism, such as environmental impact, ethics of training data, lack of reliability, negative applications, and potential impact on jobs. Additionally, there is a challenge related to their inherent unreliability and the tendency of end users to develop inaccurate mental models of how they work and what they are capable of. \n\nTo make LLMs useful in the Anthropic way, it is essential to address these criticisms by understanding and mitigating the negative issues, fostering responsible use, and improving education around their capabilities and limitations. This involves critical evaluation of the technology, ensuring better training data quality, and helping users learn how to work effectively with these inherently unreliable yet powerful tools.",
                  "Anthropic is one of the organizations that has produced better-than-GPT-3 class large language models (LLMs). A big problem with LLMs is gullibility‚Äîthey believe anything you tell them, which makes it hard for them to distinguish truth from fiction. This gullibility leads to issues like prompt injection and unreliable decision-making. According to Anthropic‚Äôs Amanda Askell, the key to making LLMs more useful is having strong automated evaluation (eval) suites. Instead of just writing system prompts and testing them, you should write tests first and then create prompts that pass those tests. Good evals help you adopt new models faster, iterate better, and build more reliable and useful product features.",
                  "multi_hop_specific_query_synthesizer"
                ],
                [
                  "10",
                  "How did Meta's Llama 3.3 70B utilize synthetic data in its fine-tuning, and what does its ability to run on a personal laptop reveal about recent advances in large language model efficiency?",
                  "['I can now run a GPT-4 class model on my laptop talks about running Meta‚Äôs Llama 3.3 70B (released in December)\\n\\nThis remains astonishing to me. I thought a model with the capabilities and output quality of GPT-4 needed a datacenter class server with one or more $40,000+ GPUs.\\n\\nThese models take up enough of my 64GB of RAM that I don‚Äôt run them often‚Äîthey don‚Äôt leave much room for anything else.\\n\\nThe fact that they run at all is a testament to the incredible training and inference performance gains that we‚Äôve figured out over the past year. It turns out there was a lot of low-hanging fruit to be harvested in terms of model efficiency. I expect there‚Äôs still more to come.', 'Meta‚Äôs Llama 3.2 models deserve a special mention. They may not be GPT-4 class, but at 1B and 3B sizes they punch massively above their weight. I run Llama 3.2 3B on my iPhone using the free MLC Chat iOS app and it‚Äôs a shockingly capable model for its tiny (<2GB) size. Try firing it up and asking it for ‚Äúa plot outline of a Netflix Christmas movie where a data journalist falls in love with a local ceramacist‚Äù. Here‚Äôs what I got, at a respectable 20 tokens per second:', 'I wrote about how Large language models are having their Stable Diffusion moment, and with hindsight that was a very good call!\\n\\nThis unleashed a whirlwind of innovation, which was accelerated further in July when Meta released Llama 2‚Äîan improved version which, crucially, included permission for commercial use.\\n\\nToday there are literally thousands of LLMs that can be run locally, on all manner of different devices.\\n\\nI run a bunch of them on my laptop. I run Mistral 7B (a surprisingly great model) on my iPhone. You can install several different apps to get your own, local, completely private LLM. My own LLM project provides a CLI tool for running an array of different models via plugins.\\n\\nYou can even run them entirely in your browser using WebAssembly and the latest Chrome!\\n\\nHobbyists can build their own fine-tuned models', 'Another common technique is to use larger models to help create training data for their smaller, cheaper alternatives‚Äîa trick used by an increasing number of labs. DeepSeek v3 used ‚Äúreasoning‚Äù data created by DeepSeek-R1. Meta‚Äôs Llama 3.3 70B fine-tuning used over 25M synthetically generated examples.\\n\\nCareful design of the training data that goes into an LLM appears to be the entire game for creating these models. The days of just grabbing a full scrape of the web and indiscriminately dumping it into a training run are long gone.\\n\\nLLMs somehow got even harder to use\\n\\nA drum I‚Äôve been banging for a while is that LLMs are power-user tools‚Äîthey‚Äôre chainsaws disguised as kitchen knives. They look deceptively simple to use‚Äîhow hard can it be to type messages to a chatbot?‚Äîbut in reality you need a huge depth of both understanding and experience to make the most of them and avoid their many pitfalls.\\n\\nIf anything, this problem got worse in 2024.', 'So training an LLM still isn‚Äôt something a hobbyist can afford, but it‚Äôs no longer the sole domain of the super-rich. I like to compare the difficulty of training an LLM to that of building a suspension bridge‚Äînot trivial, but hundreds of countries around the world have figured out how to do it. (Correction: Wikipedia‚Äôs Suspension bridges by country category lists 44 countries).\\n\\nYou can run LLMs on your own devices\\n\\nIn January of this year, I thought it would be years before I could run a useful LLM on my own computer. GPT-3 and 3.5 were pretty much the only games in town, and I thought that even if the model weights were available it would take a $10,000+ server to run them.\\n\\nThen in February, Meta released Llama. And a few weeks later in March, Georgi Gerganov released code that got it working on a MacBook.\\n\\nI wrote about how Large language models are having their Stable Diffusion moment, and with hindsight that was a very good call!']",
                  "['<1-hop>\\n\\nof the best descriptions I‚Äôve seen of this comes from the Phi-4 technical report, which included this: Synthetic data as a substantial component of pretraining is becoming increasingly common, and the Phi series of models has consistently emphasized the importance of synthetic data. Rather than serving as a cheap substitute for organic data, synthetic data has several direct advantages over organic data. Structured and Gradual Learning. In organic datasets, the relationship between tokens is often complex and indirect. Many reasoning steps may be required to connect the current token to the next, making it challenging for the model to learn effectively from next-token prediction. By contrast, each token generated by a language model is by definition predicted by the preceding tokens, making it easier for a model to follow the resulting reasoning patterns. Another common technique is to use larger models to help create training data for their smaller, cheaper alternatives‚Äîa trick used by an increasing number of labs. DeepSeek v3 used ‚Äúreasoning‚Äù data created by DeepSeek-R1. Meta‚Äôs Llama 3.3 70B fine-tuning used over 25M synthetically generated examples. Careful design of the training data that goes into an LLM appears to be the entire game for creating these models. The days of just grabbing a full scrape of the web and indiscriminately dumping it into a training run are long gone. LLMs somehow got even harder to use A drum I‚Äôve been banging for a while is that LLMs are power-user tools‚Äîthey‚Äôre chainsaws disguised as kitchen knives. They look deceptively simple to use‚Äîhow hard can it be to type messages to a chatbot?‚Äîbut in reality you need a huge depth of both understanding and experience to make the most of them and avoid their many pitfalls. If anything, this problem got worse in 2024. We‚Äôve built computer systems you can talk to in human language, that will answer your questions and usually get them right! ... depending on the question, and how you ask it, and whether it‚Äôs accurately reflected in the undocumented and secret training set. The number of available systems has exploded. Different systems have different tools they can apply to your problems‚Äîlike Python and JavaScript and web search and image generation and maybe even database lookups... so you‚Äôd better understand what those tools are, what they can do and how to tell if the LLM used them or not. Did you know ChatGPT has two entirely different ways of running Python now? Want to build a Claude Artifact that talks to an external API? You‚Äôd better understand CSP and CORS HTTP headers first. The models may have got more capable, but most of the limitations remained the same. OpenAI‚Äôs o1 may finally be able to (mostly) count the Rs in strawberry, but its abilities are still limited by its nature as an LLM and the constraints placed on it by the harness it‚Äôs running in. o1 can‚Äôt run web searches or use Code Interpreter, but GPT-4o can‚Äîboth in that same ChatGPT UI. (o1 will pretend to do those things if you ask it to, a regression to the URL hallucinations bug from early 2023). What are we doing about this? Not much. Most users are thrown in at the deep end. The default LLM chat UI is like taking brand new computer users, dropping them into a Linux terminal and expecting them to figure it all out. Meanwhile, it‚Äôs increasingly common for end users to develop wildly inaccurate mental models of how these things work and what they are capable of. I‚Äôve seen so many examples of people trying to win an argument with a screenshot from ChatGPT‚Äîan inherently ludicrous proposition, given the inherent unreliability of these models crossed with the fact that you can get them to say anything if you prompt them right. There‚Äôs a flipside to this too: a lot of better informed people have sworn off LLMs entirely because they can‚Äôt see how anyone could benefit from a tool with so many flaws. The key skill in getting the most out of LLMs is learning to work with tech that is both inherently unreliable and incredibly powerful at the same time. This is a decidedly non-obvious skill to acquire! There is so much space for helpful education content here, but we need to do do a lot better than outsourcing it all to AI grifters with bombastic Twitter threads. Knowledge is incredibly unevenly distributed Most people have heard of ChatGPT by now. How many have heard of Claude? The knowledge gap between the people who actively follow this stuff and the 99% of the population who do not is vast. The pace of change doesn‚Äôt help either. In just the past month we‚Äôve seen general availability of live interfaces where you can point your phone‚Äôs camera at something and talk about it with your voice... and optionally have it pretend to be Santa. Most self-certified nerds haven‚Äôt even tried that yet. Given the ongoing (and potential) impact on society that this technology has, I don‚Äôt think the size of this gap is healthy. I‚Äôd like to see a lot more effort put into improving this. LLMs need better criticism A lot of people absolutely hate this stuff. In some of the spaces I hang out (Mastodon, Bluesky, Lobste.rs, even Hacker News on occasion) even suggesting that ‚ÄúLLMs are useful‚Äù can be enough to kick off a huge fight. I get it. There are plenty of reasons to dislike this technology‚Äîthe environmental impact, the (lack of) ethics of the training data, the lack of reliability, the negative applications, the potential impact on people‚Äôs jobs. LLMs absolutely warrant criticism. We need to be talking through these problems, finding ways to mitigate them and helping people learn how to use these tools responsibly in ways where the positive applications outweigh the negative. I like people who are skeptical of this stuff. The hype has been deafening for more than two years now, and there are enormous quantities of snake oil and misinformation out there. A lot', '<2-hop>\\n\\nThe rise of inference-scaling ‚Äúreasoning‚Äù models Was the best currently available LLM trained in China for less than $6m? The environmental impact got better The environmental impact got much, much worse The year of slop Synthetic training data works great LLMs somehow got even harder to use Knowledge is incredibly unevenly distributed LLMs need better criticism Everything tagged ‚Äúllms‚Äù on my blog in 2024 The GPT-4 barrier was comprehensively broken In my December 2023 review I wrote about how We don‚Äôt yet know how to build GPT-4‚ÄîOpenAI‚Äôs best model was almost a year old at that point, yet no other AI lab had produced anything better. What did OpenAI know that the rest of us didn‚Äôt? I‚Äôm relieved that this has changed completely in the past twelve months. 18 organizations now have models on the Chatbot Arena Leaderboard that rank higher than the original GPT-4 from March 2023 (GPT-4-0314 on the board)‚Äî70 models in total. Screenshot of a comparison table showing AI model rankings. Table headers: Rank (UB), Rank (StyleCtrl), Model, Arena Score, 95% CI, Votes, Organization, License. Shows 12 models including GLM-4-0520, Llama-3-70B-Instruct, Gemini-1.5-Flash-8B-Exp-0827, with rankings, scores, and licensing details. Models range from rank 52-69 with Arena scores between 1186-1207. The earliest of those was Google‚Äôs Gemini 1.5 Pro, released in February. In addition to producing GPT-4 level outputs, it introduced several brand new capabilities to the field‚Äîmost notably its 1 million (and then later 2 million) token input context length, and the ability to input video. I wrote about this at the time in The killer app of Gemini Pro 1.5 is video, which earned me a short appearance as a talking head in the Google I/O opening keynote in May. Gemini 1.5 Pro also illustrated one of the key themes of 2024: increased context lengths. Last year most models accepted 4,096 or 8,192 tokens, with the notable exception of Claude 2.1 which accepted 200,000. Today every serious provider has a 100,000+ token model, and Google‚Äôs Gemini series accepts up to 2 million. Longer inputs dramatically increase the scope of problems that can be solved with an LLM: you can now throw in an entire book and ask questions about its contents, but more importantly you can feed in a lot of example code to help the model correctly solve a coding problem. LLM use-cases that involve long inputs are far more interesting to me than short prompts that rely purely on the information already baked into the model weights. Many of my tools were built using this pattern. Getting back to models that beat GPT-4: Anthropic‚Äôs Claude 3 series launched in March, and Claude 3 Opus quickly became my new favourite daily-driver. They upped the ante even more in June with the launch of Claude 3.5 Sonnet‚Äîa model that is still my favourite six months later (though it got a significant upgrade on October 22, confusingly keeping the same 3.5 version number. Anthropic fans have since taken to calling it Claude 3.6). Then there‚Äôs the rest. If you browse the Chatbot Arena leaderboard today‚Äîstill the most useful single place to get a vibes-based evaluation of models‚Äîyou‚Äôll see that GPT-4-0314 has fallen to around 70th place. The 18 organizations with higher scoring models are Google, OpenAI, Alibaba, Anthropic, Meta, Reka AI, 01 AI, Amazon, Cohere, DeepSeek, Nvidia, Mistral, NexusFlow, Zhipu AI, xAI, AI21 Labs, Princeton and Tencent. Training a GPT-4 beating model was a huge deal in 2023. In 2024 it‚Äôs an achievement that isn‚Äôt even particularly notable, though I personally still celebrate any time a new organization joins that list. Some of those GPT-4 models run on my laptop My personal laptop is a 64GB M2 MacBook Pro from 2023. It‚Äôs a powerful machine, but it‚Äôs also nearly two years old now‚Äîand crucially it‚Äôs the same laptop I‚Äôve been using ever since I first ran an LLM on my computer back in March 2023 (see Large language models are having their Stable Diffusion moment). That same laptop that could just about run a GPT-3-class model in March last year has now run multiple GPT-4 class models! Some of my notes on that: Qwen2.5-Coder-32B is an LLM that can code well that runs on my Mac talks about Qwen2.5-Coder-32B in November‚Äîan Apache 2.0 licensed model! I can now run a GPT-4 class model on my laptop talks about running Meta‚Äôs Llama 3.3 70B (released in December) This remains astonishing to me. I thought a model with the capabilities and output quality of GPT-4 needed a datacenter class server with one or more $40,000+ GPUs. These models take up enough of my 64GB of RAM that I don‚Äôt run them often‚Äîthey don‚Äôt leave much room for anything else. The fact that they run at all is a testament to the incredible training and inference performance gains that we‚Äôve figured out over the past year. It turns out there was a lot of low-hanging fruit to be harvested in terms of model efficiency. I expect there‚Äôs still more to come. Meta‚Äôs Llama 3.2 models deserve a special mention. They may not be GPT-4 class, but at 1B and 3B sizes they punch massively above their weight. I run Llama 3.2 3B on my iPhone using the free MLC Chat iOS app and it‚Äôs a shockingly capable model for its tiny (<2GB) size. Try firing it up and asking it for ‚Äúa plot outline of a Netflix Christmas movie where a data journalist falls in love with a local ceramacist‚Äù. Here‚Äôs what I got, at a respectable 20 tokens per second: MLC Chat: Llama - [System] Ready to chat. a plot outline of a Netflix Christmas movie where a data journalist falls in love with a local ceramacist. Show as Markdown is turned on. Here\\'s a plot outline for a Netflix Christmas movie: Title: \"Love in the Clay\" Plot Outline: We meet our protagonist, JESSICA, a data journalist who has just returned to her hometown of Willow Creek, a small, charming town nestled in the snow-covered mountains. She\\'s back to work']",
                  "Meta's Llama 3.3 70B utilized over 25 million synthetically generated examples for its fine-tuning process. This approach involved creating training data through careful design, leveraging larger models to generate high-quality, synthetic examples that help improve the smaller, fine-tuned models. \n\nIts ability to run on a personal laptop reveals significant recent advances in large language model efficiency. It demonstrates that models with capabilities comparable to GPT-4 can now be optimized to operate within the limited hardware resources of personal devices, such as laptops and even smartphones. This progress is attributed to substantial training and inference performance gains, as well as a focus on model efficiency improvements‚Äîindicating that the era of power-hungry, datacenter-only LLMs is giving way to more accessible, lightweight models suitable for local deployment.",
                  "Meta's Llama 3.3 70B fine-tuning process incorporated over 25 million synthetically generated examples, highlighting the growing importance and advantages of synthetic data in training large language models. This approach allows for more structured and gradual learning compared to organic datasets. Additionally, the fact that Llama 3.3 70B‚Äîa model with GPT-4 class capabilities‚Äîcan now run on a personal laptop with 64GB of RAM demonstrates significant recent advances in model efficiency and inference performance. These improvements have made it possible to operate highly capable models outside of datacenter-class servers, reflecting major progress in the field.",
                  "multi_hop_specific_query_synthesizer"
                ],
                [
                  "11",
                  "What are some recent advanced features introduced in ChatGPT, and how do they compare to similar capabilities in competing models like Google Gemini?",
                  "['The most recent twist, again from December (December was a lot) is live video. ChatGPT voice mode now provides the option to share your camera feed with the model and talk about what you can see in real time. Google Gemini have a preview of the same feature, which they managed to ship the day before ChatGPT did.\\n\\nThese abilities are just a few weeks old at this point, and I don‚Äôt think their impact has been fully felt yet. If you haven‚Äôt tried them out yet you really should.\\n\\nBoth Gemini and OpenAI offer API access to these features as well. OpenAI started with a WebSocket API that was quite challenging to use, but in December they announced a new WebRTC API which is much easier to get started with. Building a web app that a user can talk to via voice is easy now!\\n\\nPrompt driven app generation is a commodity already\\n\\nThis was possible with GPT-4 in 2023, but the value it provides became evident in 2024.', 'I‚Äôm relieved that this has changed completely in the past twelve months. 18 organizations now have models on the Chatbot Arena Leaderboard that rank higher than the original GPT-4 from March 2023 (GPT-4-0314 on the board)‚Äî70 models in total.\\n\\nScreenshot of a comparison table showing AI model rankings. Table headers: Rank (UB), Rank (StyleCtrl), Model, Arena Score, 95% CI, Votes, Organization, License. Shows 12 models including GLM-4-0520, Llama-3-70B-Instruct, Gemini-1.5-Flash-8B-Exp-0827, with rankings, scores, and licensing details. Models range from rank 52-69 with Arena scores between 1186-1207.\\n\\nThe earliest of those was Google‚Äôs Gemini 1.5 Pro, released in February. In addition to producing GPT-4 level outputs, it introduced several brand new capabilities to the field‚Äîmost notably its 1 million (and then later 2 million) token input context length, and the ability to input video.', 'I wrote about this at the time in The killer app of Gemini Pro 1.5 is video, which earned me a short appearance as a talking head in the Google I/O opening keynote in May.\\n\\nGemini 1.5 Pro also illustrated one of the key themes of 2024: increased context lengths. Last year most models accepted 4,096 or 8,192 tokens, with the notable exception of Claude 2.1 which accepted 200,000. Today every serious provider has a 100,000+ token model, and Google‚Äôs Gemini series accepts up to 2 million.\\n\\nLonger inputs dramatically increase the scope of problems that can be solved with an LLM: you can now throw in an entire book and ask questions about its contents, but more importantly you can feed in a lot of example code to help the model correctly solve a coding problem. LLM use-cases that involve long inputs are far more interesting to me than short prompts that rely purely on the information already baked into the model weights. Many of my tools were built using this pattern.', 'Did you know ChatGPT has two entirely different ways of running Python now?\\n\\nWant to build a Claude Artifact that talks to an external API? You‚Äôd better understand CSP and CORS HTTP headers first.\\n\\nThe models may have got more capable, but most of the limitations remained the same. OpenAI‚Äôs o1 may finally be able to (mostly) count the Rs in strawberry, but its abilities are still limited by its nature as an LLM and the constraints placed on it by the harness it‚Äôs running in. o1 can‚Äôt run web searches or use Code Interpreter, but GPT-4o can‚Äîboth in that same ChatGPT UI. (o1 will pretend to do those things if you ask it to, a regression to the URL hallucinations bug from early 2023).\\n\\nWhat are we doing about this? Not much. Most users are thrown in at the deep end. The default LLM chat UI is like taking brand new computer users, dropping them into a Linux terminal and expecting them to figure it all out.', 'This is a huge advantage for open over closed models: the closed, hosted models don‚Äôt have thousands of researchers and hobbyists around the world collaborating and competing to improve them.\\n\\nWe don‚Äôt yet know how to build GPT-4\\n\\nFrustratingly, despite the enormous leaps ahead we‚Äôve had this year, we are yet to see an alternative model that‚Äôs better than GPT-4.\\n\\nOpenAI released GPT-4 in March, though it later turned out we had a sneak peak of it in February when Microsoft used it as part of the new Bing.\\n\\nThis may well change in the next few weeks: Google‚Äôs Gemini Ultra has big claims, but isn‚Äôt yet available for us to try out.\\n\\nThe team behind Mistral are working to beat GPT-4 as well, and their track record is already extremely strong considering their first public model only came out in September, and they‚Äôve released two significant improvements since then.']",
                  "['<1-hop>\\n\\nof the best descriptions I‚Äôve seen of this comes from the Phi-4 technical report, which included this: Synthetic data as a substantial component of pretraining is becoming increasingly common, and the Phi series of models has consistently emphasized the importance of synthetic data. Rather than serving as a cheap substitute for organic data, synthetic data has several direct advantages over organic data. Structured and Gradual Learning. In organic datasets, the relationship between tokens is often complex and indirect. Many reasoning steps may be required to connect the current token to the next, making it challenging for the model to learn effectively from next-token prediction. By contrast, each token generated by a language model is by definition predicted by the preceding tokens, making it easier for a model to follow the resulting reasoning patterns. Another common technique is to use larger models to help create training data for their smaller, cheaper alternatives‚Äîa trick used by an increasing number of labs. DeepSeek v3 used ‚Äúreasoning‚Äù data created by DeepSeek-R1. Meta‚Äôs Llama 3.3 70B fine-tuning used over 25M synthetically generated examples. Careful design of the training data that goes into an LLM appears to be the entire game for creating these models. The days of just grabbing a full scrape of the web and indiscriminately dumping it into a training run are long gone. LLMs somehow got even harder to use A drum I‚Äôve been banging for a while is that LLMs are power-user tools‚Äîthey‚Äôre chainsaws disguised as kitchen knives. They look deceptively simple to use‚Äîhow hard can it be to type messages to a chatbot?‚Äîbut in reality you need a huge depth of both understanding and experience to make the most of them and avoid their many pitfalls. If anything, this problem got worse in 2024. We‚Äôve built computer systems you can talk to in human language, that will answer your questions and usually get them right! ... depending on the question, and how you ask it, and whether it‚Äôs accurately reflected in the undocumented and secret training set. The number of available systems has exploded. Different systems have different tools they can apply to your problems‚Äîlike Python and JavaScript and web search and image generation and maybe even database lookups... so you‚Äôd better understand what those tools are, what they can do and how to tell if the LLM used them or not. Did you know ChatGPT has two entirely different ways of running Python now? Want to build a Claude Artifact that talks to an external API? You‚Äôd better understand CSP and CORS HTTP headers first. The models may have got more capable, but most of the limitations remained the same. OpenAI‚Äôs o1 may finally be able to (mostly) count the Rs in strawberry, but its abilities are still limited by its nature as an LLM and the constraints placed on it by the harness it‚Äôs running in. o1 can‚Äôt run web searches or use Code Interpreter, but GPT-4o can‚Äîboth in that same ChatGPT UI. (o1 will pretend to do those things if you ask it to, a regression to the URL hallucinations bug from early 2023). What are we doing about this? Not much. Most users are thrown in at the deep end. The default LLM chat UI is like taking brand new computer users, dropping them into a Linux terminal and expecting them to figure it all out. Meanwhile, it‚Äôs increasingly common for end users to develop wildly inaccurate mental models of how these things work and what they are capable of. I‚Äôve seen so many examples of people trying to win an argument with a screenshot from ChatGPT‚Äîan inherently ludicrous proposition, given the inherent unreliability of these models crossed with the fact that you can get them to say anything if you prompt them right. There‚Äôs a flipside to this too: a lot of better informed people have sworn off LLMs entirely because they can‚Äôt see how anyone could benefit from a tool with so many flaws. The key skill in getting the most out of LLMs is learning to work with tech that is both inherently unreliable and incredibly powerful at the same time. This is a decidedly non-obvious skill to acquire! There is so much space for helpful education content here, but we need to do do a lot better than outsourcing it all to AI grifters with bombastic Twitter threads. Knowledge is incredibly unevenly distributed Most people have heard of ChatGPT by now. How many have heard of Claude? The knowledge gap between the people who actively follow this stuff and the 99% of the population who do not is vast. The pace of change doesn‚Äôt help either. In just the past month we‚Äôve seen general availability of live interfaces where you can point your phone‚Äôs camera at something and talk about it with your voice... and optionally have it pretend to be Santa. Most self-certified nerds haven‚Äôt even tried that yet. Given the ongoing (and potential) impact on society that this technology has, I don‚Äôt think the size of this gap is healthy. I‚Äôd like to see a lot more effort put into improving this. LLMs need better criticism A lot of people absolutely hate this stuff. In some of the spaces I hang out (Mastodon, Bluesky, Lobste.rs, even Hacker News on occasion) even suggesting that ‚ÄúLLMs are useful‚Äù can be enough to kick off a huge fight. I get it. There are plenty of reasons to dislike this technology‚Äîthe environmental impact, the (lack of) ethics of the training data, the lack of reliability, the negative applications, the potential impact on people‚Äôs jobs. LLMs absolutely warrant criticism. We need to be talking through these problems, finding ways to mitigate them and helping people learn how to use these tools responsibly in ways where the positive applications outweigh the negative. I like people who are skeptical of this stuff. The hype has been deafening for more than two years now, and there are enormous quantities of snake oil and misinformation out there. A lot', '<2-hop>\\n\\nyou talk to me exclusively in Spanish. OpenAI aren‚Äôt the only group with a multi-modal audio model. Google‚Äôs Gemini also accepts audio input, and the Google Gemini apps can speak in a similar way to ChatGPT now. Amazon also pre-announced voice mode for Amazon Nova, but that‚Äôs meant to roll out in Q1 of 2025. Google‚Äôs NotebookLM, released in September, took audio output to a new level by producing spookily realistic conversations between two ‚Äúpodcast hosts‚Äù about anything you fed into their tool. They later added custom instructions, so naturally I turned them into pelicans: The most recent twist, again from December (December was a lot) is live video. ChatGPT voice mode now provides the option to share your camera feed with the model and talk about what you can see in real time. Google Gemini have a preview of the same feature, which they managed to ship the day before ChatGPT did. These abilities are just a few weeks old at this point, and I don‚Äôt think their impact has been fully felt yet. If you haven‚Äôt tried them out yet you really should. Both Gemini and OpenAI offer API access to these features as well. OpenAI started with a WebSocket API that was quite challenging to use, but in December they announced a new WebRTC API which is much easier to get started with. Building a web app that a user can talk to via voice is easy now! Prompt driven app generation is a commodity already This was possible with GPT-4 in 2023, but the value it provides became evident in 2024. We already knew LLMs were spookily good at writing code. If you prompt them right, it turns out they can build you a full interactive application using HTML, CSS and JavaScript (and tools like React if you wire up some extra supporting build mechanisms)‚Äîoften in a single prompt. Anthropic kicked this idea into high gear when they released Claude Artifacts, a groundbreaking new feature that was initially slightly lost in the noise due to being described half way through their announcement of the incredible Claude 3.5 Sonnet. With Artifacts, Claude can write you an on-demand interactive application and then let you use it directly inside the Claude interface. Here‚Äôs my Extract URLs app, entirely generated by Claude: Extract URLs tool. Content pasted. URLs extracted. Shows a list of extracted URLs. I‚Äôve found myself using this a lot. I noticed how much I was relying on it in October and wrote Everything I built with Claude Artifacts this week, describing 14 little tools I had put together in a seven day period. Since then, a whole bunch of other teams have built similar systems. GitHub announced their version of this‚ÄîGitHub Spark‚Äîin October. Mistral Chat added it as a feature called Canvas in November. Steve Krouse from Val Town built a version of it against Cerebras, showcasing how a 2,000 token/second LLM can iterate on an application with changes visible in less than a second. Then in December, the Chatbot Arena team introduced a whole new leaderboard for this feature, driven by users building the same interactive app twice with two different models and voting on the answer. Hard to come up with a more convincing argument that this feature is now a commodity that can be effectively implemented against all of the leading models. I‚Äôve been tinkering with a version of this myself for my Datasette project, with the goal of letting users use prompts to build and iterate on custom widgets and data visualizations against their own data. I also figured out a similar pattern for writing one-shot Python programs, enabled by uv. This prompt-driven custom interface feature is so powerful and easy to build (once you‚Äôve figured out the gnarly details of browser sandboxing) that I expect it to show up as a feature in a wide range of products in 2025. Universal access to the best models lasted for just a few short months For a few short months this year all three of the best available models‚ÄîGPT-4o, Claude 3.5 Sonnet and Gemini 1.5 Pro‚Äîwere freely available to most of the world. OpenAI made GPT-4o free for all users in May, and Claude 3.5 Sonnet was freely available from its launch in June. This was a momentus change, because for the previous year free users had mostly been restricted to GPT-3.5 level models, meaning new users got a very inaccurate mental model of what a capable LLM could actually do. That era appears to have ended, likely permanently, with OpenAI‚Äôs launch of ChatGPT Pro. This $200/month subscription service is the only way to access their most capable model, o1 Pro. Since the trick behind the o1 series (and the future models it will undoubtedly inspire) is to expend more compute time to get better results, I don‚Äôt think those days of free access to the best available models are likely to return. ‚ÄúAgents‚Äù still haven‚Äôt really happened yet I find the term ‚Äúagents‚Äù extremely frustrating. It lacks a single, clear and widely understood meaning... but the people who use the term never seem to acknowledge that. If you tell me that you are building ‚Äúagents‚Äù, you‚Äôve conveyed almost no information to me at all. Without reading your mind I have no way of telling which of the dozens of possible definitions you are talking about. The two main categories I see are people who think AI agents are obviously things that go and act on your behalf‚Äîthe travel agent model‚Äîand people who think in terms of LLMs that have been given access to tools which they can run in a loop as part of solving a problem. The term ‚Äúautonomy‚Äù is often thrown into the mix too, again without including a clear definition. (I also collected 211 definitions on Twitter a few months ago‚Äîhere they are in Datasette Lite‚Äîand had gemini-exp-1206 attempt to summarize them.) Whatever the term may mean, agents still have that feeling of perpetually ‚Äúcoming soon‚Äù. Terminology aside, I remain']",
                  "Recent advanced features introduced in ChatGPT include live video capabilities, where the voice mode now allows users to share their camera feed and talk about what they see in real time. Additionally, OpenAI has made improvements to their API, introducing a new WebRTC API in December that simplifies building web apps for voice interactions. These features are very new, just a few weeks old, and their full impact is yet to be seen.\n\nIn comparison, Google Gemini introduced similar capabilities earlier, with a preview of live video features that shipped the day before ChatGPT's implementation. Gemini 1.5 Pro also showcased increased context lengths, accepting up to 2 million tokens, and the ability to input video, marking significant advancements in handling large inputs and multimodal data.\n\nOverall, both models have introduced advanced multimodal features like live video sharing and extended context lengths, with Gemini having a slight lead in the recent rollout of live video and longer input capabilities.",
                  "Recent advanced features introduced in ChatGPT include a voice mode that allows users to share their camera feed and have real-time conversations about what they see, as well as the ability to interact via voice. These features enable live video and audio interactions with the model. Google Gemini has introduced similar capabilities, such as accepting audio input and providing spoken responses, and also previewed live video features around the same time as ChatGPT. Both OpenAI and Google now offer API access to these multi-modal features, making it easier for developers to build applications that leverage voice and video interactions. While Amazon has announced a voice mode for Amazon Nova, it is scheduled for release in 2025. Overall, ChatGPT and Google Gemini are closely matched in rolling out these advanced multi-modal features, with both platforms providing users and developers with new ways to interact beyond text.",
                  "multi_hop_specific_query_synthesizer"
                ]
              ],
              "shape": {
                "columns": 6,
                "rows": 12
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_input</th>\n",
              "      <th>retrieved_contexts</th>\n",
              "      <th>reference_contexts</th>\n",
              "      <th>response</th>\n",
              "      <th>reference</th>\n",
              "      <th>synthesizer_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Which organizations, including Stability AI, h...</td>\n",
              "      <td>[I‚Äôm relieved that this has changed completely...</td>\n",
              "      <td>[We don‚Äôt yet know how to build GPT-4 Vibes Ba...</td>\n",
              "      <td>Yes, according to the provided context, organi...</td>\n",
              "      <td>Organizations that have produced better-than-G...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How does the use of Python by large language m...</td>\n",
              "      <td>[Code may be the best application\\n\\nThe ethic...</td>\n",
              "      <td>[I‚Äôm surprised that no-one has beaten the now ...</td>\n",
              "      <td>The use of Python in building and training lar...</td>\n",
              "      <td>According to the context, writing code is one ...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Wut is AI?</td>\n",
              "      <td>[A lot of people are excited about AI agents‚Äîa...</td>\n",
              "      <td>[Simon Willison‚Äôs Weblog Subscribe Stuff we fi...</td>\n",
              "      <td>AI, based on the provided context, refers to a...</td>\n",
              "      <td>AI refers to Large Language Models, which are ...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Whaat is the signifficance of OpenAI in the co...</td>\n",
              "      <td>[Law is not ethics. Is it OK to train models o...</td>\n",
              "      <td>[Microsoft over this issue. The 69 page PDF is...</td>\n",
              "      <td>According to the blog's 2023 tag cloud and tra...</td>\n",
              "      <td>According to the blog's 2023 tag cloud, 'opena...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Considering the applications of LLMs such as c...</td>\n",
              "      <td>[Code may be the best application\\n\\nThe ethic...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nWe don‚Äôt yet know how to build GPT...</td>\n",
              "      <td>The rise of LLMs has significantly impacted so...</td>\n",
              "      <td>The rise of LLMs has significantly impacted so...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>How have large language models impacted softwa...</td>\n",
              "      <td>[Code may be the best application\\n\\nThe ethic...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nWe don‚Äôt yet know how to build GPT...</td>\n",
              "      <td>Large language models have significantly impac...</td>\n",
              "      <td>Large language models (LLMs) have significantl...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>How does the use of synthetic training data pr...</td>\n",
              "      <td>[One of the best descriptions I‚Äôve seen of thi...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nThe rise of inference-scaling ‚Äúrea...</td>\n",
              "      <td>The use of synthetic training data offers seve...</td>\n",
              "      <td>Synthetic training data offers several direct ...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>How have improvements in LLM efficiency over t...</td>\n",
              "      <td>[If you can gather the right data, and afford ...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nThe rise of inference-scaling ‚Äúrea...</td>\n",
              "      <td>Improvements in LLM efficiency over the past y...</td>\n",
              "      <td>Improvements in LLM efficiency over the past y...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>How has ChatGPT been discussed in relation to ...</td>\n",
              "      <td>[How should we feel about this as software eng...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nof very bad decisions are being ma...</td>\n",
              "      <td>The discussion of ChatGPT in relation to pract...</td>\n",
              "      <td>ChatGPT has been a recurring topic in blog pos...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Anthropic make LLMs, but what is problem with ...</td>\n",
              "      <td>[LLMs need better criticism\\n\\nA lot of people...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nskeptical as to their utility base...</td>\n",
              "      <td>The main problems with LLMs, according to the ...</td>\n",
              "      <td>Anthropic is one of the organizations that has...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>How did Meta's Llama 3.3 70B utilize synthetic...</td>\n",
              "      <td>[I can now run a GPT-4 class model on my lapto...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nof the best descriptions I‚Äôve seen...</td>\n",
              "      <td>Meta's Llama 3.3 70B utilized over 25 million ...</td>\n",
              "      <td>Meta's Llama 3.3 70B fine-tuning process incor...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>What are some recent advanced features introdu...</td>\n",
              "      <td>[The most recent twist, again from December (D...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nof the best descriptions I‚Äôve seen...</td>\n",
              "      <td>Recent advanced features introduced in ChatGPT...</td>\n",
              "      <td>Recent advanced features introduced in ChatGPT...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           user_input  \\\n",
              "0   Which organizations, including Stability AI, h...   \n",
              "1   How does the use of Python by large language m...   \n",
              "2                                          Wut is AI?   \n",
              "3   Whaat is the signifficance of OpenAI in the co...   \n",
              "4   Considering the applications of LLMs such as c...   \n",
              "5   How have large language models impacted softwa...   \n",
              "6   How does the use of synthetic training data pr...   \n",
              "7   How have improvements in LLM efficiency over t...   \n",
              "8   How has ChatGPT been discussed in relation to ...   \n",
              "9   Anthropic make LLMs, but what is problem with ...   \n",
              "10  How did Meta's Llama 3.3 70B utilize synthetic...   \n",
              "11  What are some recent advanced features introdu...   \n",
              "\n",
              "                                   retrieved_contexts  \\\n",
              "0   [I‚Äôm relieved that this has changed completely...   \n",
              "1   [Code may be the best application\\n\\nThe ethic...   \n",
              "2   [A lot of people are excited about AI agents‚Äîa...   \n",
              "3   [Law is not ethics. Is it OK to train models o...   \n",
              "4   [Code may be the best application\\n\\nThe ethic...   \n",
              "5   [Code may be the best application\\n\\nThe ethic...   \n",
              "6   [One of the best descriptions I‚Äôve seen of thi...   \n",
              "7   [If you can gather the right data, and afford ...   \n",
              "8   [How should we feel about this as software eng...   \n",
              "9   [LLMs need better criticism\\n\\nA lot of people...   \n",
              "10  [I can now run a GPT-4 class model on my lapto...   \n",
              "11  [The most recent twist, again from December (D...   \n",
              "\n",
              "                                   reference_contexts  \\\n",
              "0   [We don‚Äôt yet know how to build GPT-4 Vibes Ba...   \n",
              "1   [I‚Äôm surprised that no-one has beaten the now ...   \n",
              "2   [Simon Willison‚Äôs Weblog Subscribe Stuff we fi...   \n",
              "3   [Microsoft over this issue. The 69 page PDF is...   \n",
              "4   [<1-hop>\\n\\nWe don‚Äôt yet know how to build GPT...   \n",
              "5   [<1-hop>\\n\\nWe don‚Äôt yet know how to build GPT...   \n",
              "6   [<1-hop>\\n\\nThe rise of inference-scaling ‚Äúrea...   \n",
              "7   [<1-hop>\\n\\nThe rise of inference-scaling ‚Äúrea...   \n",
              "8   [<1-hop>\\n\\nof very bad decisions are being ma...   \n",
              "9   [<1-hop>\\n\\nskeptical as to their utility base...   \n",
              "10  [<1-hop>\\n\\nof the best descriptions I‚Äôve seen...   \n",
              "11  [<1-hop>\\n\\nof the best descriptions I‚Äôve seen...   \n",
              "\n",
              "                                             response  \\\n",
              "0   Yes, according to the provided context, organi...   \n",
              "1   The use of Python in building and training lar...   \n",
              "2   AI, based on the provided context, refers to a...   \n",
              "3   According to the blog's 2023 tag cloud and tra...   \n",
              "4   The rise of LLMs has significantly impacted so...   \n",
              "5   Large language models have significantly impac...   \n",
              "6   The use of synthetic training data offers seve...   \n",
              "7   Improvements in LLM efficiency over the past y...   \n",
              "8   The discussion of ChatGPT in relation to pract...   \n",
              "9   The main problems with LLMs, according to the ...   \n",
              "10  Meta's Llama 3.3 70B utilized over 25 million ...   \n",
              "11  Recent advanced features introduced in ChatGPT...   \n",
              "\n",
              "                                            reference  \\\n",
              "0   Organizations that have produced better-than-G...   \n",
              "1   According to the context, writing code is one ...   \n",
              "2   AI refers to Large Language Models, which are ...   \n",
              "3   According to the blog's 2023 tag cloud, 'opena...   \n",
              "4   The rise of LLMs has significantly impacted so...   \n",
              "5   Large language models (LLMs) have significantl...   \n",
              "6   Synthetic training data offers several direct ...   \n",
              "7   Improvements in LLM efficiency over the past y...   \n",
              "8   ChatGPT has been a recurring topic in blog pos...   \n",
              "9   Anthropic is one of the organizations that has...   \n",
              "10  Meta's Llama 3.3 70B fine-tuning process incor...   \n",
              "11  Recent advanced features introduced in ChatGPT...   \n",
              "\n",
              "                        synthesizer_name  \n",
              "0   single_hop_specifc_query_synthesizer  \n",
              "1   single_hop_specifc_query_synthesizer  \n",
              "2   single_hop_specifc_query_synthesizer  \n",
              "3   single_hop_specifc_query_synthesizer  \n",
              "4   multi_hop_abstract_query_synthesizer  \n",
              "5   multi_hop_abstract_query_synthesizer  \n",
              "6   multi_hop_abstract_query_synthesizer  \n",
              "7   multi_hop_abstract_query_synthesizer  \n",
              "8   multi_hop_specific_query_synthesizer  \n",
              "9   multi_hop_specific_query_synthesizer  \n",
              "10  multi_hop_specific_query_synthesizer  \n",
              "11  multi_hop_specific_query_synthesizer  "
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset.to_csv('./data/evaluation-dataset-baseline.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TULcXSm0AUe0"
      },
      "source": [
        "Then we can convert that table into a `EvaluationDataset` which will make the process of evaluation smoother."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "B8zQhKR7yn1d"
      },
      "outputs": [],
      "source": [
        "from ragas import EvaluationDataset\n",
        "\n",
        "baseline_evaluation_dataset = EvaluationDataset.from_pandas(dataset.to_pandas())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQibuzfZAbvA"
      },
      "source": [
        "We'll need to select a judge model - in this case we're using the same model that was used to generate our Synthetic Data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "_q3Zl7sazFYB"
      },
      "outputs": [],
      "source": [
        "from ragas import evaluate\n",
        "from ragas.llms import LangchainLLMWrapper\n",
        "\n",
        "evaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzHuOZgBAoUU"
      },
      "source": [
        "Next up - we simply evaluate on our desired metrics!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257,
          "referenced_widgets": [
            "d0718259769b46089abda354accc4de8",
            "df156fe12b7c4d1dbb4f688d7bd3c4a3",
            "1f6cdc06bb18480aa341a732a2f1be13",
            "e362bfd3e01241c6b20e2cf0a34db7a1",
            "8ba70976ee1c451184f77494d8c47c7d",
            "ea70433388ef4d1aaf1093eaeea94dd4",
            "8fe50cb21cf9449e94efe57920440845",
            "4e03f27c3ff84046bceb5b4ec1dec571",
            "44f817c0df384faa90ac99e8bd772bc5",
            "8c251e4b43214ca894f136c5397b4a94",
            "e74718a731f0471e9740a7ae5aec571e"
          ]
        },
        "id": "M6mw2AeKziF1",
        "outputId": "dbc30b1e-6b84-4621-8307-f3060bd8ad20"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a66bc966d42940a5b27e8f81aa120656",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/72 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception raised in Job[2]: APIConnectionError(Connection error.)\n",
            "Exception raised in Job[13]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-ULKD0BfHsBV4junY2FxMu8EA on tokens per min (TPM): Limit 30000, Used 28829, Requested 2229. Please try again in 2.116s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "Exception raised in Job[11]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-ULKD0BfHsBV4junY2FxMu8EA on tokens per min (TPM): Limit 30000, Used 29274, Requested 1702. Please try again in 1.951s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "Exception raised in Job[22]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-ULKD0BfHsBV4junY2FxMu8EA on tokens per min (TPM): Limit 30000, Used 28775, Requested 1774. Please try again in 1.098s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "Exception raised in Job[19]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-ULKD0BfHsBV4junY2FxMu8EA on tokens per min (TPM): Limit 30000, Used 28823, Requested 2254. Please try again in 2.154s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "Exception raised in Job[7]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-ULKD0BfHsBV4junY2FxMu8EA on tokens per min (TPM): Limit 30000, Used 28564, Requested 2940. Please try again in 3.008s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "Exception raised in Job[8]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-ULKD0BfHsBV4junY2FxMu8EA on tokens per min (TPM): Limit 30000, Used 29941, Requested 1682. Please try again in 3.246s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "Exception raised in Job[16]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-ULKD0BfHsBV4junY2FxMu8EA on tokens per min (TPM): Limit 30000, Used 29833, Requested 1713. Please try again in 3.092s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "Exception raised in Job[28]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-ULKD0BfHsBV4junY2FxMu8EA on tokens per min (TPM): Limit 30000, Used 29036, Requested 1830. Please try again in 1.732s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "Exception raised in Job[29]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-ULKD0BfHsBV4junY2FxMu8EA on tokens per min (TPM): Limit 30000, Used 29194, Requested 1699. Please try again in 1.786s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "Exception raised in Job[24]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-ULKD0BfHsBV4junY2FxMu8EA on tokens per min (TPM): Limit 30000, Used 29210, Requested 2484. Please try again in 3.388s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "Exception raised in Job[1]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-ULKD0BfHsBV4junY2FxMu8EA on tokens per min (TPM): Limit 30000, Used 29969, Requested 2234. Please try again in 4.406s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "Exception raised in Job[26]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-ULKD0BfHsBV4junY2FxMu8EA on tokens per min (TPM): Limit 30000, Used 28648, Requested 1702. Please try again in 700ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "Exception raised in Job[25]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-ULKD0BfHsBV4junY2FxMu8EA on tokens per min (TPM): Limit 30000, Used 29484, Requested 2951. Please try again in 4.87s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "Exception raised in Job[34]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-ULKD0BfHsBV4junY2FxMu8EA on tokens per min (TPM): Limit 30000, Used 29950, Requested 1743. Please try again in 3.386s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "Exception raised in Job[30]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-ULKD0BfHsBV4junY2FxMu8EA on tokens per min (TPM): Limit 30000, Used 29872, Requested 2406. Please try again in 4.556s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "Exception raised in Job[31]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-ULKD0BfHsBV4junY2FxMu8EA on tokens per min (TPM): Limit 30000, Used 29232, Requested 2531. Please try again in 3.526s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "Exception raised in Job[36]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-ULKD0BfHsBV4junY2FxMu8EA on tokens per min (TPM): Limit 30000, Used 28554, Requested 2402. Please try again in 1.912s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "Exception raised in Job[49]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-ULKD0BfHsBV4junY2FxMu8EA on tokens per min (TPM): Limit 30000, Used 29906, Requested 2094. Please try again in 4s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "Exception raised in Job[37]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-ULKD0BfHsBV4junY2FxMu8EA on tokens per min (TPM): Limit 30000, Used 29994, Requested 2549. Please try again in 5.086s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "Exception raised in Job[42]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-ULKD0BfHsBV4junY2FxMu8EA on tokens per min (TPM): Limit 30000, Used 29301, Requested 2332. Please try again in 3.266s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "Exception raised in Job[43]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-ULKD0BfHsBV4junY2FxMu8EA on tokens per min (TPM): Limit 30000, Used 28782, Requested 2600. Please try again in 2.764s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "Exception raised in Job[35]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-ULKD0BfHsBV4junY2FxMu8EA on tokens per min (TPM): Limit 30000, Used 29386, Requested 1704. Please try again in 2.18s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "Exception raised in Job[50]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-ULKD0BfHsBV4junY2FxMu8EA on tokens per min (TPM): Limit 30000, Used 29865, Requested 1778. Please try again in 3.286s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "Exception raised in Job[53]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-ULKD0BfHsBV4junY2FxMu8EA on tokens per min (TPM): Limit 30000, Used 28792, Requested 2094. Please try again in 1.772s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "Exception raised in Job[48]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-ULKD0BfHsBV4junY2FxMu8EA on tokens per min (TPM): Limit 30000, Used 29611, Requested 2482. Please try again in 4.186s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "Exception raised in Job[54]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-ULKD0BfHsBV4junY2FxMu8EA on tokens per min (TPM): Limit 30000, Used 29786, Requested 2256. Please try again in 4.084s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "Exception raised in Job[61]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-ULKD0BfHsBV4junY2FxMu8EA on tokens per min (TPM): Limit 30000, Used 29867, Requested 2206. Please try again in 4.146s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "Exception raised in Job[47]: TimeoutError()\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'context_recall': 0.4722, 'faithfulness': 0.7415, 'factual_correctness': 0.4225, 'answer_relevancy': 0.9538, 'context_entity_recall': 0.4993, 'noise_sensitivity_relevant': 0.1831}"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from ragas.metrics import LLMContextRecall, Faithfulness, FactualCorrectness, ResponseRelevancy, ContextEntityRecall, NoiseSensitivity\n",
        "from ragas import evaluate, RunConfig\n",
        "\n",
        "custom_run_config = RunConfig(timeout=360)\n",
        "\n",
        "baseline_result = evaluate(\n",
        "    dataset=baseline_evaluation_dataset,\n",
        "    metrics=[LLMContextRecall(), Faithfulness(), FactualCorrectness(), ResponseRelevancy(), ContextEntityRecall(), NoiseSensitivity()],\n",
        "    llm=evaluator_llm,\n",
        "    run_config=custom_run_config\n",
        ")\n",
        "baseline_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZxxr2NqAyBp"
      },
      "source": [
        "## Making Adjustments and Re-Evaluating\n",
        "\n",
        "Now that we've got our baseline - let's make a change and see how the model improves or doesn't improve!\n",
        "\n",
        "> NOTE: This will be using Cohere's Rerank model (which was updated fairly [recently](https://docs.cohere.com/v2/changelog/rerank-v3.5)) - please be sure to [sign-up for an API key!](https://docs.cohere.com/reference/about)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMpf7nFDBH-K",
        "outputId": "5146dc88-964a-45b1-c030-15a0de3c4546"
      },
      "outputs": [],
      "source": [
        "os.environ[\"COHERE_API_KEY\"] = getpass(\"Please enter your Cohere API key!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMwNl2M5BYWg",
        "outputId": "1c05d482-d64f-4123-d449-4c32bc2be1ff"
      },
      "outputs": [],
      "source": [
        "#!pip install -qU cohere langchain_cohere"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "We'll first set our retriever to return more documents, which will allow us to take advantage of the reranking."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "3Oa5r78dA4K9"
      },
      "outputs": [],
      "source": [
        "retriever = vector_store.as_retriever(search_kwargs={\"k\": 20})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Reranking, or contextual compression, is a technique that uses a reranker to compress the retrieved documents into a smaller set of documents.\n",
        "\n",
        "This is essentially a slower, more accurate form of semantic similarity that we use on a smaller subset of our documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "B3d3B3OEBCCc"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
        "from langchain_cohere import CohereRerank\n",
        "\n",
        "def retrieve_adjusted(state):\n",
        "  compressor = CohereRerank(model=\"rerank-v3.5\")\n",
        "  compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor, base_retriever=retriever, search_kwargs={\"k\": 5}\n",
        "  )\n",
        "  retrieved_docs = compression_retriever.invoke(state[\"question\"])\n",
        "  return {\"context\" : retrieved_docs}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can simply rebuild our graph with the new retriever!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "4XZKorBaB4BW"
      },
      "outputs": [],
      "source": [
        "class State(TypedDict):\n",
        "  question: str\n",
        "  context: List[Document]\n",
        "  response: str\n",
        "\n",
        "graph_builder = StateGraph(State).add_sequence([retrieve_adjusted, generate])\n",
        "graph_builder.add_edge(START, \"retrieve_adjusted\")\n",
        "graph = graph_builder.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "s7doJbZJB_19",
        "outputId": "c64ec4a0-8cb9-47ab-f369-736fc0182fad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'LLM agents are useful because they can act on your behalf, such as performing tasks like travel planning or research, by accessing and utilizing tools within a loop to solve problems. Additionally, writing code is one of the most effective applications of LLMs, as they excel at generating and understanding programming languages like Python and JavaScript.'"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = graph.invoke({\"question\" : \"How are LLM agents useful?\"})\n",
        "response[\"response\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "siBFKs-gCDdQ"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "for test_row in dataset:\n",
        "  response = graph.invoke({\"question\" : test_row.eval_sample.user_input})\n",
        "  test_row.eval_sample.response = response[\"response\"]\n",
        "  test_row.eval_sample.retrieved_contexts = [context.page_content for context in response[\"context\"]]\n",
        "  time.sleep(2) # To try to avoid rate limiting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "user_input",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "retrieved_contexts",
                  "rawType": "object",
                  "type": "unknown"
                },
                {
                  "name": "reference_contexts",
                  "rawType": "object",
                  "type": "unknown"
                },
                {
                  "name": "response",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "reference",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "synthesizer_name",
                  "rawType": "object",
                  "type": "string"
                }
              ],
              "conversionMethod": "pd.DataFrame",
              "ref": "87807c1f-b963-4610-abfa-76a89660467a",
              "rows": [
                [
                  "0",
                  "Which organizations, including Stability AI, have produced better-than-GPT-3 class large language models?",
                  "['If you can gather the right data, and afford to pay for the GPUs to train it, you can build an LLM.\\n\\nA year ago, the only organization that had released a generally useful LLM was OpenAI. We‚Äôve now seen better-than-GPT-3 class models produced by Anthropic, Mistral, Google, Meta, EleutherAI, Stability AI, TII in Abu Dhabi (Falcon), Microsoft Research, xAI, Replit, Baidu and a bunch of other organizations.\\n\\nThe training cost (hardware and electricity) is still significant‚Äîinitially millions of dollars, but that seems to have dropped to the tens of thousands already. Microsoft‚Äôs Phi-2 claims to have used ‚Äú14 days on 96 A100 GPUs‚Äù, which works out at around $35,000 using current Lambda pricing.', 'Getting back to models that beat GPT-4: Anthropic‚Äôs Claude 3 series launched in March, and Claude 3 Opus quickly became my new favourite daily-driver. They upped the ante even more in June with the launch of Claude 3.5 Sonnet‚Äîa model that is still my favourite six months later (though it got a significant upgrade on October 22, confusingly keeping the same 3.5 version number. Anthropic fans have since taken to calling it Claude 3.6).\\n\\nThen there‚Äôs the rest. If you browse the Chatbot Arena leaderboard today‚Äîstill the most useful single place to get a vibes-based evaluation of models‚Äîyou‚Äôll see that GPT-4-0314 has fallen to around 70th place. The 18 organizations with higher scoring models are Google, OpenAI, Alibaba, Anthropic, Meta, Reka AI, 01 AI, Amazon, Cohere, DeepSeek, Nvidia, Mistral, NexusFlow, Zhipu AI, xAI, AI21 Labs, Princeton and Tencent.', '‚ÄúAgents‚Äù still haven‚Äôt really happened yet\\n\\nEvals really matter\\n\\nApple Intelligence is bad, Apple‚Äôs MLX library is excellent\\n\\nThe rise of inference-scaling ‚Äúreasoning‚Äù models\\n\\nWas the best currently available LLM trained in China for less than $6m?\\n\\nThe environmental impact got better\\n\\nThe environmental impact got much, much worse\\n\\nThe year of slop\\n\\nSynthetic training data works great\\n\\nLLMs somehow got even harder to use\\n\\nKnowledge is incredibly unevenly distributed\\n\\nLLMs need better criticism\\n\\nEverything tagged ‚Äúllms‚Äù on my blog in 2024\\n\\nThe GPT-4 barrier was comprehensively broken\\n\\nIn my December 2023 review I wrote about how We don‚Äôt yet know how to build GPT-4‚ÄîOpenAI‚Äôs best model was almost a year old at that point, yet no other AI lab had produced anything better. What did OpenAI know that the rest of us didn‚Äôt?']",
                  "['We don‚Äôt yet know how to build GPT-4 Vibes Based Development LLMs are really smart, and also really, really dumb Gullibility is the biggest unsolved problem Code may be the best application The ethics of this space remain diabolically complex My blog in 2023 Here‚Äôs the sequel to this post: Things we learned about LLMs in 2024. Large Language Models In the past 24-36 months, our species has discovered that you can take a GIANT corpus of text, run it through a pile of GPUs, and use it to create a fascinating new kind of software. LLMs can do a lot of things. They can answer questions, summarize documents, translate from one language to another, extract information and even write surprisingly competent code. They can also help you cheat at your homework, generate unlimited streams of fake content and be used for all manner of nefarious purposes. So far, I think they‚Äôre a net positive. I‚Äôve used them on a personal level to improve my productivity (and entertain myself) in all sorts of different ways. I think people who learn how to use them effectively can gain a significant boost to their quality of life. A lot of people are yet to be sold on their value! Some think their negatives outweigh their positives, some think they are all hot air, and some even think they represent an existential threat to humanity. They‚Äôre actually quite easy to build The most surprising thing we‚Äôve learned about LLMs this year is that they‚Äôre actually quite easy to build. Intuitively, one would expect that systems this powerful would take millions of lines of complex code. Instead, it turns out a few hundred lines of Python is genuinely enough to train a basic version! What matters most is the training data. You need a lot of data to make these things work, and the quantity and quality of the training data appears to be the most important factor in how good the resulting model is. If you can gather the right data, and afford to pay for the GPUs to train it, you can build an LLM. A year ago, the only organization that had released a generally useful LLM was OpenAI. We‚Äôve now seen better-than-GPT-3 class models produced by Anthropic, Mistral, Google, Meta, EleutherAI, Stability AI, TII in Abu Dhabi (Falcon), Microsoft Research, xAI, Replit, Baidu and a bunch of other organizations. The training cost (hardware and electricity) is still significant‚Äîinitially millions of dollars, but that seems to have dropped to the tens of thousands already. Microsoft‚Äôs Phi-2 claims to have used ‚Äú14 days on 96 A100 GPUs‚Äù, which works out at around $35,000 using current Lambda pricing. So training an LLM still isn‚Äôt something a hobbyist can afford, but it‚Äôs no longer the sole domain of the super-rich. I like to compare the difficulty of training an LLM to that of building a suspension bridge‚Äînot trivial, but hundreds of countries around the world have figured out how to do it. (Correction: Wikipedia‚Äôs Suspension bridges by country category lists 44 countries). You can run LLMs on your own devices In January of this year, I thought it would be years before I could run a useful LLM on my own computer. GPT-3 and 3.5 were pretty much the only games in town, and I thought that even if the model weights were available it would take a $10,000+ server to run them. Then in February, Meta released Llama. And a few weeks later in March, Georgi Gerganov released code that got it working on a MacBook. I wrote about how Large language models are having their Stable Diffusion moment, and with hindsight that was a very good call! This unleashed a whirlwind of innovation, which was accelerated further in July when Meta released Llama 2‚Äîan improved version which, crucially, included permission for commercial use. Today there are literally thousands of LLMs that can be run locally, on all manner of different devices. I run a bunch of them on my laptop. I run Mistral 7B (a surprisingly great model) on my iPhone. You can install several different apps to get your own, local, completely private LLM. My own LLM project provides a CLI tool for running an array of different models via plugins. You can even run them entirely in your browser using WebAssembly and the latest Chrome! Hobbyists can build their own fine-tuned models I said earlier that building an LLM was still out of reach of hobbyists. That may be true for training from scratch, but fine-tuning one of those models is another matter entirely. There‚Äôs now a fascinating ecosystem of people training their own models on top of these foundations, publishing those models, building fine-tuning datasets and sharing those too. The Hugging Face Open LLM Leaderboard is one place that tracks these. I can‚Äôt even attempt to count them, and any count would be out-of-date within a few hours. The best overall openly licensed LLM at any time is rarely a foundation model: instead, it‚Äôs whichever fine-tuned community model has most recently discovered the best combination of fine-tuning data. This is a huge advantage for open over closed models: the closed, hosted models don‚Äôt have thousands of researchers and hobbyists around the world collaborating and competing to improve them. We don‚Äôt yet know how to build GPT-4 Frustratingly, despite the enormous leaps ahead we‚Äôve had this year, we are yet to see an alternative model that‚Äôs better than GPT-4. OpenAI released GPT-4 in March, though it later turned out we had a sneak peak of it in February when Microsoft used it as part of the new Bing. This may well change in the next few weeks: Google‚Äôs Gemini Ultra has big claims, but isn‚Äôt yet available for us to try out. The team behind Mistral are working to beat GPT-4 as well, and their track record is already extremely strong considering their first public model only came out in September, and they‚Äôve released two significant improvements since then. Still,']",
                  "Organizations that have produced better-than-GPT-3 class large language models, including Stability AI, are:\n\n- Anthropic\n- Mistral\n- Google\n- Meta\n- EleutherAI\n- Stability AI\n- TII in Abu Dhabi (Falcon)\n- Microsoft Research\n- xAI\n- Replit\n- Baidu\n- A bunch of other organizations",
                  "Organizations that have produced better-than-GPT-3 class large language models include Anthropic, Mistral, Google, Meta, EleutherAI, Stability AI, TII in Abu Dhabi (Falcon), Microsoft Research, xAI, Replit, and Baidu.",
                  "single_hop_specifc_query_synthesizer"
                ],
                [
                  "1",
                  "How does the use of Python by large language models (LLMs) impact their code generation capabilities, and what are the implications for evaluating LLM performance in coding tasks?",
                  "['It‚Äôs still astonishing to me how effective they are though.\\n\\nOne of the great weaknesses of LLMs is their tendency to hallucinate‚Äîto imagine things that don‚Äôt correspond to reality. You would expect this to be a particularly bad problem for code‚Äîif an LLM hallucinates a method that doesn‚Äôt exist, the code should be useless.\\n\\nExcept... you can run generated code to see if it‚Äôs correct. And with patterns like ChatGPT Code Interpreter the LLM can execute the code itself, process the error message, then rewrite it and keep trying until it works!\\n\\nSo hallucination is a much lesser problem for code generation than for anything else. If only we had the equivalent of Code Interpreter for fact-checking natural language!\\n\\nHow should we feel about this as software engineers?\\n\\nOn the one hand, this feels like a threat: who needs a programmer if ChatGPT can write code for you?', 'Still, I‚Äôm surprised that no-one has beaten the now almost year old GPT-4 by now. OpenAI clearly have some substantial tricks that they haven‚Äôt shared yet.\\n\\nVibes Based Development\\n\\nAs a computer scientist and software engineer, LLMs are infuriating.\\n\\nEven the openly licensed ones are still the world‚Äôs most convoluted black boxes. We continue to have very little idea what they can do, how exactly they work and how best to control them.\\n\\nI‚Äôm used to programming where the computer does exactly what I tell it to do. Prompting an LLM is decidedly not that!\\n\\nThe worst part is the challenge of evaluating them.\\n\\nThere are plenty of benchmarks, but no benchmark is going to tell you if an LLM actually ‚Äúfeels‚Äù right when you try it for a given task.\\n\\nI find I have to work with an LLM for a few weeks in order to get a good intuition for it‚Äôs strengths and weaknesses. This greatly limits how many I can evaluate myself!\\n\\nThe most frustrating thing for me is at the level of individual prompting.', 'A lot of people are yet to be sold on their value! Some think their negatives outweigh their positives, some think they are all hot air, and some even think they represent an existential threat to humanity.\\n\\nThey‚Äôre actually quite easy to build\\n\\nThe most surprising thing we‚Äôve learned about LLMs this year is that they‚Äôre actually quite easy to build.\\n\\nIntuitively, one would expect that systems this powerful would take millions of lines of complex code. Instead, it turns out a few hundred lines of Python is genuinely enough to train a basic version!\\n\\nWhat matters most is the training data. You need a lot of data to make these things work, and the quantity and quality of the training data appears to be the most important factor in how good the resulting model is.\\n\\nIf you can gather the right data, and afford to pay for the GPUs to train it, you can build an LLM.']",
                  "['I‚Äôm surprised that no-one has beaten the now almost year old GPT-4 by now. OpenAI clearly have some substantial tricks that they haven‚Äôt shared yet. Vibes Based Development As a computer scientist and software engineer, LLMs are infuriating. Even the openly licensed ones are still the world‚Äôs most convoluted black boxes. We continue to have very little idea what they can do, how exactly they work and how best to control them. I‚Äôm used to programming where the computer does exactly what I tell it to do. Prompting an LLM is decidedly not that! The worst part is the challenge of evaluating them. There are plenty of benchmarks, but no benchmark is going to tell you if an LLM actually ‚Äúfeels‚Äù right when you try it for a given task. I find I have to work with an LLM for a few weeks in order to get a good intuition for it‚Äôs strengths and weaknesses. This greatly limits how many I can evaluate myself! The most frustrating thing for me is at the level of individual prompting. Sometimes I‚Äôll tweak a prompt and capitalize some of the words in it, to emphasize that I really want it to OUTPUT VALID MARKDOWN or similar. Did capitalizing those words make a difference? I still don‚Äôt have a good methodology for figuring that out. We‚Äôre left with what‚Äôs effectively Vibes Based Development. It‚Äôs vibes all the way down. I‚Äôd love to see us move beyond vibes in 2024! LLMs are really smart, and also really, really dumb On the one hand, we keep on finding new things that LLMs can do that we didn‚Äôt expect‚Äîand that the people who trained the models didn‚Äôt expect either. That‚Äôs usually really fun! But on the other hand, the things you sometimes have to do to get the models to behave are often incredibly dumb. Does ChatGPT get lazy in December, because its hidden system prompt includes the current date and its training data shows that people provide less useful answers coming up to the holidays? The honest answer is ‚Äúmaybe‚Äù! No-one is entirely sure, but if you give it a different date its answers may skew slightly longer. Sometimes it omits sections of code and leaves you to fill them in, but if you tell it you can‚Äôt type because you don‚Äôt have any fingers it produces the full code for you instead. There are so many more examples like this. Offer it cash tips for better answers. Tell it your career depends on it. Give it positive reinforcement. It‚Äôs all so dumb, but it works! Gullibility is the biggest unsolved problem I coined the term prompt injection in September last year. 15 months later, I regret to say that we‚Äôre still no closer to a robust, dependable solution to this problem. I‚Äôve written a ton about this already. Beyond that specific class of security vulnerabilities, I‚Äôve started seeing this as a wider problem of gullibility. Language Models are gullible. They ‚Äúbelieve‚Äù what we tell them‚Äîwhat‚Äôs in their training data, then what‚Äôs in the fine-tuning data, then what‚Äôs in the prompt. In order to be useful tools for us, we need them to believe what we feed them! But it turns out a lot of the things we want to build need them not to be gullible. Everyone wants an AI personal assistant. If you hired a real-world personal assistant who believed everything that anyone told them, you would quickly find that their ability to positively impact your life was severely limited. A lot of people are excited about AI agents‚Äîan infuriatingly vague term that seems to be converging on ‚ÄúAI systems that can go away and act on your behalf‚Äù. We‚Äôve been talking about them all year, but I‚Äôve seen few if any examples of them running in production, despite lots of exciting prototypes. I think this is because of gullibility. Can we solve this? Honestly, I‚Äôm beginning to suspect that you can‚Äôt fully solve gullibility without achieving AGI. So it may be quite a while before those agent dreams can really start to come true! Code may be the best application Over the course of the year, it‚Äôs become increasingly clear that writing code is one of the things LLMs are most capable of. If you think about what they do, this isn‚Äôt such a big surprise. The grammar rules of programming languages like Python and JavaScript are massively less complicated than the grammar of Chinese, Spanish or English. It‚Äôs still astonishing to me how effective they are though. One of the great weaknesses of LLMs is their tendency to hallucinate‚Äîto imagine things that don‚Äôt correspond to reality. You would expect this to be a particularly bad problem for code‚Äîif an LLM hallucinates a method that doesn‚Äôt exist, the code should be useless. Except... you can run generated code to see if it‚Äôs correct. And with patterns like ChatGPT Code Interpreter the LLM can execute the code itself, process the error message, then rewrite it and keep trying until it works! So hallucination is a much lesser problem for code generation than for anything else. If only we had the equivalent of Code Interpreter for fact-checking natural language! How should we feel about this as software engineers? On the one hand, this feels like a threat: who needs a programmer if ChatGPT can write code for you? On the other hand, as software engineers we are better placed to take advantage of this than anyone else. We‚Äôve all been given weird coding interns‚Äîwe can use our deep knowledge to prompt them to solve coding problems more effectively than anyone else can. The ethics of this space remain diabolically complex In September last year Andy Baio and I produced the first major story on the unlicensed training data behind Stable Diffusion. Since then, almost every major LLM (and most of the image generation models) have also been trained on unlicensed data. Just this week, the New York Times launched a landmark lawsuit against OpenAI and']",
                  "The use of Python by large language models (LLMs) significantly enhances their code generation capabilities, as it allows for the development of models that can be trained with relatively few lines of Python code‚Äîsometimes just a few hundred lines‚Äîto create basic versions. This indicates that Python serves as a crucial tool in building and training these models, emphasizing the importance of accessible, flexible programming languages in their development.\n\nIn terms of evaluating LLM performance in coding tasks, the fact that generated code can be executed to verify correctness is a major advantage. This execution-based approach reduces the problem of hallucination‚Äîwhere the model invents non-existent methods or functions‚Äîsince errors can be caught and iteratively fixed through testing and rewriting. Consequently, the ability of LLMs to generate executable code and self-correct through run-time feedback makes their code generation more reliable and easier to assess, compared to natural language tasks where factual correctness is harder to verify.\n\nOverall, the integration of Python in training LLMs and the capacity to run and test generated code directly impact their effectiveness in coding tasks and influence how their performance is evaluated‚Äîfavoring approaches that incorporate execution and iterative testing for more accurate assessment.",
                  "According to the context, writing code is one of the things LLMs are most capable of, and this is partly because the grammar rules of programming languages like Python are massively less complicated than those of natural languages such as Chinese, Spanish, or English. This makes it less surprising that LLMs are effective at generating code in Python. Although LLMs have a tendency to hallucinate, this issue is less problematic for code generation because generated code can be run to check its correctness. Additionally, tools like ChatGPT Code Interpreter allow the LLM to execute Python code, process error messages, and iteratively rewrite the code until it works. This means that hallucination is a much lesser problem for code generation than for other tasks. However, evaluating LLM performance in coding tasks remains challenging, as benchmarks may not fully capture whether an LLM 'feels' right for a given task, and developing a good methodology for prompt engineering and evaluation is still an open problem.",
                  "single_hop_specifc_query_synthesizer"
                ],
                [
                  "2",
                  "Wut is AI?",
                  "['A lot of people are excited about AI agents‚Äîan infuriatingly vague term that seems to be converging on ‚ÄúAI systems that can go away and act on your behalf‚Äù. We‚Äôve been talking about them all year, but I‚Äôve seen few if any examples of them running in production, despite lots of exciting prototypes.\\n\\nI think this is because of gullibility.\\n\\nCan we solve this? Honestly, I‚Äôm beginning to suspect that you can‚Äôt fully solve gullibility without achieving AGI. So it may be quite a while before those agent dreams can really start to come true!\\n\\nCode may be the best application\\n\\nOver the course of the year, it‚Äôs become increasingly clear that writing code is one of the things LLMs are most capable of.\\n\\nIf you think about what they do, this isn‚Äôt such a big surprise. The grammar rules of programming languages like Python and JavaScript are massively less complicated than the grammar of Chinese, Spanish or English.\\n\\nIt‚Äôs still astonishing to me how effective they are though.', 'Article Visitors Pageviews Bing: ‚ÄúI will not harm you unless you harm me first‚Äù 1.1M 1.3M Leaked Google document: ‚ÄúWe Have No Moat, And Neither Does OpenAI‚Äù 132k 162k Large language models are having their Stable Diffusion moment 121k 150k Prompt injection: What‚Äôs the worst that can happen? 79.8k 95.9k Embeddings: What they are and why they matter 61.7k 79.3k Catching up on the weird world of LLMs 61.6k 85.9k llamafile is the new best way to run an LLM on your own computer 52k 66k Prompt injection explained, with video, slides, and a transcript 51k 61.9k AI-enhanced development makes me more ambitious with my projects 49.6k 60.1k Understanding GPT tokenizers 49.5k 61.1k Exploring GPTs: ChatGPT in a trench coat? 46.4k 58.5k Could you train a ChatGPT-beating model for $85,000 and run it in a browser? 40.5k 49.2k How to implement Q&A against your documentation with GPT3, embeddings and Datasette 37.3k 44.9k Lawyer cites fake cases invented by ChatGPT, judge is not amused 37.1k 47.4k Now', 'The two main categories I see are people who think AI agents are obviously things that go and act on your behalf‚Äîthe travel agent model‚Äîand people who think in terms of LLMs that have been given access to tools which they can run in a loop as part of solving a problem. The term ‚Äúautonomy‚Äù is often thrown into the mix too, again without including a clear definition.\\n\\n(I also collected 211 definitions on Twitter a few months ago‚Äîhere they are in Datasette Lite‚Äîand had gemini-exp-1206 attempt to summarize them.)\\n\\nWhatever the term may mean, agents still have that feeling of perpetually ‚Äúcoming soon‚Äù.\\n\\nTerminology aside, I remain skeptical as to their utility based, once again, on the challenge of gullibility. LLMs believe anything you tell them. Any systems that attempts to make meaningful decisions on your behalf will run into the same roadblock: how good is a travel agent, or a digital assistant, or even a research tool if it can‚Äôt distinguish truth from fiction?']",
                  "['Simon Willison‚Äôs Weblog Subscribe Stuff we figured out about AI in 2023 31st December 2023 2023 was the breakthrough year for Large Language Models (LLMs). I think it‚Äôs OK to call these AI‚Äîthey‚Äôre the latest and (currently) most interesting development in the academic field of Artificial Intelligence that dates back to the 1950s. Here‚Äôs my attempt to round up the highlights in one place! Large Language Models They‚Äôre actually quite easy to build You can run LLMs on your own devices Hobbyists can build their own fine-tuned models']",
                  "Based on the provided context, AI refers to systems that are capable of acting on your behalf, often called AI agents. These agents are envisioned as autonomous entities that can perform tasks or make decisions, but the term remains somewhat vague and still in development. The context also discusses that AI, particularly large language models (LLMs), are highly capable of tasks like writing code and understanding language, but their utility as autonomous agents is challenged by issues like gullibility‚Äîsince LLMs believe anything they are told and cannot reliably distinguish truth from fiction without achieving artificial general intelligence (AGI).",
                  "AI refers to Large Language Models, which are the latest and most interesting development in the academic field of Artificial Intelligence.",
                  "single_hop_specifc_query_synthesizer"
                ],
                [
                  "3",
                  "Whaat is the signifficance of OpenAI in the context of LLMs and AI discusionns acccording to the blog's 2023 tag cloud and traffic data?",
                  "['Law is not ethics. Is it OK to train models on people‚Äôs content without their permission, when those models will then be used in ways that compete with those people?\\n\\nAs the quality of results produced by AI models has increased over the year, these questions have become even more pressing.\\n\\nThe impact on human society in terms of these models is already huge, if difficult to objectively measure.\\n\\nPeople have certainly lost work to them‚Äîanecdotally, I‚Äôve seen this for copywriters, artists and translators.\\n\\nThere are a great deal of untold stories here. I‚Äôm hoping 2024 sees significant amounts of dedicated journalism on this topic.\\n\\nMy blog in 2023\\n\\nHere‚Äôs a tag cloud for content I posted to my blog in 2023 (generated using Django SQL Dashboard):\\n\\nTag cloud words in order of size: ai, generativeai, llms, openai, chatgpt, projects, python, datasette, ethics, llama, homebrewllms, sqlite, gpt3, promptengineering, promptinjection, llm, security, opensource, gpt4, weeknotes', '‚ÄúAgents‚Äù still haven‚Äôt really happened yet\\n\\nEvals really matter\\n\\nApple Intelligence is bad, Apple‚Äôs MLX library is excellent\\n\\nThe rise of inference-scaling ‚Äúreasoning‚Äù models\\n\\nWas the best currently available LLM trained in China for less than $6m?\\n\\nThe environmental impact got better\\n\\nThe environmental impact got much, much worse\\n\\nThe year of slop\\n\\nSynthetic training data works great\\n\\nLLMs somehow got even harder to use\\n\\nKnowledge is incredibly unevenly distributed\\n\\nLLMs need better criticism\\n\\nEverything tagged ‚Äúllms‚Äù on my blog in 2024\\n\\nThe GPT-4 barrier was comprehensively broken\\n\\nIn my December 2023 review I wrote about how We don‚Äôt yet know how to build GPT-4‚ÄîOpenAI‚Äôs best model was almost a year old at that point, yet no other AI lab had produced anything better. What did OpenAI know that the rest of us didn‚Äôt?', 'I also gave a bunch of talks and podcast appearances. I‚Äôve started habitually turning my talks into annotated presentations‚Äîhere are my best from 2023:\\n\\nPrompt injection explained, with video, slides, and a transcript\\n\\nCatching up on the weird world of LLMs\\n\\nMaking Large Language Models work for you\\n\\nOpen questions for AI engineering\\n\\nEmbeddings: What they are and why they matter\\n\\nFinancial sustainability for open source projects at GitHub Universe\\n\\nAnd in podcasts:\\n\\nWhat AI can do for you on the Theory of Change\\n\\nWorking in public on Path to Citus Con\\n\\nLLMs break the internet on the Changelog\\n\\nTalking Large Language Models on Rooftop Ruby\\n\\nThoughts on the OpenAI board situation on Newsroom Robots\\n\\nIndustry‚Äôs Tardy Response to the AI Prompt Injection Vulnerability on RedMonk Conversations\\n\\nPosted 31st December 2023 at 11:59 pm ¬∑ Follow me on Mastodon, Bluesky, Twitter or subscribe to my newsletter\\n\\nMore recent articles']",
                  "['Microsoft over this issue. The 69 page PDF is genuinely worth reading‚Äîespecially the first few pages, which lay out the issues in a way that‚Äôs surprisingly easy to follow. The rest of the document includes some of the clearest explanations of what LLMs are, how they work and how they are built that I‚Äôve read anywhere. The legal arguments here are complex. I‚Äôm not a lawyer, but I don‚Äôt think this one will be easily decided. Whichever way it goes, I expect this case to have a profound impact on how this technology develops in the future. Law is not ethics. Is it OK to train models on people‚Äôs content without their permission, when those models will then be used in ways that compete with those people? As the quality of results produced by AI models has increased over the year, these questions have become even more pressing. The impact on human society in terms of these models is already huge, if difficult to objectively measure. People have certainly lost work to them‚Äîanecdotally, I‚Äôve seen this for copywriters, artists and translators. There are a great deal of untold stories here. I‚Äôm hoping 2024 sees significant amounts of dedicated journalism on this topic. My blog in 2023 Here‚Äôs a tag cloud for content I posted to my blog in 2023 (generated using Django SQL Dashboard): Tag cloud words in order of size: ai, generativeai, llms, openai, chatgpt, projects, python, datasette, ethics, llama, homebrewllms, sqlite, gpt3, promptengineering, promptinjection, llm, security, opensource, gpt4, weeknotes The top five: ai (342), generativeai (300), llms (287), openai (86), chatgpt (78). I‚Äôve written a lot about this stuff! I grabbed a screenshot of my Plausible analytics for the year, fed that to ChatGPT Vision, told it to extract the data into a table, then got it to mix in entry titles (from a SQL query it wrote) and produced this table with it. Here are my top entries this year by amount of traffic: Article Visitors Pageviews Bing: ‚ÄúI will not harm you unless you harm me first‚Äù 1.1M 1.3M Leaked Google document: ‚ÄúWe Have No Moat, And Neither Does OpenAI‚Äù 132k 162k Large language models are having their Stable Diffusion moment 121k 150k Prompt injection: What‚Äôs the worst that can happen? 79.8k 95.9k Embeddings: What they are and why they matter 61.7k 79.3k Catching up on the weird world of LLMs 61.6k 85.9k llamafile is the new best way to run an LLM on your own computer 52k 66k Prompt injection explained, with video, slides, and a transcript 51k 61.9k AI-enhanced development makes me more ambitious with my projects 49.6k 60.1k Understanding GPT tokenizers 49.5k 61.1k Exploring GPTs: ChatGPT in a trench coat? 46.4k 58.5k Could you train a ChatGPT-beating model for $85,000 and run it in a browser? 40.5k 49.2k How to implement Q&A against your documentation with GPT3, embeddings and Datasette 37.3k 44.9k Lawyer cites fake cases invented by ChatGPT, judge is not amused 37.1k 47.4k Now add a walrus: Prompt engineering in DALL-E 3 32.8k 41.2k Web LLM runs the vicuna-7b Large Language Model entirely in your browser, and it‚Äôs very impressive 32.5k 38.2k ChatGPT can‚Äôt access the internet, even though it really looks like it can 30.5k 34.2k Stanford Alpaca, and the acceleration of on-device large language model development 29.7k 35.7k Run Llama 2 on your own Mac using LLM and Homebrew 27.9k 33.6k Midjourney 5.1 26.7k 33.4k Think of language models like ChatGPT as a ‚Äúcalculator for words‚Äù 25k 31.8k Multi-modal prompt injection image attacks against GPT-4V 23.7k 27.4k I also gave a bunch of talks and podcast appearances. I‚Äôve started habitually turning my talks into annotated presentations‚Äîhere are my best from 2023: Prompt injection explained, with video, slides, and a transcript Catching up on the weird world of LLMs Making Large Language Models work for you Open questions for AI engineering Embeddings: What they are and why they matter Financial sustainability for open source projects at GitHub Universe And in podcasts: What AI can do for you on the Theory of Change Working in public on Path to Citus Con LLMs break the internet on the Changelog Talking Large Language Models on Rooftop Ruby Thoughts on the OpenAI board situation on Newsroom Robots Industry‚Äôs Tardy Response to the AI Prompt Injection Vulnerability on RedMonk Conversations Posted 31st December 2023 at 11:59 pm ¬∑ Follow me on Mastodon, Bluesky, Twitter or subscribe to my newsletter More recent articles Feed a video to a vision LLM as a sequence of JPEG frames on the CLI (also LLM 0.25) - 5th May 2025 Two publishers and three authors fail to understand what \"vibe coding\" means - 1st May 2025 Understanding the recent criticism of the Chatbot Arena - 30th April 2025 This is Stuff we figured out about AI in 2023 by Simon Willison, posted on 31st December 2023. Part of series LLMs annual review Stuff we figured out about AI in 2023 - Dec. 31, 2023, 11:59 p.m. Things we learned about LLMs in 2024 - Dec. 31, 2024, 6:07 p.m. blogging 105 ai 1262 generative-ai 1089 llms 1076 Next: Tom Scott, and the formidable power of escalating streaks Previous: Last weeknotes of 2023 Colophon ¬© 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 2025']",
                  "According to the blog's 2023 tag cloud and traffic data, OpenAI holds significant importance in the context of LLMs and AI discussions. The prominence of \"openai\" in the tag cloud indicates that content related to OpenAI was highly relevant and frequently discussed during 2023. Additionally, the mention of \"chatgpt,\" \"gpt3,\" and \"gpt4\" further underscores OpenAI's central role in the development and conversation around large language models. The fact that OpenAI's GPT-4 \"barrier was comprehensively broken\" and that no other AI lab produced a comparable model for nearly a year highlights OpenAI's leading position and influence in the field of LLMs and AI discourse in 2023.",
                  "According to the blog's 2023 tag cloud, 'openai' was one of the top five most used tags, with 86 mentions, indicating its prominence in discussions about LLMs and AI. Additionally, one of the top traffic articles was titled 'Leaked Google document: ‚ÄúWe Have No Moat, And Neither Does OpenAI‚Äù', which received 132k visitors and 162k pageviews, further highlighting OpenAI's significant role in the AI and LLM conversation on the blog.",
                  "single_hop_specifc_query_synthesizer"
                ],
                [
                  "4",
                  "Considering the applications of LLMs such as code generation and productivity enhancement, how has the rise of LLMs impacted software engineering and programming roles, particularly in terms of both opportunities and perceived threats, as discussed in the context?",
                  "['It‚Äôs still astonishing to me how effective they are though.\\n\\nOne of the great weaknesses of LLMs is their tendency to hallucinate‚Äîto imagine things that don‚Äôt correspond to reality. You would expect this to be a particularly bad problem for code‚Äîif an LLM hallucinates a method that doesn‚Äôt exist, the code should be useless.\\n\\nExcept... you can run generated code to see if it‚Äôs correct. And with patterns like ChatGPT Code Interpreter the LLM can execute the code itself, process the error message, then rewrite it and keep trying until it works!\\n\\nSo hallucination is a much lesser problem for code generation than for anything else. If only we had the equivalent of Code Interpreter for fact-checking natural language!\\n\\nHow should we feel about this as software engineers?\\n\\nOn the one hand, this feels like a threat: who needs a programmer if ChatGPT can write code for you?', 'How should we feel about this as software engineers?\\n\\nOn the one hand, this feels like a threat: who needs a programmer if ChatGPT can write code for you?\\n\\nOn the other hand, as software engineers we are better placed to take advantage of this than anyone else. We‚Äôve all been given weird coding interns‚Äîwe can use our deep knowledge to prompt them to solve coding problems more effectively than anyone else can.\\n\\nThe ethics of this space remain diabolically complex\\n\\nIn September last year Andy Baio and I produced the first major story on the unlicensed training data behind Stable Diffusion.\\n\\nSince then, almost every major LLM (and most of the image generation models) have also been trained on unlicensed data.', 'Still, I‚Äôm surprised that no-one has beaten the now almost year old GPT-4 by now. OpenAI clearly have some substantial tricks that they haven‚Äôt shared yet.\\n\\nVibes Based Development\\n\\nAs a computer scientist and software engineer, LLMs are infuriating.\\n\\nEven the openly licensed ones are still the world‚Äôs most convoluted black boxes. We continue to have very little idea what they can do, how exactly they work and how best to control them.\\n\\nI‚Äôm used to programming where the computer does exactly what I tell it to do. Prompting an LLM is decidedly not that!\\n\\nThe worst part is the challenge of evaluating them.\\n\\nThere are plenty of benchmarks, but no benchmark is going to tell you if an LLM actually ‚Äúfeels‚Äù right when you try it for a given task.\\n\\nI find I have to work with an LLM for a few weeks in order to get a good intuition for it‚Äôs strengths and weaknesses. This greatly limits how many I can evaluate myself!\\n\\nThe most frustrating thing for me is at the level of individual prompting.']",
                  "['<1-hop>\\n\\nWe don‚Äôt yet know how to build GPT-4 Vibes Based Development LLMs are really smart, and also really, really dumb Gullibility is the biggest unsolved problem Code may be the best application The ethics of this space remain diabolically complex My blog in 2023 Here‚Äôs the sequel to this post: Things we learned about LLMs in 2024. Large Language Models In the past 24-36 months, our species has discovered that you can take a GIANT corpus of text, run it through a pile of GPUs, and use it to create a fascinating new kind of software. LLMs can do a lot of things. They can answer questions, summarize documents, translate from one language to another, extract information and even write surprisingly competent code. They can also help you cheat at your homework, generate unlimited streams of fake content and be used for all manner of nefarious purposes. So far, I think they‚Äôre a net positive. I‚Äôve used them on a personal level to improve my productivity (and entertain myself) in all sorts of different ways. I think people who learn how to use them effectively can gain a significant boost to their quality of life. A lot of people are yet to be sold on their value! Some think their negatives outweigh their positives, some think they are all hot air, and some even think they represent an existential threat to humanity. They‚Äôre actually quite easy to build The most surprising thing we‚Äôve learned about LLMs this year is that they‚Äôre actually quite easy to build. Intuitively, one would expect that systems this powerful would take millions of lines of complex code. Instead, it turns out a few hundred lines of Python is genuinely enough to train a basic version! What matters most is the training data. You need a lot of data to make these things work, and the quantity and quality of the training data appears to be the most important factor in how good the resulting model is. If you can gather the right data, and afford to pay for the GPUs to train it, you can build an LLM. A year ago, the only organization that had released a generally useful LLM was OpenAI. We‚Äôve now seen better-than-GPT-3 class models produced by Anthropic, Mistral, Google, Meta, EleutherAI, Stability AI, TII in Abu Dhabi (Falcon), Microsoft Research, xAI, Replit, Baidu and a bunch of other organizations. The training cost (hardware and electricity) is still significant‚Äîinitially millions of dollars, but that seems to have dropped to the tens of thousands already. Microsoft‚Äôs Phi-2 claims to have used ‚Äú14 days on 96 A100 GPUs‚Äù, which works out at around $35,000 using current Lambda pricing. So training an LLM still isn‚Äôt something a hobbyist can afford, but it‚Äôs no longer the sole domain of the super-rich. I like to compare the difficulty of training an LLM to that of building a suspension bridge‚Äînot trivial, but hundreds of countries around the world have figured out how to do it. (Correction: Wikipedia‚Äôs Suspension bridges by country category lists 44 countries). You can run LLMs on your own devices In January of this year, I thought it would be years before I could run a useful LLM on my own computer. GPT-3 and 3.5 were pretty much the only games in town, and I thought that even if the model weights were available it would take a $10,000+ server to run them. Then in February, Meta released Llama. And a few weeks later in March, Georgi Gerganov released code that got it working on a MacBook. I wrote about how Large language models are having their Stable Diffusion moment, and with hindsight that was a very good call! This unleashed a whirlwind of innovation, which was accelerated further in July when Meta released Llama 2‚Äîan improved version which, crucially, included permission for commercial use. Today there are literally thousands of LLMs that can be run locally, on all manner of different devices. I run a bunch of them on my laptop. I run Mistral 7B (a surprisingly great model) on my iPhone. You can install several different apps to get your own, local, completely private LLM. My own LLM project provides a CLI tool for running an array of different models via plugins. You can even run them entirely in your browser using WebAssembly and the latest Chrome! Hobbyists can build their own fine-tuned models I said earlier that building an LLM was still out of reach of hobbyists. That may be true for training from scratch, but fine-tuning one of those models is another matter entirely. There‚Äôs now a fascinating ecosystem of people training their own models on top of these foundations, publishing those models, building fine-tuning datasets and sharing those too. The Hugging Face Open LLM Leaderboard is one place that tracks these. I can‚Äôt even attempt to count them, and any count would be out-of-date within a few hours. The best overall openly licensed LLM at any time is rarely a foundation model: instead, it‚Äôs whichever fine-tuned community model has most recently discovered the best combination of fine-tuning data. This is a huge advantage for open over closed models: the closed, hosted models don‚Äôt have thousands of researchers and hobbyists around the world collaborating and competing to improve them. We don‚Äôt yet know how to build GPT-4 Frustratingly, despite the enormous leaps ahead we‚Äôve had this year, we are yet to see an alternative model that‚Äôs better than GPT-4. OpenAI released GPT-4 in March, though it later turned out we had a sneak peak of it in February when Microsoft used it as part of the new Bing. This may well change in the next few weeks: Google‚Äôs Gemini Ultra has big claims, but isn‚Äôt yet available for us to try out. The team behind Mistral are working to beat GPT-4 as well, and their track record is already extremely strong considering their first public model only came out in September, and they‚Äôve released two significant improvements since then. Still,', '<2-hop>\\n\\nI‚Äôm surprised that no-one has beaten the now almost year old GPT-4 by now. OpenAI clearly have some substantial tricks that they haven‚Äôt shared yet. Vibes Based Development As a computer scientist and software engineer, LLMs are infuriating. Even the openly licensed ones are still the world‚Äôs most convoluted black boxes. We continue to have very little idea what they can do, how exactly they work and how best to control them. I‚Äôm used to programming where the computer does exactly what I tell it to do. Prompting an LLM is decidedly not that! The worst part is the challenge of evaluating them. There are plenty of benchmarks, but no benchmark is going to tell you if an LLM actually ‚Äúfeels‚Äù right when you try it for a given task. I find I have to work with an LLM for a few weeks in order to get a good intuition for it‚Äôs strengths and weaknesses. This greatly limits how many I can evaluate myself! The most frustrating thing for me is at the level of individual prompting. Sometimes I‚Äôll tweak a prompt and capitalize some of the words in it, to emphasize that I really want it to OUTPUT VALID MARKDOWN or similar. Did capitalizing those words make a difference? I still don‚Äôt have a good methodology for figuring that out. We‚Äôre left with what‚Äôs effectively Vibes Based Development. It‚Äôs vibes all the way down. I‚Äôd love to see us move beyond vibes in 2024! LLMs are really smart, and also really, really dumb On the one hand, we keep on finding new things that LLMs can do that we didn‚Äôt expect‚Äîand that the people who trained the models didn‚Äôt expect either. That‚Äôs usually really fun! But on the other hand, the things you sometimes have to do to get the models to behave are often incredibly dumb. Does ChatGPT get lazy in December, because its hidden system prompt includes the current date and its training data shows that people provide less useful answers coming up to the holidays? The honest answer is ‚Äúmaybe‚Äù! No-one is entirely sure, but if you give it a different date its answers may skew slightly longer. Sometimes it omits sections of code and leaves you to fill them in, but if you tell it you can‚Äôt type because you don‚Äôt have any fingers it produces the full code for you instead. There are so many more examples like this. Offer it cash tips for better answers. Tell it your career depends on it. Give it positive reinforcement. It‚Äôs all so dumb, but it works! Gullibility is the biggest unsolved problem I coined the term prompt injection in September last year. 15 months later, I regret to say that we‚Äôre still no closer to a robust, dependable solution to this problem. I‚Äôve written a ton about this already. Beyond that specific class of security vulnerabilities, I‚Äôve started seeing this as a wider problem of gullibility. Language Models are gullible. They ‚Äúbelieve‚Äù what we tell them‚Äîwhat‚Äôs in their training data, then what‚Äôs in the fine-tuning data, then what‚Äôs in the prompt. In order to be useful tools for us, we need them to believe what we feed them! But it turns out a lot of the things we want to build need them not to be gullible. Everyone wants an AI personal assistant. If you hired a real-world personal assistant who believed everything that anyone told them, you would quickly find that their ability to positively impact your life was severely limited. A lot of people are excited about AI agents‚Äîan infuriatingly vague term that seems to be converging on ‚ÄúAI systems that can go away and act on your behalf‚Äù. We‚Äôve been talking about them all year, but I‚Äôve seen few if any examples of them running in production, despite lots of exciting prototypes. I think this is because of gullibility. Can we solve this? Honestly, I‚Äôm beginning to suspect that you can‚Äôt fully solve gullibility without achieving AGI. So it may be quite a while before those agent dreams can really start to come true! Code may be the best application Over the course of the year, it‚Äôs become increasingly clear that writing code is one of the things LLMs are most capable of. If you think about what they do, this isn‚Äôt such a big surprise. The grammar rules of programming languages like Python and JavaScript are massively less complicated than the grammar of Chinese, Spanish or English. It‚Äôs still astonishing to me how effective they are though. One of the great weaknesses of LLMs is their tendency to hallucinate‚Äîto imagine things that don‚Äôt correspond to reality. You would expect this to be a particularly bad problem for code‚Äîif an LLM hallucinates a method that doesn‚Äôt exist, the code should be useless. Except... you can run generated code to see if it‚Äôs correct. And with patterns like ChatGPT Code Interpreter the LLM can execute the code itself, process the error message, then rewrite it and keep trying until it works! So hallucination is a much lesser problem for code generation than for anything else. If only we had the equivalent of Code Interpreter for fact-checking natural language! How should we feel about this as software engineers? On the one hand, this feels like a threat: who needs a programmer if ChatGPT can write code for you? On the other hand, as software engineers we are better placed to take advantage of this than anyone else. We‚Äôve all been given weird coding interns‚Äîwe can use our deep knowledge to prompt them to solve coding problems more effectively than anyone else can. The ethics of this space remain diabolically complex In September last year Andy Baio and I produced the first major story on the unlicensed training data behind Stable Diffusion. Since then, almost every major LLM (and most of the image generation models) have also been trained on unlicensed data. Just this week, the New York Times launched a landmark lawsuit against OpenAI and']",
                  "The rise of LLMs in software engineering and programming roles has introduced both opportunities and perceived threats, as discussed in the context. On the opportunity side, software engineers are uniquely positioned to leverage LLMs due to their deep knowledge of coding. They can craft effective prompts and utilize their expertise to solve coding problems more efficiently than others, effectively acting as skilled \"prompt engineers\" who can harness the capabilities of LLMs like ChatGPT to generate code, improve productivity, and potentially streamline development processes.\n\nHowever, there is also a perceived threat to traditional programming roles. The ability of LLMs to write code autonomously raises concerns about the necessity of human programmers, as these models can produce functional code with minimal human intervention. This has led to feelings of uncertainty and fear among software engineers about job security.\n\nAdditionally, the context highlights challenges related to understanding and controlling LLMs, such as their black-box nature and the difficulty in evaluating their outputs. This complexity can make the integration of LLMs into software development a nuanced process, requiring specialized skills to manage their strengths and limitations effectively.\n\nIn summary, while LLMs open new opportunities for enhancing productivity and problem-solving in software engineering, they also pose perceived threats to traditional roles and underscore the importance of expertise in prompting and managing these advanced models.",
                  "The rise of LLMs has significantly impacted software engineering and programming roles, especially through their applications in code generation and productivity enhancement. According to the context, writing code has emerged as one of the most effective applications of LLMs, largely because programming languages have simpler grammar rules compared to natural languages. LLMs can generate surprisingly competent code, and tools like ChatGPT Code Interpreter allow the model to execute and iteratively improve its own code, reducing the impact of hallucinations that might otherwise render generated code useless. This capability presents both opportunities and threats for software engineers. On one hand, there is a perceived threat that LLMs could replace programmers, as they can automate many coding tasks. On the other hand, software engineers are uniquely positioned to leverage LLMs as powerful tools or 'weird coding interns,' using their expertise to prompt LLMs more effectively than non-experts. This duality means that while LLMs may automate certain aspects of programming, they also offer significant productivity boosts and new ways for engineers to enhance their work, provided they adapt to and integrate these tools into their workflows.",
                  "multi_hop_abstract_query_synthesizer"
                ],
                [
                  "5",
                  "How have large language models impacted software engineering roles, particularly through applications like code generation, and what challenges do software engineers face when working with these models?",
                  "['It‚Äôs still astonishing to me how effective they are though.\\n\\nOne of the great weaknesses of LLMs is their tendency to hallucinate‚Äîto imagine things that don‚Äôt correspond to reality. You would expect this to be a particularly bad problem for code‚Äîif an LLM hallucinates a method that doesn‚Äôt exist, the code should be useless.\\n\\nExcept... you can run generated code to see if it‚Äôs correct. And with patterns like ChatGPT Code Interpreter the LLM can execute the code itself, process the error message, then rewrite it and keep trying until it works!\\n\\nSo hallucination is a much lesser problem for code generation than for anything else. If only we had the equivalent of Code Interpreter for fact-checking natural language!\\n\\nHow should we feel about this as software engineers?\\n\\nOn the one hand, this feels like a threat: who needs a programmer if ChatGPT can write code for you?', 'Simon Willison‚Äôs Weblog\\n\\nSubscribe\\n\\nThings we learned about LLMs in 2024\\n\\n31st December 2024\\n\\nA lot has happened in the world of Large Language Models over the course of 2024. Here‚Äôs a review of things we figured out about the field in the past twelve months, plus my attempt at identifying key themes and pivotal moments.\\n\\nThis is a sequel to my review of 2023.\\n\\nIn this article:\\n\\nThe GPT-4 barrier was comprehensively broken\\n\\nSome of those GPT-4 models run on my laptop\\n\\nLLM prices crashed, thanks to competition and increased efficiency\\n\\nMultimodal vision is common, audio and video are starting to emerge\\n\\nVoice and live camera mode are science fiction come to life\\n\\nPrompt driven app generation is a commodity already\\n\\nUniversal access to the best models lasted for just a few short months\\n\\n‚ÄúAgents‚Äù still haven‚Äôt really happened yet\\n\\nEvals really matter\\n\\nApple Intelligence is bad, Apple‚Äôs MLX library is excellent\\n\\nThe rise of inference-scaling ‚Äúreasoning‚Äù models', 'Code may be the best application\\n\\nThe ethics of this space remain diabolically complex\\n\\nMy blog in 2023\\n\\nHere‚Äôs the sequel to this post: Things we learned about LLMs in 2024.\\n\\nLarge Language Models\\n\\nIn the past 24-36 months, our species has discovered that you can take a GIANT corpus of text, run it through a pile of GPUs, and use it to create a fascinating new kind of software.\\n\\nLLMs can do a lot of things. They can answer questions, summarize documents, translate from one language to another, extract information and even write surprisingly competent code.\\n\\nThey can also help you cheat at your homework, generate unlimited streams of fake content and be used for all manner of nefarious purposes.\\n\\nSo far, I think they‚Äôre a net positive. I‚Äôve used them on a personal level to improve my productivity (and entertain myself) in all sorts of different ways. I think people who learn how to use them effectively can gain a significant boost to their quality of life.']",
                  "['<1-hop>\\n\\nWe don‚Äôt yet know how to build GPT-4 Vibes Based Development LLMs are really smart, and also really, really dumb Gullibility is the biggest unsolved problem Code may be the best application The ethics of this space remain diabolically complex My blog in 2023 Here‚Äôs the sequel to this post: Things we learned about LLMs in 2024. Large Language Models In the past 24-36 months, our species has discovered that you can take a GIANT corpus of text, run it through a pile of GPUs, and use it to create a fascinating new kind of software. LLMs can do a lot of things. They can answer questions, summarize documents, translate from one language to another, extract information and even write surprisingly competent code. They can also help you cheat at your homework, generate unlimited streams of fake content and be used for all manner of nefarious purposes. So far, I think they‚Äôre a net positive. I‚Äôve used them on a personal level to improve my productivity (and entertain myself) in all sorts of different ways. I think people who learn how to use them effectively can gain a significant boost to their quality of life. A lot of people are yet to be sold on their value! Some think their negatives outweigh their positives, some think they are all hot air, and some even think they represent an existential threat to humanity. They‚Äôre actually quite easy to build The most surprising thing we‚Äôve learned about LLMs this year is that they‚Äôre actually quite easy to build. Intuitively, one would expect that systems this powerful would take millions of lines of complex code. Instead, it turns out a few hundred lines of Python is genuinely enough to train a basic version! What matters most is the training data. You need a lot of data to make these things work, and the quantity and quality of the training data appears to be the most important factor in how good the resulting model is. If you can gather the right data, and afford to pay for the GPUs to train it, you can build an LLM. A year ago, the only organization that had released a generally useful LLM was OpenAI. We‚Äôve now seen better-than-GPT-3 class models produced by Anthropic, Mistral, Google, Meta, EleutherAI, Stability AI, TII in Abu Dhabi (Falcon), Microsoft Research, xAI, Replit, Baidu and a bunch of other organizations. The training cost (hardware and electricity) is still significant‚Äîinitially millions of dollars, but that seems to have dropped to the tens of thousands already. Microsoft‚Äôs Phi-2 claims to have used ‚Äú14 days on 96 A100 GPUs‚Äù, which works out at around $35,000 using current Lambda pricing. So training an LLM still isn‚Äôt something a hobbyist can afford, but it‚Äôs no longer the sole domain of the super-rich. I like to compare the difficulty of training an LLM to that of building a suspension bridge‚Äînot trivial, but hundreds of countries around the world have figured out how to do it. (Correction: Wikipedia‚Äôs Suspension bridges by country category lists 44 countries). You can run LLMs on your own devices In January of this year, I thought it would be years before I could run a useful LLM on my own computer. GPT-3 and 3.5 were pretty much the only games in town, and I thought that even if the model weights were available it would take a $10,000+ server to run them. Then in February, Meta released Llama. And a few weeks later in March, Georgi Gerganov released code that got it working on a MacBook. I wrote about how Large language models are having their Stable Diffusion moment, and with hindsight that was a very good call! This unleashed a whirlwind of innovation, which was accelerated further in July when Meta released Llama 2‚Äîan improved version which, crucially, included permission for commercial use. Today there are literally thousands of LLMs that can be run locally, on all manner of different devices. I run a bunch of them on my laptop. I run Mistral 7B (a surprisingly great model) on my iPhone. You can install several different apps to get your own, local, completely private LLM. My own LLM project provides a CLI tool for running an array of different models via plugins. You can even run them entirely in your browser using WebAssembly and the latest Chrome! Hobbyists can build their own fine-tuned models I said earlier that building an LLM was still out of reach of hobbyists. That may be true for training from scratch, but fine-tuning one of those models is another matter entirely. There‚Äôs now a fascinating ecosystem of people training their own models on top of these foundations, publishing those models, building fine-tuning datasets and sharing those too. The Hugging Face Open LLM Leaderboard is one place that tracks these. I can‚Äôt even attempt to count them, and any count would be out-of-date within a few hours. The best overall openly licensed LLM at any time is rarely a foundation model: instead, it‚Äôs whichever fine-tuned community model has most recently discovered the best combination of fine-tuning data. This is a huge advantage for open over closed models: the closed, hosted models don‚Äôt have thousands of researchers and hobbyists around the world collaborating and competing to improve them. We don‚Äôt yet know how to build GPT-4 Frustratingly, despite the enormous leaps ahead we‚Äôve had this year, we are yet to see an alternative model that‚Äôs better than GPT-4. OpenAI released GPT-4 in March, though it later turned out we had a sneak peak of it in February when Microsoft used it as part of the new Bing. This may well change in the next few weeks: Google‚Äôs Gemini Ultra has big claims, but isn‚Äôt yet available for us to try out. The team behind Mistral are working to beat GPT-4 as well, and their track record is already extremely strong considering their first public model only came out in September, and they‚Äôve released two significant improvements since then. Still,', '<2-hop>\\n\\nI‚Äôm surprised that no-one has beaten the now almost year old GPT-4 by now. OpenAI clearly have some substantial tricks that they haven‚Äôt shared yet. Vibes Based Development As a computer scientist and software engineer, LLMs are infuriating. Even the openly licensed ones are still the world‚Äôs most convoluted black boxes. We continue to have very little idea what they can do, how exactly they work and how best to control them. I‚Äôm used to programming where the computer does exactly what I tell it to do. Prompting an LLM is decidedly not that! The worst part is the challenge of evaluating them. There are plenty of benchmarks, but no benchmark is going to tell you if an LLM actually ‚Äúfeels‚Äù right when you try it for a given task. I find I have to work with an LLM for a few weeks in order to get a good intuition for it‚Äôs strengths and weaknesses. This greatly limits how many I can evaluate myself! The most frustrating thing for me is at the level of individual prompting. Sometimes I‚Äôll tweak a prompt and capitalize some of the words in it, to emphasize that I really want it to OUTPUT VALID MARKDOWN or similar. Did capitalizing those words make a difference? I still don‚Äôt have a good methodology for figuring that out. We‚Äôre left with what‚Äôs effectively Vibes Based Development. It‚Äôs vibes all the way down. I‚Äôd love to see us move beyond vibes in 2024! LLMs are really smart, and also really, really dumb On the one hand, we keep on finding new things that LLMs can do that we didn‚Äôt expect‚Äîand that the people who trained the models didn‚Äôt expect either. That‚Äôs usually really fun! But on the other hand, the things you sometimes have to do to get the models to behave are often incredibly dumb. Does ChatGPT get lazy in December, because its hidden system prompt includes the current date and its training data shows that people provide less useful answers coming up to the holidays? The honest answer is ‚Äúmaybe‚Äù! No-one is entirely sure, but if you give it a different date its answers may skew slightly longer. Sometimes it omits sections of code and leaves you to fill them in, but if you tell it you can‚Äôt type because you don‚Äôt have any fingers it produces the full code for you instead. There are so many more examples like this. Offer it cash tips for better answers. Tell it your career depends on it. Give it positive reinforcement. It‚Äôs all so dumb, but it works! Gullibility is the biggest unsolved problem I coined the term prompt injection in September last year. 15 months later, I regret to say that we‚Äôre still no closer to a robust, dependable solution to this problem. I‚Äôve written a ton about this already. Beyond that specific class of security vulnerabilities, I‚Äôve started seeing this as a wider problem of gullibility. Language Models are gullible. They ‚Äúbelieve‚Äù what we tell them‚Äîwhat‚Äôs in their training data, then what‚Äôs in the fine-tuning data, then what‚Äôs in the prompt. In order to be useful tools for us, we need them to believe what we feed them! But it turns out a lot of the things we want to build need them not to be gullible. Everyone wants an AI personal assistant. If you hired a real-world personal assistant who believed everything that anyone told them, you would quickly find that their ability to positively impact your life was severely limited. A lot of people are excited about AI agents‚Äîan infuriatingly vague term that seems to be converging on ‚ÄúAI systems that can go away and act on your behalf‚Äù. We‚Äôve been talking about them all year, but I‚Äôve seen few if any examples of them running in production, despite lots of exciting prototypes. I think this is because of gullibility. Can we solve this? Honestly, I‚Äôm beginning to suspect that you can‚Äôt fully solve gullibility without achieving AGI. So it may be quite a while before those agent dreams can really start to come true! Code may be the best application Over the course of the year, it‚Äôs become increasingly clear that writing code is one of the things LLMs are most capable of. If you think about what they do, this isn‚Äôt such a big surprise. The grammar rules of programming languages like Python and JavaScript are massively less complicated than the grammar of Chinese, Spanish or English. It‚Äôs still astonishing to me how effective they are though. One of the great weaknesses of LLMs is their tendency to hallucinate‚Äîto imagine things that don‚Äôt correspond to reality. You would expect this to be a particularly bad problem for code‚Äîif an LLM hallucinates a method that doesn‚Äôt exist, the code should be useless. Except... you can run generated code to see if it‚Äôs correct. And with patterns like ChatGPT Code Interpreter the LLM can execute the code itself, process the error message, then rewrite it and keep trying until it works! So hallucination is a much lesser problem for code generation than for anything else. If only we had the equivalent of Code Interpreter for fact-checking natural language! How should we feel about this as software engineers? On the one hand, this feels like a threat: who needs a programmer if ChatGPT can write code for you? On the other hand, as software engineers we are better placed to take advantage of this than anyone else. We‚Äôve all been given weird coding interns‚Äîwe can use our deep knowledge to prompt them to solve coding problems more effectively than anyone else can. The ethics of this space remain diabolically complex In September last year Andy Baio and I produced the first major story on the unlicensed training data behind Stable Diffusion. Since then, almost every major LLM (and most of the image generation models) have also been trained on unlicensed data. Just this week, the New York Times launched a landmark lawsuit against OpenAI and']",
                  "Large language models have significantly impacted software engineering roles, particularly through applications like code generation. They are capable of writing surprisingly competent code, assisting developers in creating software more efficiently. The use of patterns like ChatGPT Code Interpreter enables these models to execute generated code, process error messages, and iteratively improve the output until it works correctly. This process reduces the problem of hallucination‚Äîwhere models imagine non-existent methods or code‚Äîmaking code generation more reliable.\n\nHowever, working with these models presents challenges for software engineers. One primary concern is the potential threat to traditional programming roles, as models can generate substantial amounts of code autonomously. Additionally, developers need to be aware of the limitations, such as hallucinations, and incorporate strategies to verify and test generated code. The necessity for critical evaluation and testing remains crucial, since the models, despite their capabilities, can produce incorrect or misleading outputs.",
                  "Large language models (LLMs) have significantly impacted software engineering roles, especially through their strong capabilities in code generation. As noted, writing code is one of the tasks LLMs are most capable of, due to the relatively simple grammar of programming languages compared to natural languages. This has led to LLMs being used to write surprisingly competent code, and tools like ChatGPT Code Interpreter can even execute and iteratively improve generated code, reducing issues like hallucination. However, this advancement presents both opportunities and challenges for software engineers. On one hand, LLMs can be seen as a threat to traditional programming roles, since they can automate parts of the coding process. On the other hand, software engineers are uniquely positioned to leverage LLMs effectively, using their expertise to prompt and guide these models to solve complex coding problems. Despite these benefits, engineers face challenges such as the 'black box' nature of LLMs, difficulties in evaluating their outputs, and the need for 'Vibes Based Development'‚Äîrelying on intuition and trial-and-error when prompting models. Additionally, issues like model gullibility and the lack of robust methodologies for prompt engineering remain unresolved, complicating the integration of LLMs into software engineering workflows.",
                  "multi_hop_abstract_query_synthesizer"
                ],
                [
                  "6",
                  "How does the use of synthetic training data provide advantages over organic data in the development of large language models, and what are some examples of these advantages as described in recent model training practices?",
                  "['One of the best descriptions I‚Äôve seen of this comes from the Phi-4 technical report, which included this:\\n\\nSynthetic data as a substantial component of pretraining is becoming increasingly common, and the Phi series of models has consistently emphasized the importance of synthetic data. Rather than serving as a cheap substitute for organic data, synthetic data has several direct advantages over organic data.\\n\\nStructured and Gradual Learning. In organic datasets, the relationship between tokens is often complex and indirect. Many reasoning steps may be required to connect the current token to the next, making it challenging for the model to learn effectively from next-token prediction. By contrast, each token generated by a language model is by definition predicted by the preceding tokens, making it easier for a model to follow the resulting reasoning patterns.', 'Another common technique is to use larger models to help create training data for their smaller, cheaper alternatives‚Äîa trick used by an increasing number of labs. DeepSeek v3 used ‚Äúreasoning‚Äù data created by DeepSeek-R1. Meta‚Äôs Llama 3.3 70B fine-tuning used over 25M synthetically generated examples.\\n\\nCareful design of the training data that goes into an LLM appears to be the entire game for creating these models. The days of just grabbing a full scrape of the web and indiscriminately dumping it into a training run are long gone.\\n\\nLLMs somehow got even harder to use\\n\\nA drum I‚Äôve been banging for a while is that LLMs are power-user tools‚Äîthey‚Äôre chainsaws disguised as kitchen knives. They look deceptively simple to use‚Äîhow hard can it be to type messages to a chatbot?‚Äîbut in reality you need a huge depth of both understanding and experience to make the most of them and avoid their many pitfalls.\\n\\nIf anything, this problem got worse in 2024.', '‚ÄúAgents‚Äù still haven‚Äôt really happened yet\\n\\nEvals really matter\\n\\nApple Intelligence is bad, Apple‚Äôs MLX library is excellent\\n\\nThe rise of inference-scaling ‚Äúreasoning‚Äù models\\n\\nWas the best currently available LLM trained in China for less than $6m?\\n\\nThe environmental impact got better\\n\\nThe environmental impact got much, much worse\\n\\nThe year of slop\\n\\nSynthetic training data works great\\n\\nLLMs somehow got even harder to use\\n\\nKnowledge is incredibly unevenly distributed\\n\\nLLMs need better criticism\\n\\nEverything tagged ‚Äúllms‚Äù on my blog in 2024\\n\\nThe GPT-4 barrier was comprehensively broken\\n\\nIn my December 2023 review I wrote about how We don‚Äôt yet know how to build GPT-4‚ÄîOpenAI‚Äôs best model was almost a year old at that point, yet no other AI lab had produced anything better. What did OpenAI know that the rest of us didn‚Äôt?']",
                  "['<1-hop>\\n\\nThe rise of inference-scaling ‚Äúreasoning‚Äù models Was the best currently available LLM trained in China for less than $6m? The environmental impact got better The environmental impact got much, much worse The year of slop Synthetic training data works great LLMs somehow got even harder to use Knowledge is incredibly unevenly distributed LLMs need better criticism Everything tagged ‚Äúllms‚Äù on my blog in 2024 The GPT-4 barrier was comprehensively broken In my December 2023 review I wrote about how We don‚Äôt yet know how to build GPT-4‚ÄîOpenAI‚Äôs best model was almost a year old at that point, yet no other AI lab had produced anything better. What did OpenAI know that the rest of us didn‚Äôt? I‚Äôm relieved that this has changed completely in the past twelve months. 18 organizations now have models on the Chatbot Arena Leaderboard that rank higher than the original GPT-4 from March 2023 (GPT-4-0314 on the board)‚Äî70 models in total. Screenshot of a comparison table showing AI model rankings. Table headers: Rank (UB), Rank (StyleCtrl), Model, Arena Score, 95% CI, Votes, Organization, License. Shows 12 models including GLM-4-0520, Llama-3-70B-Instruct, Gemini-1.5-Flash-8B-Exp-0827, with rankings, scores, and licensing details. Models range from rank 52-69 with Arena scores between 1186-1207. The earliest of those was Google‚Äôs Gemini 1.5 Pro, released in February. In addition to producing GPT-4 level outputs, it introduced several brand new capabilities to the field‚Äîmost notably its 1 million (and then later 2 million) token input context length, and the ability to input video. I wrote about this at the time in The killer app of Gemini Pro 1.5 is video, which earned me a short appearance as a talking head in the Google I/O opening keynote in May. Gemini 1.5 Pro also illustrated one of the key themes of 2024: increased context lengths. Last year most models accepted 4,096 or 8,192 tokens, with the notable exception of Claude 2.1 which accepted 200,000. Today every serious provider has a 100,000+ token model, and Google‚Äôs Gemini series accepts up to 2 million. Longer inputs dramatically increase the scope of problems that can be solved with an LLM: you can now throw in an entire book and ask questions about its contents, but more importantly you can feed in a lot of example code to help the model correctly solve a coding problem. LLM use-cases that involve long inputs are far more interesting to me than short prompts that rely purely on the information already baked into the model weights. Many of my tools were built using this pattern. Getting back to models that beat GPT-4: Anthropic‚Äôs Claude 3 series launched in March, and Claude 3 Opus quickly became my new favourite daily-driver. They upped the ante even more in June with the launch of Claude 3.5 Sonnet‚Äîa model that is still my favourite six months later (though it got a significant upgrade on October 22, confusingly keeping the same 3.5 version number. Anthropic fans have since taken to calling it Claude 3.6). Then there‚Äôs the rest. If you browse the Chatbot Arena leaderboard today‚Äîstill the most useful single place to get a vibes-based evaluation of models‚Äîyou‚Äôll see that GPT-4-0314 has fallen to around 70th place. The 18 organizations with higher scoring models are Google, OpenAI, Alibaba, Anthropic, Meta, Reka AI, 01 AI, Amazon, Cohere, DeepSeek, Nvidia, Mistral, NexusFlow, Zhipu AI, xAI, AI21 Labs, Princeton and Tencent. Training a GPT-4 beating model was a huge deal in 2023. In 2024 it‚Äôs an achievement that isn‚Äôt even particularly notable, though I personally still celebrate any time a new organization joins that list. Some of those GPT-4 models run on my laptop My personal laptop is a 64GB M2 MacBook Pro from 2023. It‚Äôs a powerful machine, but it‚Äôs also nearly two years old now‚Äîand crucially it‚Äôs the same laptop I‚Äôve been using ever since I first ran an LLM on my computer back in March 2023 (see Large language models are having their Stable Diffusion moment). That same laptop that could just about run a GPT-3-class model in March last year has now run multiple GPT-4 class models! Some of my notes on that: Qwen2.5-Coder-32B is an LLM that can code well that runs on my Mac talks about Qwen2.5-Coder-32B in November‚Äîan Apache 2.0 licensed model! I can now run a GPT-4 class model on my laptop talks about running Meta‚Äôs Llama 3.3 70B (released in December) This remains astonishing to me. I thought a model with the capabilities and output quality of GPT-4 needed a datacenter class server with one or more $40,000+ GPUs. These models take up enough of my 64GB of RAM that I don‚Äôt run them often‚Äîthey don‚Äôt leave much room for anything else. The fact that they run at all is a testament to the incredible training and inference performance gains that we‚Äôve figured out over the past year. It turns out there was a lot of low-hanging fruit to be harvested in terms of model efficiency. I expect there‚Äôs still more to come. Meta‚Äôs Llama 3.2 models deserve a special mention. They may not be GPT-4 class, but at 1B and 3B sizes they punch massively above their weight. I run Llama 3.2 3B on my iPhone using the free MLC Chat iOS app and it‚Äôs a shockingly capable model for its tiny (<2GB) size. Try firing it up and asking it for ‚Äúa plot outline of a Netflix Christmas movie where a data journalist falls in love with a local ceramacist‚Äù. Here‚Äôs what I got, at a respectable 20 tokens per second: MLC Chat: Llama - [System] Ready to chat. a plot outline of a Netflix Christmas movie where a data journalist falls in love with a local ceramacist. Show as Markdown is turned on. Here\\'s a plot outline for a Netflix Christmas movie: Title: \"Love in the Clay\" Plot Outline: We meet our protagonist, JESSICA, a data journalist who has just returned to her hometown of Willow Creek, a small, charming town nestled in the snow-covered mountains. She\\'s back to work', '<2-hop>\\n\\nmodel available to try out through their chat interface on November 20th. To understand more about inference scaling I recommend Is AI progress slowing down? by Arvind Narayanan and Sayash Kapoor. Nothing yet from Anthropic or Meta but I would be very surprised if they don‚Äôt have their own inference-scaling models in the works. Meta published a relevant paper Training Large Language Models to Reason in a Continuous Latent Space in December. Was the best currently available LLM trained in China for less than $6m? Not quite, but almost! It does make for a great attention-grabbing headline. The big news to end the year was the release of DeepSeek v3‚Äîdropped on Hugging Face on Christmas Day without so much as a README file, then followed by documentation and a paper the day after that. DeepSeek v3 is a huge 685B parameter model‚Äîone of the largest openly licensed models currently available, significantly bigger than the largest of Meta‚Äôs Llama series, Llama 3.1 405B. Benchmarks put it up there with Claude 3.5 Sonnet. Vibe benchmarks (aka the Chatbot Arena) currently rank it 7th, just behind the Gemini 2.0 and OpenAI 4o/o1 models. This is by far the highest ranking openly licensed model. The really impressive thing about DeepSeek v3 is the training cost. The model was trained on 2,788,000 H800 GPU hours at an estimated cost of $5,576,000. Llama 3.1 405B trained 30,840,000 GPU hours‚Äî11x that used by DeepSeek v3, for a model that benchmarks slightly worse. Those US export regulations on GPUs to China seem to have inspired some very effective training optimizations! The environmental impact got better A welcome result of the increased efficiency of the models‚Äîboth the hosted ones and the ones I can run locally‚Äîis that the energy usage and environmental impact of running a prompt has dropped enormously over the past couple of years. OpenAI themselves are charging 100x less for a prompt compared to the GPT-3 days. I have it on good authority that neither Google Gemini nor Amazon Nova (two of the least expensive model providers) are running prompts at a loss. I think this means that, as individual users, we don‚Äôt need to feel any guilt at all for the energy consumed by the vast majority of our prompts. The impact is likely neglible compared to driving a car down the street or maybe even watching a video on YouTube. Likewise, training. DeepSeek v3 training for less than $6m is a fantastic sign that training costs can and should continue to drop. For less efficient models I find it useful to compare their energy usage to commercial flights. The largest Llama 3 model cost about the same as a single digit number of fully loaded passenger flights from New York to London. That‚Äôs certainly not nothing, but once trained that model can be used by millions of people at no extra training cost. The environmental impact got much, much worse The much bigger problem here is the enormous competitive buildout of the infrastructure that is imagined to be necessary for these models in the future. Companies like Google, Meta, Microsoft and Amazon are all spending billions of dollars rolling out new datacenters, with a very material impact on the electricity grid and the environment. There‚Äôs even talk of spinning up new nuclear power stations, but those can take decades. Is this infrastructure necessary? DeepSeek v3‚Äôs $6m training cost and the continued crash in LLM prices might hint that it‚Äôs not. But would you want to be the big tech executive that argued NOT to build out this infrastructure only to be proven wrong in a few years‚Äô time? An interesting point of comparison here could be the way railways rolled out around the world in the 1800s. Constructing these required enormous investments and had a massive environmental impact, and many of the lines that were built turned out to be unnecessary‚Äîsometimes multiple lines from different companies serving the exact same routes! The resulting bubbles contributed to several financial crashes, see Wikipedia for Panic of 1873, Panic of 1893, Panic of 1901 and the UK‚Äôs Railway Mania. They left us with a lot of useful infrastructure and a great deal of bankruptcies and environmental damage. The year of slop 2024 was the year that the word \"slop\" became a term of art. I wrote about this in May, expanding on this tweet by @deepfates: Watching in real time as ‚Äúslop‚Äù becomes a term of art. the way that ‚Äúspam‚Äù became the term for unwanted emails, ‚Äúslop‚Äù is going in the dictionary as the term for unwanted AI generated content I expanded that definition a tiny bit to this: Slop describes AI-generated content that is both unrequested and unreviewed. I ended up getting quoted talking about slop in both the Guardian and the NY Times. Here‚Äôs what I said in the NY TImes: Society needs concise ways to talk about modern A.I. ‚Äî both the positives and the negatives. ‚ÄòIgnore that email, it‚Äôs spam,‚Äô and ‚ÄòIgnore that article, it‚Äôs slop,‚Äô are both useful lessons. I love the term ‚Äúslop‚Äù because it so succinctly captures one of the ways we should not be using generative AI! Slop was even in the running for Oxford Word of the Year 2024, but it lost to brain rot. Synthetic training data works great An idea that surprisingly seems to have stuck in the public consciousness is that of ‚Äúmodel collapse‚Äù. This was first described in the paper The Curse of Recursion: Training on Generated Data Makes Models Forget in May 2023, and repeated in Nature in July 2024 with the more eye-catching headline AI models collapse when trained on recursively generated data. The idea is seductive: as the internet floods with AI-generated slop the models themselves will degenerate, feeding on their own output in a way that leads to their inevitable demise! That‚Äôs clearly not happening. Instead, we are seeing AI labs increasingly train on synthetic content‚Äîdeliberately creating artificial data to help steer their models in the right way. One', '<3-hop>\\n\\nof the best descriptions I‚Äôve seen of this comes from the Phi-4 technical report, which included this: Synthetic data as a substantial component of pretraining is becoming increasingly common, and the Phi series of models has consistently emphasized the importance of synthetic data. Rather than serving as a cheap substitute for organic data, synthetic data has several direct advantages over organic data. Structured and Gradual Learning. In organic datasets, the relationship between tokens is often complex and indirect. Many reasoning steps may be required to connect the current token to the next, making it challenging for the model to learn effectively from next-token prediction. By contrast, each token generated by a language model is by definition predicted by the preceding tokens, making it easier for a model to follow the resulting reasoning patterns. Another common technique is to use larger models to help create training data for their smaller, cheaper alternatives‚Äîa trick used by an increasing number of labs. DeepSeek v3 used ‚Äúreasoning‚Äù data created by DeepSeek-R1. Meta‚Äôs Llama 3.3 70B fine-tuning used over 25M synthetically generated examples. Careful design of the training data that goes into an LLM appears to be the entire game for creating these models. The days of just grabbing a full scrape of the web and indiscriminately dumping it into a training run are long gone. LLMs somehow got even harder to use A drum I‚Äôve been banging for a while is that LLMs are power-user tools‚Äîthey‚Äôre chainsaws disguised as kitchen knives. They look deceptively simple to use‚Äîhow hard can it be to type messages to a chatbot?‚Äîbut in reality you need a huge depth of both understanding and experience to make the most of them and avoid their many pitfalls. If anything, this problem got worse in 2024. We‚Äôve built computer systems you can talk to in human language, that will answer your questions and usually get them right! ... depending on the question, and how you ask it, and whether it‚Äôs accurately reflected in the undocumented and secret training set. The number of available systems has exploded. Different systems have different tools they can apply to your problems‚Äîlike Python and JavaScript and web search and image generation and maybe even database lookups... so you‚Äôd better understand what those tools are, what they can do and how to tell if the LLM used them or not. Did you know ChatGPT has two entirely different ways of running Python now? Want to build a Claude Artifact that talks to an external API? You‚Äôd better understand CSP and CORS HTTP headers first. The models may have got more capable, but most of the limitations remained the same. OpenAI‚Äôs o1 may finally be able to (mostly) count the Rs in strawberry, but its abilities are still limited by its nature as an LLM and the constraints placed on it by the harness it‚Äôs running in. o1 can‚Äôt run web searches or use Code Interpreter, but GPT-4o can‚Äîboth in that same ChatGPT UI. (o1 will pretend to do those things if you ask it to, a regression to the URL hallucinations bug from early 2023). What are we doing about this? Not much. Most users are thrown in at the deep end. The default LLM chat UI is like taking brand new computer users, dropping them into a Linux terminal and expecting them to figure it all out. Meanwhile, it‚Äôs increasingly common for end users to develop wildly inaccurate mental models of how these things work and what they are capable of. I‚Äôve seen so many examples of people trying to win an argument with a screenshot from ChatGPT‚Äîan inherently ludicrous proposition, given the inherent unreliability of these models crossed with the fact that you can get them to say anything if you prompt them right. There‚Äôs a flipside to this too: a lot of better informed people have sworn off LLMs entirely because they can‚Äôt see how anyone could benefit from a tool with so many flaws. The key skill in getting the most out of LLMs is learning to work with tech that is both inherently unreliable and incredibly powerful at the same time. This is a decidedly non-obvious skill to acquire! There is so much space for helpful education content here, but we need to do do a lot better than outsourcing it all to AI grifters with bombastic Twitter threads. Knowledge is incredibly unevenly distributed Most people have heard of ChatGPT by now. How many have heard of Claude? The knowledge gap between the people who actively follow this stuff and the 99% of the population who do not is vast. The pace of change doesn‚Äôt help either. In just the past month we‚Äôve seen general availability of live interfaces where you can point your phone‚Äôs camera at something and talk about it with your voice... and optionally have it pretend to be Santa. Most self-certified nerds haven‚Äôt even tried that yet. Given the ongoing (and potential) impact on society that this technology has, I don‚Äôt think the size of this gap is healthy. I‚Äôd like to see a lot more effort put into improving this. LLMs need better criticism A lot of people absolutely hate this stuff. In some of the spaces I hang out (Mastodon, Bluesky, Lobste.rs, even Hacker News on occasion) even suggesting that ‚ÄúLLMs are useful‚Äù can be enough to kick off a huge fight. I get it. There are plenty of reasons to dislike this technology‚Äîthe environmental impact, the (lack of) ethics of the training data, the lack of reliability, the negative applications, the potential impact on people‚Äôs jobs. LLMs absolutely warrant criticism. We need to be talking through these problems, finding ways to mitigate them and helping people learn how to use these tools responsibly in ways where the positive applications outweigh the negative. I like people who are skeptical of this stuff. The hype has been deafening for more than two years now, and there are enormous quantities of snake oil and misinformation out there. A lot']",
                  "The use of synthetic training data offers several advantages over organic data in the development of large language models, as highlighted in the Phi-4 technical report. These advantages include:\n\n1. **Structured and Gradual Learning:** Synthetic data allows for easier learning of reasoning patterns because each token is generated based on preceding tokens, making the relationships more explicit. Unlike organic datasets where token relationships are often complex and indirect, synthetic data can be designed to facilitate clearer learning pathways.\n\n2. **Enhanced Data Design and Control:** Carefully designed synthetic datasets enable targeted training strategies. For example, larger models can generate reasoning data to train smaller, more cost-effective models, as seen with DeepSeek v3 and Meta‚Äôs Llama 3.3 70B fine-tuning, which used over 25 million synthetically generated examples.\n\n3. **Efficient and Purposeful Data Generation:** Synthetic data can be tailored to include specific reasoning steps or knowledge, making the training process more efficient and focused. This reduces reliance on indiscriminate web scraping and allows for more curated, high-quality training inputs.\n\nRecent model training practices exemplify these advantages through the strategic use of synthetic data to improve reasoning capabilities, reduce costs, and enhance the quality of training datasets, ultimately contributing to more effective and adaptable large language models.",
                  "Synthetic training data offers several direct advantages over organic data in the development of large language models. According to the Phi-4 technical report, synthetic data enables structured and gradual learning because each token generated is predicted by the preceding tokens, making it easier for models to follow reasoning patterns. In contrast, organic datasets often have complex and indirect relationships between tokens, which can make effective learning more challenging. Additionally, synthetic data allows for deliberate design and curation, helping steer models in desired directions. Recent model training practices illustrate these benefits: for example, DeepSeek v3 used 'reasoning' data created by DeepSeek-R1, and Meta‚Äôs Llama 3.3 70B fine-tuning involved over 25 million synthetically generated examples. These practices show that synthetic data is not just a substitute for organic data but a tool for more effective and targeted model training.",
                  "multi_hop_abstract_query_synthesizer"
                ],
                [
                  "7",
                  "How have improvements in LLM efficiency over the past year influenced both the environmental impact of AI model training and the cost of using large language models, according to recent trends?",
                  "['Simon Willison‚Äôs Weblog\\n\\nSubscribe\\n\\nThings we learned about LLMs in 2024\\n\\n31st December 2024\\n\\nA lot has happened in the world of Large Language Models over the course of 2024. Here‚Äôs a review of things we figured out about the field in the past twelve months, plus my attempt at identifying key themes and pivotal moments.\\n\\nThis is a sequel to my review of 2023.\\n\\nIn this article:\\n\\nThe GPT-4 barrier was comprehensively broken\\n\\nSome of those GPT-4 models run on my laptop\\n\\nLLM prices crashed, thanks to competition and increased efficiency\\n\\nMultimodal vision is common, audio and video are starting to emerge\\n\\nVoice and live camera mode are science fiction come to life\\n\\nPrompt driven app generation is a commodity already\\n\\nUniversal access to the best models lasted for just a few short months\\n\\n‚ÄúAgents‚Äù still haven‚Äôt really happened yet\\n\\nEvals really matter\\n\\nApple Intelligence is bad, Apple‚Äôs MLX library is excellent\\n\\nThe rise of inference-scaling ‚Äúreasoning‚Äù models', '‚ÄúAgents‚Äù still haven‚Äôt really happened yet\\n\\nEvals really matter\\n\\nApple Intelligence is bad, Apple‚Äôs MLX library is excellent\\n\\nThe rise of inference-scaling ‚Äúreasoning‚Äù models\\n\\nWas the best currently available LLM trained in China for less than $6m?\\n\\nThe environmental impact got better\\n\\nThe environmental impact got much, much worse\\n\\nThe year of slop\\n\\nSynthetic training data works great\\n\\nLLMs somehow got even harder to use\\n\\nKnowledge is incredibly unevenly distributed\\n\\nLLMs need better criticism\\n\\nEverything tagged ‚Äúllms‚Äù on my blog in 2024\\n\\nThe GPT-4 barrier was comprehensively broken\\n\\nIn my December 2023 review I wrote about how We don‚Äôt yet know how to build GPT-4‚ÄîOpenAI‚Äôs best model was almost a year old at that point, yet no other AI lab had produced anything better. What did OpenAI know that the rest of us didn‚Äôt?', 'LLM prices crashed, thanks to competition and increased efficiency\\n\\nThe past twelve months have seen a dramatic collapse in the cost of running a prompt through the top tier hosted LLMs.\\n\\nIn December 2023 (here‚Äôs the Internet Archive for the OpenAI pricing page) OpenAI were charging $30/million input tokens for GPT-4, $10/mTok for the then-new GPT-4 Turbo and $1/mTok for GPT-3.5 Turbo.\\n\\nToday $30/mTok gets you OpenAI‚Äôs most expensive model, o1. GPT-4o is $2.50 (12x cheaper than GPT-4) and GPT-4o mini is $0.15/mTok‚Äî200x cheaper than GPT-4, nearly 7x cheaper than GPT-3.5 and massively more capable than that model.\\n\\nOther model providers charge even less. Anthropic‚Äôs Claude 3 Haiku (from March, but still their cheapest model) is $0.25/mTok. Google‚Äôs Gemini 1.5 Flash is $0.075/mTok and their Gemini 1.5 Flash 8B is $0.0375/mTok‚Äîthat‚Äôs 27x cheaper than GPT-3.5 Turbo last year.\\n\\nI‚Äôve been tracking these pricing changes under my llm-pricing tag.']",
                  "['<1-hop>\\n\\nThe rise of inference-scaling ‚Äúreasoning‚Äù models Was the best currently available LLM trained in China for less than $6m? The environmental impact got better The environmental impact got much, much worse The year of slop Synthetic training data works great LLMs somehow got even harder to use Knowledge is incredibly unevenly distributed LLMs need better criticism Everything tagged ‚Äúllms‚Äù on my blog in 2024 The GPT-4 barrier was comprehensively broken In my December 2023 review I wrote about how We don‚Äôt yet know how to build GPT-4‚ÄîOpenAI‚Äôs best model was almost a year old at that point, yet no other AI lab had produced anything better. What did OpenAI know that the rest of us didn‚Äôt? I‚Äôm relieved that this has changed completely in the past twelve months. 18 organizations now have models on the Chatbot Arena Leaderboard that rank higher than the original GPT-4 from March 2023 (GPT-4-0314 on the board)‚Äî70 models in total. Screenshot of a comparison table showing AI model rankings. Table headers: Rank (UB), Rank (StyleCtrl), Model, Arena Score, 95% CI, Votes, Organization, License. Shows 12 models including GLM-4-0520, Llama-3-70B-Instruct, Gemini-1.5-Flash-8B-Exp-0827, with rankings, scores, and licensing details. Models range from rank 52-69 with Arena scores between 1186-1207. The earliest of those was Google‚Äôs Gemini 1.5 Pro, released in February. In addition to producing GPT-4 level outputs, it introduced several brand new capabilities to the field‚Äîmost notably its 1 million (and then later 2 million) token input context length, and the ability to input video. I wrote about this at the time in The killer app of Gemini Pro 1.5 is video, which earned me a short appearance as a talking head in the Google I/O opening keynote in May. Gemini 1.5 Pro also illustrated one of the key themes of 2024: increased context lengths. Last year most models accepted 4,096 or 8,192 tokens, with the notable exception of Claude 2.1 which accepted 200,000. Today every serious provider has a 100,000+ token model, and Google‚Äôs Gemini series accepts up to 2 million. Longer inputs dramatically increase the scope of problems that can be solved with an LLM: you can now throw in an entire book and ask questions about its contents, but more importantly you can feed in a lot of example code to help the model correctly solve a coding problem. LLM use-cases that involve long inputs are far more interesting to me than short prompts that rely purely on the information already baked into the model weights. Many of my tools were built using this pattern. Getting back to models that beat GPT-4: Anthropic‚Äôs Claude 3 series launched in March, and Claude 3 Opus quickly became my new favourite daily-driver. They upped the ante even more in June with the launch of Claude 3.5 Sonnet‚Äîa model that is still my favourite six months later (though it got a significant upgrade on October 22, confusingly keeping the same 3.5 version number. Anthropic fans have since taken to calling it Claude 3.6). Then there‚Äôs the rest. If you browse the Chatbot Arena leaderboard today‚Äîstill the most useful single place to get a vibes-based evaluation of models‚Äîyou‚Äôll see that GPT-4-0314 has fallen to around 70th place. The 18 organizations with higher scoring models are Google, OpenAI, Alibaba, Anthropic, Meta, Reka AI, 01 AI, Amazon, Cohere, DeepSeek, Nvidia, Mistral, NexusFlow, Zhipu AI, xAI, AI21 Labs, Princeton and Tencent. Training a GPT-4 beating model was a huge deal in 2023. In 2024 it‚Äôs an achievement that isn‚Äôt even particularly notable, though I personally still celebrate any time a new organization joins that list. Some of those GPT-4 models run on my laptop My personal laptop is a 64GB M2 MacBook Pro from 2023. It‚Äôs a powerful machine, but it‚Äôs also nearly two years old now‚Äîand crucially it‚Äôs the same laptop I‚Äôve been using ever since I first ran an LLM on my computer back in March 2023 (see Large language models are having their Stable Diffusion moment). That same laptop that could just about run a GPT-3-class model in March last year has now run multiple GPT-4 class models! Some of my notes on that: Qwen2.5-Coder-32B is an LLM that can code well that runs on my Mac talks about Qwen2.5-Coder-32B in November‚Äîan Apache 2.0 licensed model! I can now run a GPT-4 class model on my laptop talks about running Meta‚Äôs Llama 3.3 70B (released in December) This remains astonishing to me. I thought a model with the capabilities and output quality of GPT-4 needed a datacenter class server with one or more $40,000+ GPUs. These models take up enough of my 64GB of RAM that I don‚Äôt run them often‚Äîthey don‚Äôt leave much room for anything else. The fact that they run at all is a testament to the incredible training and inference performance gains that we‚Äôve figured out over the past year. It turns out there was a lot of low-hanging fruit to be harvested in terms of model efficiency. I expect there‚Äôs still more to come. Meta‚Äôs Llama 3.2 models deserve a special mention. They may not be GPT-4 class, but at 1B and 3B sizes they punch massively above their weight. I run Llama 3.2 3B on my iPhone using the free MLC Chat iOS app and it‚Äôs a shockingly capable model for its tiny (<2GB) size. Try firing it up and asking it for ‚Äúa plot outline of a Netflix Christmas movie where a data journalist falls in love with a local ceramacist‚Äù. Here‚Äôs what I got, at a respectable 20 tokens per second: MLC Chat: Llama - [System] Ready to chat. a plot outline of a Netflix Christmas movie where a data journalist falls in love with a local ceramacist. Show as Markdown is turned on. Here\\'s a plot outline for a Netflix Christmas movie: Title: \"Love in the Clay\" Plot Outline: We meet our protagonist, JESSICA, a data journalist who has just returned to her hometown of Willow Creek, a small, charming town nestled in the snow-covered mountains. She\\'s back to work', \"<2-hop>\\n\\non a story about the town's history and the effects of gentrification on the local community. Here‚Äôs the rest of the transcript. It‚Äôs bland and generic, but my phone can pitch bland and generic Christmas movies to Netflix now! LLM prices crashed, thanks to competition and increased efficiency The past twelve months have seen a dramatic collapse in the cost of running a prompt through the top tier hosted LLMs. In December 2023 (here‚Äôs the Internet Archive for the OpenAI pricing page) OpenAI were charging $30/million input tokens for GPT-4, $10/mTok for the then-new GPT-4 Turbo and $1/mTok for GPT-3.5 Turbo. Today $30/mTok gets you OpenAI‚Äôs most expensive model, o1. GPT-4o is $2.50 (12x cheaper than GPT-4) and GPT-4o mini is $0.15/mTok‚Äî200x cheaper than GPT-4, nearly 7x cheaper than GPT-3.5 and massively more capable than that model. Other model providers charge even less. Anthropic‚Äôs Claude 3 Haiku (from March, but still their cheapest model) is $0.25/mTok. Google‚Äôs Gemini 1.5 Flash is $0.075/mTok and their Gemini 1.5 Flash 8B is $0.0375/mTok‚Äîthat‚Äôs 27x cheaper than GPT-3.5 Turbo last year. I‚Äôve been tracking these pricing changes under my llm-pricing tag. These price drops are driven by two factors: increased competition and increased efficiency. The efficiency thing is really important for everyone who is concerned about the environmental impact of LLMs. These price drops tie directly to how much energy is being used for running prompts. There‚Äôs still plenty to worry about with respect to the environmental impact of the great AI datacenter buildout, but a lot of the concerns over the energy cost of individual prompts are no longer credible. Here‚Äôs a fun napkin calculation: how much would it cost to generate short descriptions of every one of the 68,000 photos in my personal photo library using Google‚Äôs Gemini 1.5 Flash 8B (released in October), their cheapest model? Each photo would need 260 input tokens and around 100 output tokens. 260 * 68,000 = 17,680,000 input tokens 17,680,000 * $0.0375/million = $0.66 100 * 68,000 = 6,800,000 output tokens 6,800,000 * $0.15/million = $1.02 That‚Äôs a total cost of $1.68 to process 68,000 images. That‚Äôs so absurdly cheap I had to run the numbers three times to confirm I got it right. How good are those descriptions? Here‚Äôs what I got from this command: llm -m gemini-1.5-flash-8b-latest describe -a IMG_1825.jpeg Against this photo of butterflies at the California Academy of Sciences: A photo of two butterflies feeding on a red tray A shallow dish, likely a hummingbird or butterfly feeder, is red. Pieces of orange slices of fruit are visible inside the dish. Two butterflies are positioned in the feeder, one is a dark brown/black butterfly with white/cream-colored markings. The other is a large, brown butterfly with patterns of lighter brown, beige, and black markings, including prominent eye spots. The larger brown butterfly appears to be feeding on the fruit. 260 input tokens, 92 output tokens. Cost approximately 0.0024 cents (that‚Äôs less than a 400th of a cent). This increase in efficiency and reduction in price is my single favourite trend from 2024. I want the utility of LLMs at a fraction of the energy cost and it looks like that‚Äôs what we‚Äôre getting. Multimodal vision is common, audio and video are starting to emerge My butterfly example above illustrates another key trend from 2024: the rise of multi-modal LLMs. A year ago the single most notable example of these was GPT-4 Vision, released at OpenAI‚Äôs DevDay in November 2023. Google‚Äôs multi-modal Gemini 1.0 was announced on December 7th 2023 so it also (just) makes it into the 2023 window. In 2024, almost every significant model vendor released multi-modal models. We saw the Claude 3 series from Anthropic in March, Gemini 1.5 Pro in April (images, audio and video), then September brought Qwen2-VL and Mistral‚Äôs Pixtral 12B and Meta‚Äôs Llama 3.2 11B and 90B vision models. We got audio input and output from OpenAI in October, then November saw SmolVLM from Hugging Face and December saw image and video models from Amazon Nova. In October I upgraded my LLM CLI tool to support multi-modal models via attachments. It now has plugins for a whole collection of different vision models. I think people who complain that LLM improvement has slowed are often missing the enormous advances in these multi-modal models. Being able to run prompts against images (and audio and video) is a fascinating new way to apply these models. Voice and live camera mode are science fiction come to life The audio and live video modes that have started to emerge deserve a special mention. The ability to talk to ChatGPT first arrived in September 2023, but it was mostly an illusion: OpenAI used their excellent Whisper speech-to-text model and a new text-to-speech model (creatively named tts-1) to enable conversations with the ChatGPT mobile apps, but the actual model just saw text. The May 13th announcement of GPT-4o included a demo of a brand new voice mode, where the true multi-modal GPT-4o (the o is for ‚Äúomni‚Äù) model could accept audio input and output incredibly realistic sounding speech without needing separate TTS or STT models. The demo also sounded conspicuously similar to Scarlett Johansson... and after she complained the voice from the demo, Skye, never made it to a production product. The delay in releasing the new voice mode after the initial demo caused quite a lot of confusion. I wrote about that in ChatGPT in ‚Äú4o‚Äù mode is not running the new features yet. When ChatGPT Advanced Voice mode finally did roll out (a slow roll from August through September) it was spectacular. I‚Äôve been using it extensively on walks with my dog and it‚Äôs amazing how much the improvement in intonation elevates the material. I‚Äôve also had a lot of fun experimenting with the OpenAI audio APIs. Even more fun: Advanced Voice mode can do accents! Here‚Äôs what happened when I told it I need you to pretend to be a California brown pelican with a very thick Russian accent, but\"]",
                  "Improvements in LLM efficiency over the past year have significantly influenced both the environmental impact of AI model training and the cost of using large language models. According to recent trends, as highlighted in the review, increased efficiency has led to a dramatic decrease in the cost of running prompt-based interactions with top-tier LLMs, with prices dropping by factors of up to 200x for certain models compared to the previous year. This reduction in operational costs is partly due to advancements that make models more efficient to run.\n\nFurthermore, the environmental impact has improved, as increased efficiency means less computational power is required for training and inference, which in turn reduces energy consumption. While the review also mentions that the environmental impact got worse at some point during the year, the overall trend for efficiency improvements has contributed to making AI model training and deployment more environmentally friendly.",
                  "Improvements in LLM efficiency over the past year have significantly reduced both the environmental impact of AI model training and the cost of using large language models. As described, the dramatic collapse in the cost of running prompts through top-tier hosted LLMs is directly tied to increased efficiency and competition. For example, OpenAI‚Äôs GPT-4o is now 12 times cheaper than GPT-4, and other providers like Google and Anthropic offer even lower prices. This efficiency means that the energy cost per prompt has dropped, alleviating many concerns about the environmental impact of individual LLM usage. While the overall environmental impact of large-scale AI datacenter buildouts remains a concern, the energy required for each prompt is now much lower, making LLMs more accessible and environmentally sustainable. These trends are exemplified by the ability to process large datasets, such as generating descriptions for 68,000 photos, at a negligible cost and energy footprint.",
                  "multi_hop_abstract_query_synthesizer"
                ],
                [
                  "8",
                  "How has ChatGPT been discussed in relation to both its practical applications and its societal impact, including concerns about job displacement and ethical considerations, as reflected in the 2024 and 2023 blog posts and analytics?",
                  "['Law is not ethics. Is it OK to train models on people‚Äôs content without their permission, when those models will then be used in ways that compete with those people?\\n\\nAs the quality of results produced by AI models has increased over the year, these questions have become even more pressing.\\n\\nThe impact on human society in terms of these models is already huge, if difficult to objectively measure.\\n\\nPeople have certainly lost work to them‚Äîanecdotally, I‚Äôve seen this for copywriters, artists and translators.\\n\\nThere are a great deal of untold stories here. I‚Äôm hoping 2024 sees significant amounts of dedicated journalism on this topic.\\n\\nMy blog in 2023\\n\\nHere‚Äôs a tag cloud for content I posted to my blog in 2023 (generated using Django SQL Dashboard):\\n\\nTag cloud words in order of size: ai, generativeai, llms, openai, chatgpt, projects, python, datasette, ethics, llama, homebrewllms, sqlite, gpt3, promptengineering, promptinjection, llm, security, opensource, gpt4, weeknotes', 'The most recent twist, again from December (December was a lot) is live video. ChatGPT voice mode now provides the option to share your camera feed with the model and talk about what you can see in real time. Google Gemini have a preview of the same feature, which they managed to ship the day before ChatGPT did.\\n\\nThese abilities are just a few weeks old at this point, and I don‚Äôt think their impact has been fully felt yet. If you haven‚Äôt tried them out yet you really should.\\n\\nBoth Gemini and OpenAI offer API access to these features as well. OpenAI started with a WebSocket API that was quite challenging to use, but in December they announced a new WebRTC API which is much easier to get started with. Building a web app that a user can talk to via voice is easy now!\\n\\nPrompt driven app generation is a commodity already\\n\\nThis was possible with GPT-4 in 2023, but the value it provides became evident in 2024.', 'There is so much space for helpful education content here, but we need to do do a lot better than outsourcing it all to AI grifters with bombastic Twitter threads.\\n\\nKnowledge is incredibly unevenly distributed\\n\\nMost people have heard of ChatGPT by now. How many have heard of Claude?\\n\\nThe knowledge gap between the people who actively follow this stuff and the 99% of the population who do not is vast.\\n\\nThe pace of change doesn‚Äôt help either. In just the past month we‚Äôve seen general availability of live interfaces where you can point your phone‚Äôs camera at something and talk about it with your voice... and optionally have it pretend to be Santa. Most self-certified nerds haven‚Äôt even tried that yet.\\n\\nGiven the ongoing (and potential) impact on society that this technology has, I don‚Äôt think the size of this gap is healthy. I‚Äôd like to see a lot more effort put into improving this.\\n\\nLLMs need better criticism']",
                  "['<1-hop>\\n\\nof very bad decisions are being made based on that hype. Being critical is a virtue. If we want people with decision-making authority to make good decisions about how to apply these tools we first need to acknowledge that there ARE good applications, and then help explain how to put those into practice while avoiding the many unintiutive traps. (If you still don‚Äôt think there are any good applications at all I‚Äôm not sure why you made it to this point in the article!) I think telling people that this whole field is environmentally catastrophic plagiarism machines that constantly make things up is doing those people a disservice, no matter how much truth that represents. There is genuine value to be had here, but getting to that value is unintuitive and needs guidance. Those of us who understand this stuff have a duty to help everyone else figure it out. Everything tagged ‚Äúllms‚Äù on my blog in 2024 Because I undoubtedly missed a whole bunch of things, here‚Äôs every long-form post I wrote in 2024 that I tagged with llms: January 7th: It‚Äôs OK to call it Artificial Intelligence 9th: What I should have said about the term Artificial Intelligence 17th: Talking about Open Source LLMs on Oxide and Friends 26th: LLM 0.13: The annotated release notes February 21st: The killer app of Gemini Pro 1.5 is video March 5th: Prompt injection and jailbreaking are not the same thing 8th: The GPT-4 barrier has finally been broken 22nd: Claude and ChatGPT for ad-hoc sidequests 23rd: Building and testing C extensions for SQLite with ChatGPT Code Interpreter 26th: llm cmd undo last git commit‚Äîa new plugin for LLM April 8th: Building files-to-prompt entirely using Claude 3 Opus 10th: Three major LLM releases in 24 hours (plus weeknotes) 17th: AI for Data Journalism: demonstrating what we can do with this stuff right now 22nd: Options for accessing Llama 3 from the terminal using LLM May 8th: Slop is the new name for unwanted AI-generated content 15th: ChatGPT in ‚Äú4o‚Äù mode is not running the new features yet 29th: Training is not the same as chatting: ChatGPT and other LLMs don‚Äôt remember everything you say June 6th: Accidental prompt injection against RAG applications 10th: Thoughts on the WWDC 2024 keynote on Apple Intelligence 17th: Language models on the command-line 21st: Building search-based RAG using Claude, Datasette and Val Town 27th: Open challenges for AI engineering July 14th: Imitation Intelligence, my keynote for PyCon US 2024 19th: Weeknotes: GPT-4o mini, LLM 0.15, sqlite-utils 3.37 and building a staging environment August 6th: Weeknotes: a staging environment, a Datasette alpha and a bunch of new LLMs 8th: django-http-debug, a new Django app mostly written by Claude 23rd: Claude‚Äôs API now supports CORS requests, enabling client-side applications 26th: Building a tool showing how Gemini Pro can return bounding boxes for objects in images September 6th: Calling LLMs from client-side JavaScript, converting PDFs to HTML + weeknotes 10th: Notes from my appearance on the Software Misadventures Podcast 12th: Notes on OpenAI‚Äôs new o1 chain-of-thought models 20th: Notes on using LLMs for code 29th: NotebookLM‚Äôs automatically generated podcasts are surprisingly effective 30th: Weeknotes: Three podcasts, two trips and a new plugin system October 1st: OpenAI DevDay 2024 live blog 2nd: OpenAI DevDay: Let‚Äôs build developer tools, not digital God 15th: ChatGPT will happily write you a thinly disguised horoscope 17th: Video scraping: extracting JSON data from a 35 second screen capture for less than 1/10th of a cent 18th: Experimenting with audio input and output for the OpenAI Chat Completion API 19th: Running Llama 3.2 Vision and Phi-3.5 Vision on a Mac with mistral.rs 21st: Everything I built with Claude Artifacts this week 22nd: Initial explorations of Anthropic‚Äôs new Computer Use capability 24th: Notes on the new Claude analysis JavaScript code execution tool 27th: Run a prompt to generate and execute jq programs using llm-jq 29th: You can now run prompts against images, audio and video in your terminal using LLM 30th: WÃ∂eÃ∂eÃ∂kÃ∂nÃ∂oÃ∂tÃ∂eÃ∂sÃ∂ Monthnotes for October November 4th: Claude 3.5 Haiku 7th: Project: VERDAD‚Äîtracking misinformation in radio broadcasts using Gemini 1.5 12th: Qwen2.5-Coder-32B is an LLM that can code well that runs on my Mac 19th: Notes from Bing Chat‚ÄîOur First Encounter With Manipulative AI 25th: Ask questions of SQLite databases and CSV/JSON files in your terminal December 4th: First impressions of the new Amazon Nova LLMs (via a new llm-bedrock plugin) 7th: Prompts.js 9th: I can now run a GPT-4 class model on my laptop 10th: ChatGPT Canvas can make API requests now, but it‚Äôs complicated 11th: Gemini 2.0 Flash: An outstanding multi-modal LLM with a sci-fi streaming mode 19th: Building Python tools with a one-shot prompt using uv run and Claude Projects 19th: Gemini 2.0 Flash ‚ÄúThinking mode‚Äù 20th: December in LLMs has been a lot 20th: Live blog: the 12th day of OpenAI‚Äî‚ÄúEarly evals for OpenAI o3‚Äù 24th: Trying out QvQ‚ÄîQwen‚Äôs new visual reasoning model 31st: Things we learned about LLMs in 2024 (This list generated using Django SQL Dashboard with a SQL query written for me by Claude.) Posted 31st December 2024 at 6:07 pm ¬∑ Follow me on Mastodon, Bluesky, Twitter or subscribe to my newsletter More recent articles Feed a video to a vision LLM as a sequence of JPEG frames on the CLI (also LLM 0.25) - 5th May 2025 Two publishers and three authors fail to understand what \"vibe coding\" means - 1st May 2025 Understanding the recent criticism of the Chatbot Arena - 30th April 2025 This is Things we learned about LLMs in 2024 by Simon Willison, posted on 31st December 2024. Part of series LLMs annual review Stuff we figured out about AI in 2023 - Dec. 31, 2023, 11:59 p.m. Things we learned about LLMs in 2024 - Dec. 31, 2024, 6:07 p.m. google 360 ai 1262 openai 289 generative-ai 1089 local-llms 113 llms 1076 anthropic 136 gemini 80 meta 32 llm-reasoning 44 long-context 15 ai-energy-usage 5 Next: Ending a year long posting streak Previous: Trying out', '<2-hop>\\n\\nMicrosoft over this issue. The 69 page PDF is genuinely worth reading‚Äîespecially the first few pages, which lay out the issues in a way that‚Äôs surprisingly easy to follow. The rest of the document includes some of the clearest explanations of what LLMs are, how they work and how they are built that I‚Äôve read anywhere. The legal arguments here are complex. I‚Äôm not a lawyer, but I don‚Äôt think this one will be easily decided. Whichever way it goes, I expect this case to have a profound impact on how this technology develops in the future. Law is not ethics. Is it OK to train models on people‚Äôs content without their permission, when those models will then be used in ways that compete with those people? As the quality of results produced by AI models has increased over the year, these questions have become even more pressing. The impact on human society in terms of these models is already huge, if difficult to objectively measure. People have certainly lost work to them‚Äîanecdotally, I‚Äôve seen this for copywriters, artists and translators. There are a great deal of untold stories here. I‚Äôm hoping 2024 sees significant amounts of dedicated journalism on this topic. My blog in 2023 Here‚Äôs a tag cloud for content I posted to my blog in 2023 (generated using Django SQL Dashboard): Tag cloud words in order of size: ai, generativeai, llms, openai, chatgpt, projects, python, datasette, ethics, llama, homebrewllms, sqlite, gpt3, promptengineering, promptinjection, llm, security, opensource, gpt4, weeknotes The top five: ai (342), generativeai (300), llms (287), openai (86), chatgpt (78). I‚Äôve written a lot about this stuff! I grabbed a screenshot of my Plausible analytics for the year, fed that to ChatGPT Vision, told it to extract the data into a table, then got it to mix in entry titles (from a SQL query it wrote) and produced this table with it. Here are my top entries this year by amount of traffic: Article Visitors Pageviews Bing: ‚ÄúI will not harm you unless you harm me first‚Äù 1.1M 1.3M Leaked Google document: ‚ÄúWe Have No Moat, And Neither Does OpenAI‚Äù 132k 162k Large language models are having their Stable Diffusion moment 121k 150k Prompt injection: What‚Äôs the worst that can happen? 79.8k 95.9k Embeddings: What they are and why they matter 61.7k 79.3k Catching up on the weird world of LLMs 61.6k 85.9k llamafile is the new best way to run an LLM on your own computer 52k 66k Prompt injection explained, with video, slides, and a transcript 51k 61.9k AI-enhanced development makes me more ambitious with my projects 49.6k 60.1k Understanding GPT tokenizers 49.5k 61.1k Exploring GPTs: ChatGPT in a trench coat? 46.4k 58.5k Could you train a ChatGPT-beating model for $85,000 and run it in a browser? 40.5k 49.2k How to implement Q&A against your documentation with GPT3, embeddings and Datasette 37.3k 44.9k Lawyer cites fake cases invented by ChatGPT, judge is not amused 37.1k 47.4k Now add a walrus: Prompt engineering in DALL-E 3 32.8k 41.2k Web LLM runs the vicuna-7b Large Language Model entirely in your browser, and it‚Äôs very impressive 32.5k 38.2k ChatGPT can‚Äôt access the internet, even though it really looks like it can 30.5k 34.2k Stanford Alpaca, and the acceleration of on-device large language model development 29.7k 35.7k Run Llama 2 on your own Mac using LLM and Homebrew 27.9k 33.6k Midjourney 5.1 26.7k 33.4k Think of language models like ChatGPT as a ‚Äúcalculator for words‚Äù 25k 31.8k Multi-modal prompt injection image attacks against GPT-4V 23.7k 27.4k I also gave a bunch of talks and podcast appearances. I‚Äôve started habitually turning my talks into annotated presentations‚Äîhere are my best from 2023: Prompt injection explained, with video, slides, and a transcript Catching up on the weird world of LLMs Making Large Language Models work for you Open questions for AI engineering Embeddings: What they are and why they matter Financial sustainability for open source projects at GitHub Universe And in podcasts: What AI can do for you on the Theory of Change Working in public on Path to Citus Con LLMs break the internet on the Changelog Talking Large Language Models on Rooftop Ruby Thoughts on the OpenAI board situation on Newsroom Robots Industry‚Äôs Tardy Response to the AI Prompt Injection Vulnerability on RedMonk Conversations Posted 31st December 2023 at 11:59 pm ¬∑ Follow me on Mastodon, Bluesky, Twitter or subscribe to my newsletter More recent articles Feed a video to a vision LLM as a sequence of JPEG frames on the CLI (also LLM 0.25) - 5th May 2025 Two publishers and three authors fail to understand what \"vibe coding\" means - 1st May 2025 Understanding the recent criticism of the Chatbot Arena - 30th April 2025 This is Stuff we figured out about AI in 2023 by Simon Willison, posted on 31st December 2023. Part of series LLMs annual review Stuff we figured out about AI in 2023 - Dec. 31, 2023, 11:59 p.m. Things we learned about LLMs in 2024 - Dec. 31, 2024, 6:07 p.m. blogging 105 ai 1262 generative-ai 1089 llms 1076 Next: Tom Scott, and the formidable power of escalating streaks Previous: Last weeknotes of 2023 Colophon ¬© 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 2025']",
                  "ChatGPT has been discussed extensively in relation to both its practical applications and its societal impact, as reflected in the 2023 blog posts and analytics. In 2023, the blog highlighted the rapid development of ChatGPT‚Äôs features, such as voice mode and live video capabilities, emphasizing how these advancements are changing user interactions and expanding the potential uses of AI models. The discussions also touched on the accessibility of prompt-driven app generation, noting that such functionalities became more valuable in 2024, indicating a trajectory of increasing practical utility.\n\nRegarding societal impact, the blog acknowledged that AI models like ChatGPT have already had a significant effect on society, including the displacement of certain jobs‚Äîparticularly in fields like copywriting, art, and translation‚Äîbased on anecdotal evidence. There is a concern about the broad societal implications, such as the uneven distribution of knowledge about AI technologies and the rapid pace of change, which can widen the knowledge gap between those actively following AI developments and the general population. The blog also expressed a desire for more dedicated journalism and societal discourse on these issues, indicating ongoing concerns about job displacement and the ethical considerations surrounding AI training practices.\n\nOverall, the reflections from 2023 and 2024 show that ChatGPT's practical capabilities are expanding rapidly, while societal discussions are increasingly focusing on its disruptive potential, ethical questions, and the need for better societal criticism and awareness.",
                  "ChatGPT has been a recurring topic in blog posts and analytics throughout 2023 and 2024, reflecting both its practical applications and its broader societal impact. In 2024, ChatGPT was featured in discussions about ad-hoc sidequests, code interpretation, and its evolving features, such as the '4o' mode and the distinction between training and chatting. The blog highlights the need for critical evaluation of AI tools like ChatGPT, emphasizing that while there are unintuitive traps and potential for misuse, there is also genuine value that requires guidance to realize. Ethical concerns are raised, particularly regarding the training of models on people's content without permission and the resulting competition with human workers, which has led to job losses among copywriters, artists, and translators. The analytics from 2023 show that 'chatgpt' was among the top tags and most visited articles, including topics like 'Lawyer cites fake cases invented by ChatGPT' and 'ChatGPT can‚Äôt access the internet, even though it really looks like it can.' These entries illustrate both the capabilities and limitations of ChatGPT, as well as the legal and ethical debates surrounding its use. Overall, the blog posts and analytics demonstrate that ChatGPT is at the center of ongoing discussions about practical utility, ethical challenges, and its significant, if sometimes difficult to measure, impact on society.",
                  "multi_hop_specific_query_synthesizer"
                ],
                [
                  "9",
                  "Anthropic make LLMs, but what is problem with LLMs and what is needed to make them useful, Anthropic way?",
                  "['LLMs need better criticism\\n\\nA lot of people absolutely hate this stuff. In some of the spaces I hang out (Mastodon, Bluesky, Lobste.rs, even Hacker News on occasion) even suggesting that ‚ÄúLLMs are useful‚Äù can be enough to kick off a huge fight.\\n\\nI get it. There are plenty of reasons to dislike this technology‚Äîthe environmental impact, the (lack of) ethics of the training data, the lack of reliability, the negative applications, the potential impact on people‚Äôs jobs.\\n\\nLLMs absolutely warrant criticism. We need to be talking through these problems, finding ways to mitigate them and helping people learn how to use these tools responsibly in ways where the positive applications outweigh the negative.\\n\\nI like people who are skeptical of this stuff. The hype has been deafening for more than two years now, and there are enormous quantities of snake oil and misinformation out there. A lot of very bad decisions are being made based on that hype. Being critical is a virtue.', 'It‚Äôs still astonishing to me how effective they are though.\\n\\nOne of the great weaknesses of LLMs is their tendency to hallucinate‚Äîto imagine things that don‚Äôt correspond to reality. You would expect this to be a particularly bad problem for code‚Äîif an LLM hallucinates a method that doesn‚Äôt exist, the code should be useless.\\n\\nExcept... you can run generated code to see if it‚Äôs correct. And with patterns like ChatGPT Code Interpreter the LLM can execute the code itself, process the error message, then rewrite it and keep trying until it works!\\n\\nSo hallucination is a much lesser problem for code generation than for anything else. If only we had the equivalent of Code Interpreter for fact-checking natural language!\\n\\nHow should we feel about this as software engineers?\\n\\nOn the one hand, this feels like a threat: who needs a programmer if ChatGPT can write code for you?', 'Meanwhile, it‚Äôs increasingly common for end users to develop wildly inaccurate mental models of how these things work and what they are capable of. I‚Äôve seen so many examples of people trying to win an argument with a screenshot from ChatGPT‚Äîan inherently ludicrous proposition, given the inherent unreliability of these models crossed with the fact that you can get them to say anything if you prompt them right.\\n\\nThere‚Äôs a flipside to this too: a lot of better informed people have sworn off LLMs entirely because they can‚Äôt see how anyone could benefit from a tool with so many flaws. The key skill in getting the most out of LLMs is learning to work with tech that is both inherently unreliable and incredibly powerful at the same time. This is a decidedly non-obvious skill to acquire!\\n\\nThere is so much space for helpful education content here, but we need to do do a lot better than outsourcing it all to AI grifters with bombastic Twitter threads.']",
                  "['<1-hop>\\n\\nskeptical as to their utility based, once again, on the challenge of gullibility. LLMs believe anything you tell them. Any systems that attempts to make meaningful decisions on your behalf will run into the same roadblock: how good is a travel agent, or a digital assistant, or even a research tool if it can‚Äôt distinguish truth from fiction? Just the other day Google Search was caught serving up an entirely fake description of the non-existant movie ‚ÄúEncanto 2‚Äù. It turned out to be summarizing an imagined movie listing from a fan fiction wiki. Prompt injection is a natural consequence of this gulibility. I‚Äôve seen precious little progress on tackling that problem in 2024, and we‚Äôve been talking about it since September 2022. I‚Äôm beginning to see the most popular idea of ‚Äúagents‚Äù as dependent on AGI itself. A model that‚Äôs robust against gulliblity is a very tall order indeed. Evals really matter Anthropic‚Äôs Amanda Askell (responsible for much of the work behind Claude‚Äôs Character): The boring yet crucial secret behind good system prompts is test-driven development. You don‚Äôt write down a system prompt and find ways to test it. You write down tests and find a system prompt that passes them. It‚Äôs become abundantly clear over the course of 2024 that writing good automated evals for LLM-powered systems is the skill that‚Äôs most needed to build useful applications on top of these models. If you have a strong eval suite you can adopt new models faster, iterate better and build more reliable and useful product features than your competition. Vercel‚Äôs Malte Ubl: When @v0 first came out we were paranoid about protecting the prompt with all kinds of pre and post processing complexity. We completely pivoted to let it rip. A prompt without the evals, models, and especially UX is like getting a broken ASML machine without a manual I‚Äôm still trying to figure out the best patterns for doing this for my own work. Everyone knows that evals are important, but there remains a lack of great guidance for how to best implement them‚ÄîI‚Äôm tracking this under my evals tag. My SVG pelican riding a bicycle benchmark is a pale imitation of what a real eval suite should look like. Apple Intelligence is bad, Apple‚Äôs MLX library is excellent As a Mac user I‚Äôve been feeling a lot better about my choice of platform this year. Last year it felt like my lack of a Linux/Windows machine with an NVIDIA GPU was a huge disadvantage in terms of trying out new models. On paper, a 64GB Mac should be a great machine for running models due to the way the CPU and GPU can share the same memory. In practice, many models are released as model weights and libraries that reward NVIDIA‚Äôs CUDA over other platforms. The llama.cpp ecosystem helped a lot here, but the real breakthrough has been Apple‚Äôs MLX library, ‚Äúan array framework for Apple Silicon‚Äù. It‚Äôs fantastic. Apple‚Äôs mlx-lm Python library supports running a wide range of MLX-compatible models on my Mac, with excellent performance. mlx-community on Hugging Face offers more than 1,000 models that have been converted to the necessary format. Prince Canuma‚Äôs excellent, fast moving mlx-vlm project brings vision LLMs to Apple Silicon as well. I used that recently to run Qwen‚Äôs QvQ. While MLX is a game changer, Apple‚Äôs own ‚ÄúApple Intelligence‚Äù features have mostly been a disappointment. I wrote about their initial announcement in June, and I was optimistic that Apple had focused hard on the subset of LLM applications that preserve user privacy and minimize the chance of users getting mislead by confusing features. Now that those features are rolling out they‚Äôre pretty weak. As an LLM power-user I know what these models are capable of, and Apple‚Äôs LLM features offer a pale imitation of what a frontier LLM can do. Instead we‚Äôre getting notification summaries that misrepresent news headlines and writing assistant tools that I‚Äôve not found useful at all. Genmoji are kind of fun though. The rise of inference-scaling ‚Äúreasoning‚Äù models The most interesting development in the final quarter of 2024 was the introduction of a new shape of LLM, exemplified by OpenAI‚Äôs o1 models‚Äîinitially released as o1-preview and o1-mini on September 12th. One way to think about these models is an extension of the chain-of-thought prompting trick, first explored in the May 2022 paper Large Language Models are Zero-Shot Reasoners. This is that trick where, if you get a model to talk out loud about a problem it‚Äôs solving, you often get a result which the model would not have achieved otherwise. o1 takes this process and further bakes it into the model itself. The details are somewhat obfuscated: o1 models spend ‚Äúreasoning tokens‚Äù thinking through the problem that are not directly visible to the user (though the ChatGPT UI shows a summary of them), then outputs a final result. The biggest innovation here is that it opens up a new way to scale a model: instead of improving model performance purely through additional compute at training time, models can now take on harder problems by spending more compute on inference. The sequel to o1, o3 (they skipped ‚Äúo2‚Äù for European trademark reasons) was announced on 20th December with an impressive result against the ARC-AGI benchmark, albeit one that likely involved more than $1,000,000 of compute time expense! o3 is expected to ship in January. I doubt many people have real-world problems that would benefit from that level of compute expenditure‚ÄîI certainly don‚Äôt!‚Äîbut it appears to be a genuine next step in LLM architecture for taking on much harder problems. OpenAI are not the only game in town here. Google released their first entrant in the category, gemini-2.0-flash-thinking-exp, on December 19th. Alibaba‚Äôs Qwen team released their QwQ model on November 28th‚Äîunder an Apache 2.0 license, and that one I could run on my own machine. They followed that up with a vision reasoning model called QvQ on December 24th, which I also ran locally. DeepSeek made their DeepSeek-R1-Lite-Preview', '<2-hop>\\n\\nWe don‚Äôt yet know how to build GPT-4 Vibes Based Development LLMs are really smart, and also really, really dumb Gullibility is the biggest unsolved problem Code may be the best application The ethics of this space remain diabolically complex My blog in 2023 Here‚Äôs the sequel to this post: Things we learned about LLMs in 2024. Large Language Models In the past 24-36 months, our species has discovered that you can take a GIANT corpus of text, run it through a pile of GPUs, and use it to create a fascinating new kind of software. LLMs can do a lot of things. They can answer questions, summarize documents, translate from one language to another, extract information and even write surprisingly competent code. They can also help you cheat at your homework, generate unlimited streams of fake content and be used for all manner of nefarious purposes. So far, I think they‚Äôre a net positive. I‚Äôve used them on a personal level to improve my productivity (and entertain myself) in all sorts of different ways. I think people who learn how to use them effectively can gain a significant boost to their quality of life. A lot of people are yet to be sold on their value! Some think their negatives outweigh their positives, some think they are all hot air, and some even think they represent an existential threat to humanity. They‚Äôre actually quite easy to build The most surprising thing we‚Äôve learned about LLMs this year is that they‚Äôre actually quite easy to build. Intuitively, one would expect that systems this powerful would take millions of lines of complex code. Instead, it turns out a few hundred lines of Python is genuinely enough to train a basic version! What matters most is the training data. You need a lot of data to make these things work, and the quantity and quality of the training data appears to be the most important factor in how good the resulting model is. If you can gather the right data, and afford to pay for the GPUs to train it, you can build an LLM. A year ago, the only organization that had released a generally useful LLM was OpenAI. We‚Äôve now seen better-than-GPT-3 class models produced by Anthropic, Mistral, Google, Meta, EleutherAI, Stability AI, TII in Abu Dhabi (Falcon), Microsoft Research, xAI, Replit, Baidu and a bunch of other organizations. The training cost (hardware and electricity) is still significant‚Äîinitially millions of dollars, but that seems to have dropped to the tens of thousands already. Microsoft‚Äôs Phi-2 claims to have used ‚Äú14 days on 96 A100 GPUs‚Äù, which works out at around $35,000 using current Lambda pricing. So training an LLM still isn‚Äôt something a hobbyist can afford, but it‚Äôs no longer the sole domain of the super-rich. I like to compare the difficulty of training an LLM to that of building a suspension bridge‚Äînot trivial, but hundreds of countries around the world have figured out how to do it. (Correction: Wikipedia‚Äôs Suspension bridges by country category lists 44 countries). You can run LLMs on your own devices In January of this year, I thought it would be years before I could run a useful LLM on my own computer. GPT-3 and 3.5 were pretty much the only games in town, and I thought that even if the model weights were available it would take a $10,000+ server to run them. Then in February, Meta released Llama. And a few weeks later in March, Georgi Gerganov released code that got it working on a MacBook. I wrote about how Large language models are having their Stable Diffusion moment, and with hindsight that was a very good call! This unleashed a whirlwind of innovation, which was accelerated further in July when Meta released Llama 2‚Äîan improved version which, crucially, included permission for commercial use. Today there are literally thousands of LLMs that can be run locally, on all manner of different devices. I run a bunch of them on my laptop. I run Mistral 7B (a surprisingly great model) on my iPhone. You can install several different apps to get your own, local, completely private LLM. My own LLM project provides a CLI tool for running an array of different models via plugins. You can even run them entirely in your browser using WebAssembly and the latest Chrome! Hobbyists can build their own fine-tuned models I said earlier that building an LLM was still out of reach of hobbyists. That may be true for training from scratch, but fine-tuning one of those models is another matter entirely. There‚Äôs now a fascinating ecosystem of people training their own models on top of these foundations, publishing those models, building fine-tuning datasets and sharing those too. The Hugging Face Open LLM Leaderboard is one place that tracks these. I can‚Äôt even attempt to count them, and any count would be out-of-date within a few hours. The best overall openly licensed LLM at any time is rarely a foundation model: instead, it‚Äôs whichever fine-tuned community model has most recently discovered the best combination of fine-tuning data. This is a huge advantage for open over closed models: the closed, hosted models don‚Äôt have thousands of researchers and hobbyists around the world collaborating and competing to improve them. We don‚Äôt yet know how to build GPT-4 Frustratingly, despite the enormous leaps ahead we‚Äôve had this year, we are yet to see an alternative model that‚Äôs better than GPT-4. OpenAI released GPT-4 in March, though it later turned out we had a sneak peak of it in February when Microsoft used it as part of the new Bing. This may well change in the next few weeks: Google‚Äôs Gemini Ultra has big claims, but isn‚Äôt yet available for us to try out. The team behind Mistral are working to beat GPT-4 as well, and their track record is already extremely strong considering their first public model only came out in September, and they‚Äôve released two significant improvements since then. Still,']",
                  "The main problems with LLMs, as highlighted in the context, include their tendency to hallucinate‚Äîimagine and generate information that doesn‚Äôt correspond to reality‚Äîand their inherent unreliability. These issues make them controversial and sometimes unreliable tools, especially for factual or critical applications.\n\nTo make LLMs more useful in the Anthropic way, the focus is on critical evaluation and mitigation of these problems. This involves developing better criticism and understanding of their limitations, and finding ways to improve their reliability. For example, while code generation is somewhat less problematic because generated code can be tested and refined through execution, there is a need for similar validation methods for natural language outputs‚Äîlike an equivalent of Code Interpreter for fact-checking.\n\nOverall, making LLMs useful in the Anthropic way requires ongoing scrutiny, responsible use, education, and the development of techniques that help users work effectively with these inherently unreliable yet powerful tools.",
                  "Anthropic is one of the organizations that has produced better-than-GPT-3 class large language models (LLMs). A big problem with LLMs is gullibility‚Äîthey believe anything you tell them, which makes it hard for them to distinguish truth from fiction. This gullibility leads to issues like prompt injection and unreliable decision-making. According to Anthropic‚Äôs Amanda Askell, the key to making LLMs more useful is having strong automated evaluation (eval) suites. Instead of just writing system prompts and testing them, you should write tests first and then create prompts that pass those tests. Good evals help you adopt new models faster, iterate better, and build more reliable and useful product features.",
                  "multi_hop_specific_query_synthesizer"
                ],
                [
                  "10",
                  "How did Meta's Llama 3.3 70B utilize synthetic data in its fine-tuning, and what does its ability to run on a personal laptop reveal about recent advances in large language model efficiency?",
                  "['I can now run a GPT-4 class model on my laptop talks about running Meta‚Äôs Llama 3.3 70B (released in December)\\n\\nThis remains astonishing to me. I thought a model with the capabilities and output quality of GPT-4 needed a datacenter class server with one or more $40,000+ GPUs.\\n\\nThese models take up enough of my 64GB of RAM that I don‚Äôt run them often‚Äîthey don‚Äôt leave much room for anything else.\\n\\nThe fact that they run at all is a testament to the incredible training and inference performance gains that we‚Äôve figured out over the past year. It turns out there was a lot of low-hanging fruit to be harvested in terms of model efficiency. I expect there‚Äôs still more to come.', 'Training a GPT-4 beating model was a huge deal in 2023. In 2024 it‚Äôs an achievement that isn‚Äôt even particularly notable, though I personally still celebrate any time a new organization joins that list.\\n\\nSome of those GPT-4 models run on my laptop\\n\\nMy personal laptop is a 64GB M2 MacBook Pro from 2023. It‚Äôs a powerful machine, but it‚Äôs also nearly two years old now‚Äîand crucially it‚Äôs the same laptop I‚Äôve been using ever since I first ran an LLM on my computer back in March 2023 (see Large language models are having their Stable Diffusion moment).\\n\\nThat same laptop that could just about run a GPT-3-class model in March last year has now run multiple GPT-4 class models! Some of my notes on that:\\n\\nQwen2.5-Coder-32B is an LLM that can code well that runs on my Mac talks about Qwen2.5-Coder-32B in November‚Äîan Apache 2.0 licensed model!\\n\\nI can now run a GPT-4 class model on my laptop talks about running Meta‚Äôs Llama 3.3 70B (released in December)', 'Another common technique is to use larger models to help create training data for their smaller, cheaper alternatives‚Äîa trick used by an increasing number of labs. DeepSeek v3 used ‚Äúreasoning‚Äù data created by DeepSeek-R1. Meta‚Äôs Llama 3.3 70B fine-tuning used over 25M synthetically generated examples.\\n\\nCareful design of the training data that goes into an LLM appears to be the entire game for creating these models. The days of just grabbing a full scrape of the web and indiscriminately dumping it into a training run are long gone.\\n\\nLLMs somehow got even harder to use\\n\\nA drum I‚Äôve been banging for a while is that LLMs are power-user tools‚Äîthey‚Äôre chainsaws disguised as kitchen knives. They look deceptively simple to use‚Äîhow hard can it be to type messages to a chatbot?‚Äîbut in reality you need a huge depth of both understanding and experience to make the most of them and avoid their many pitfalls.\\n\\nIf anything, this problem got worse in 2024.']",
                  "['<1-hop>\\n\\nof the best descriptions I‚Äôve seen of this comes from the Phi-4 technical report, which included this: Synthetic data as a substantial component of pretraining is becoming increasingly common, and the Phi series of models has consistently emphasized the importance of synthetic data. Rather than serving as a cheap substitute for organic data, synthetic data has several direct advantages over organic data. Structured and Gradual Learning. In organic datasets, the relationship between tokens is often complex and indirect. Many reasoning steps may be required to connect the current token to the next, making it challenging for the model to learn effectively from next-token prediction. By contrast, each token generated by a language model is by definition predicted by the preceding tokens, making it easier for a model to follow the resulting reasoning patterns. Another common technique is to use larger models to help create training data for their smaller, cheaper alternatives‚Äîa trick used by an increasing number of labs. DeepSeek v3 used ‚Äúreasoning‚Äù data created by DeepSeek-R1. Meta‚Äôs Llama 3.3 70B fine-tuning used over 25M synthetically generated examples. Careful design of the training data that goes into an LLM appears to be the entire game for creating these models. The days of just grabbing a full scrape of the web and indiscriminately dumping it into a training run are long gone. LLMs somehow got even harder to use A drum I‚Äôve been banging for a while is that LLMs are power-user tools‚Äîthey‚Äôre chainsaws disguised as kitchen knives. They look deceptively simple to use‚Äîhow hard can it be to type messages to a chatbot?‚Äîbut in reality you need a huge depth of both understanding and experience to make the most of them and avoid their many pitfalls. If anything, this problem got worse in 2024. We‚Äôve built computer systems you can talk to in human language, that will answer your questions and usually get them right! ... depending on the question, and how you ask it, and whether it‚Äôs accurately reflected in the undocumented and secret training set. The number of available systems has exploded. Different systems have different tools they can apply to your problems‚Äîlike Python and JavaScript and web search and image generation and maybe even database lookups... so you‚Äôd better understand what those tools are, what they can do and how to tell if the LLM used them or not. Did you know ChatGPT has two entirely different ways of running Python now? Want to build a Claude Artifact that talks to an external API? You‚Äôd better understand CSP and CORS HTTP headers first. The models may have got more capable, but most of the limitations remained the same. OpenAI‚Äôs o1 may finally be able to (mostly) count the Rs in strawberry, but its abilities are still limited by its nature as an LLM and the constraints placed on it by the harness it‚Äôs running in. o1 can‚Äôt run web searches or use Code Interpreter, but GPT-4o can‚Äîboth in that same ChatGPT UI. (o1 will pretend to do those things if you ask it to, a regression to the URL hallucinations bug from early 2023). What are we doing about this? Not much. Most users are thrown in at the deep end. The default LLM chat UI is like taking brand new computer users, dropping them into a Linux terminal and expecting them to figure it all out. Meanwhile, it‚Äôs increasingly common for end users to develop wildly inaccurate mental models of how these things work and what they are capable of. I‚Äôve seen so many examples of people trying to win an argument with a screenshot from ChatGPT‚Äîan inherently ludicrous proposition, given the inherent unreliability of these models crossed with the fact that you can get them to say anything if you prompt them right. There‚Äôs a flipside to this too: a lot of better informed people have sworn off LLMs entirely because they can‚Äôt see how anyone could benefit from a tool with so many flaws. The key skill in getting the most out of LLMs is learning to work with tech that is both inherently unreliable and incredibly powerful at the same time. This is a decidedly non-obvious skill to acquire! There is so much space for helpful education content here, but we need to do do a lot better than outsourcing it all to AI grifters with bombastic Twitter threads. Knowledge is incredibly unevenly distributed Most people have heard of ChatGPT by now. How many have heard of Claude? The knowledge gap between the people who actively follow this stuff and the 99% of the population who do not is vast. The pace of change doesn‚Äôt help either. In just the past month we‚Äôve seen general availability of live interfaces where you can point your phone‚Äôs camera at something and talk about it with your voice... and optionally have it pretend to be Santa. Most self-certified nerds haven‚Äôt even tried that yet. Given the ongoing (and potential) impact on society that this technology has, I don‚Äôt think the size of this gap is healthy. I‚Äôd like to see a lot more effort put into improving this. LLMs need better criticism A lot of people absolutely hate this stuff. In some of the spaces I hang out (Mastodon, Bluesky, Lobste.rs, even Hacker News on occasion) even suggesting that ‚ÄúLLMs are useful‚Äù can be enough to kick off a huge fight. I get it. There are plenty of reasons to dislike this technology‚Äîthe environmental impact, the (lack of) ethics of the training data, the lack of reliability, the negative applications, the potential impact on people‚Äôs jobs. LLMs absolutely warrant criticism. We need to be talking through these problems, finding ways to mitigate them and helping people learn how to use these tools responsibly in ways where the positive applications outweigh the negative. I like people who are skeptical of this stuff. The hype has been deafening for more than two years now, and there are enormous quantities of snake oil and misinformation out there. A lot', '<2-hop>\\n\\nThe rise of inference-scaling ‚Äúreasoning‚Äù models Was the best currently available LLM trained in China for less than $6m? The environmental impact got better The environmental impact got much, much worse The year of slop Synthetic training data works great LLMs somehow got even harder to use Knowledge is incredibly unevenly distributed LLMs need better criticism Everything tagged ‚Äúllms‚Äù on my blog in 2024 The GPT-4 barrier was comprehensively broken In my December 2023 review I wrote about how We don‚Äôt yet know how to build GPT-4‚ÄîOpenAI‚Äôs best model was almost a year old at that point, yet no other AI lab had produced anything better. What did OpenAI know that the rest of us didn‚Äôt? I‚Äôm relieved that this has changed completely in the past twelve months. 18 organizations now have models on the Chatbot Arena Leaderboard that rank higher than the original GPT-4 from March 2023 (GPT-4-0314 on the board)‚Äî70 models in total. Screenshot of a comparison table showing AI model rankings. Table headers: Rank (UB), Rank (StyleCtrl), Model, Arena Score, 95% CI, Votes, Organization, License. Shows 12 models including GLM-4-0520, Llama-3-70B-Instruct, Gemini-1.5-Flash-8B-Exp-0827, with rankings, scores, and licensing details. Models range from rank 52-69 with Arena scores between 1186-1207. The earliest of those was Google‚Äôs Gemini 1.5 Pro, released in February. In addition to producing GPT-4 level outputs, it introduced several brand new capabilities to the field‚Äîmost notably its 1 million (and then later 2 million) token input context length, and the ability to input video. I wrote about this at the time in The killer app of Gemini Pro 1.5 is video, which earned me a short appearance as a talking head in the Google I/O opening keynote in May. Gemini 1.5 Pro also illustrated one of the key themes of 2024: increased context lengths. Last year most models accepted 4,096 or 8,192 tokens, with the notable exception of Claude 2.1 which accepted 200,000. Today every serious provider has a 100,000+ token model, and Google‚Äôs Gemini series accepts up to 2 million. Longer inputs dramatically increase the scope of problems that can be solved with an LLM: you can now throw in an entire book and ask questions about its contents, but more importantly you can feed in a lot of example code to help the model correctly solve a coding problem. LLM use-cases that involve long inputs are far more interesting to me than short prompts that rely purely on the information already baked into the model weights. Many of my tools were built using this pattern. Getting back to models that beat GPT-4: Anthropic‚Äôs Claude 3 series launched in March, and Claude 3 Opus quickly became my new favourite daily-driver. They upped the ante even more in June with the launch of Claude 3.5 Sonnet‚Äîa model that is still my favourite six months later (though it got a significant upgrade on October 22, confusingly keeping the same 3.5 version number. Anthropic fans have since taken to calling it Claude 3.6). Then there‚Äôs the rest. If you browse the Chatbot Arena leaderboard today‚Äîstill the most useful single place to get a vibes-based evaluation of models‚Äîyou‚Äôll see that GPT-4-0314 has fallen to around 70th place. The 18 organizations with higher scoring models are Google, OpenAI, Alibaba, Anthropic, Meta, Reka AI, 01 AI, Amazon, Cohere, DeepSeek, Nvidia, Mistral, NexusFlow, Zhipu AI, xAI, AI21 Labs, Princeton and Tencent. Training a GPT-4 beating model was a huge deal in 2023. In 2024 it‚Äôs an achievement that isn‚Äôt even particularly notable, though I personally still celebrate any time a new organization joins that list. Some of those GPT-4 models run on my laptop My personal laptop is a 64GB M2 MacBook Pro from 2023. It‚Äôs a powerful machine, but it‚Äôs also nearly two years old now‚Äîand crucially it‚Äôs the same laptop I‚Äôve been using ever since I first ran an LLM on my computer back in March 2023 (see Large language models are having their Stable Diffusion moment). That same laptop that could just about run a GPT-3-class model in March last year has now run multiple GPT-4 class models! Some of my notes on that: Qwen2.5-Coder-32B is an LLM that can code well that runs on my Mac talks about Qwen2.5-Coder-32B in November‚Äîan Apache 2.0 licensed model! I can now run a GPT-4 class model on my laptop talks about running Meta‚Äôs Llama 3.3 70B (released in December) This remains astonishing to me. I thought a model with the capabilities and output quality of GPT-4 needed a datacenter class server with one or more $40,000+ GPUs. These models take up enough of my 64GB of RAM that I don‚Äôt run them often‚Äîthey don‚Äôt leave much room for anything else. The fact that they run at all is a testament to the incredible training and inference performance gains that we‚Äôve figured out over the past year. It turns out there was a lot of low-hanging fruit to be harvested in terms of model efficiency. I expect there‚Äôs still more to come. Meta‚Äôs Llama 3.2 models deserve a special mention. They may not be GPT-4 class, but at 1B and 3B sizes they punch massively above their weight. I run Llama 3.2 3B on my iPhone using the free MLC Chat iOS app and it‚Äôs a shockingly capable model for its tiny (<2GB) size. Try firing it up and asking it for ‚Äúa plot outline of a Netflix Christmas movie where a data journalist falls in love with a local ceramacist‚Äù. Here‚Äôs what I got, at a respectable 20 tokens per second: MLC Chat: Llama - [System] Ready to chat. a plot outline of a Netflix Christmas movie where a data journalist falls in love with a local ceramacist. Show as Markdown is turned on. Here\\'s a plot outline for a Netflix Christmas movie: Title: \"Love in the Clay\" Plot Outline: We meet our protagonist, JESSICA, a data journalist who has just returned to her hometown of Willow Creek, a small, charming town nestled in the snow-covered mountains. She\\'s back to work']",
                  "Meta's Llama 3.3 70B utilized over 25 million synthetically generated examples in its fine-tuning process. This approach of using large amounts of carefully designed synthetic data demonstrates how recent advances in large language model efficiency allow models to be effectively fine-tuned with less reliance on massive, indiscriminate web scrapes. The ability to run such a large model on a personal laptop further reveals significant progress in optimizing model training and inference performance. These developments indicate that recent innovations have made large language models more efficient, requiring less specialized hardware and enabling more accessible use, even on everyday personal computing devices.",
                  "Meta's Llama 3.3 70B fine-tuning process incorporated over 25 million synthetically generated examples, highlighting the growing importance and advantages of synthetic data in training large language models. This approach allows for more structured and gradual learning compared to organic datasets. Additionally, the fact that Llama 3.3 70B‚Äîa model with GPT-4 class capabilities‚Äîcan now run on a personal laptop with 64GB of RAM demonstrates significant recent advances in model efficiency and inference performance. These improvements have made it possible to operate highly capable models outside of datacenter-class servers, reflecting major progress in the field.",
                  "multi_hop_specific_query_synthesizer"
                ],
                [
                  "11",
                  "What are some recent advanced features introduced in ChatGPT, and how do they compare to similar capabilities in competing models like Google Gemini?",
                  "['The most recent twist, again from December (December was a lot) is live video. ChatGPT voice mode now provides the option to share your camera feed with the model and talk about what you can see in real time. Google Gemini have a preview of the same feature, which they managed to ship the day before ChatGPT did.\\n\\nThese abilities are just a few weeks old at this point, and I don‚Äôt think their impact has been fully felt yet. If you haven‚Äôt tried them out yet you really should.\\n\\nBoth Gemini and OpenAI offer API access to these features as well. OpenAI started with a WebSocket API that was quite challenging to use, but in December they announced a new WebRTC API which is much easier to get started with. Building a web app that a user can talk to via voice is easy now!\\n\\nPrompt driven app generation is a commodity already\\n\\nThis was possible with GPT-4 in 2023, but the value it provides became evident in 2024.', 'Even more fun: Advanced Voice mode can do accents! Here‚Äôs what happened when I told it I need you to pretend to be a California brown pelican with a very thick Russian accent, but you talk to me exclusively in Spanish.\\n\\nOpenAI aren‚Äôt the only group with a multi-modal audio model. Google‚Äôs Gemini also accepts audio input, and the Google Gemini apps can speak in a similar way to ChatGPT now. Amazon also pre-announced voice mode for Amazon Nova, but that‚Äôs meant to roll out in Q1 of 2025.\\n\\nGoogle‚Äôs NotebookLM, released in September, took audio output to a new level by producing spookily realistic conversations between two ‚Äúpodcast hosts‚Äù about anything you fed into their tool. They later added custom instructions, so naturally I turned them into pelicans:', 'I‚Äôm relieved that this has changed completely in the past twelve months. 18 organizations now have models on the Chatbot Arena Leaderboard that rank higher than the original GPT-4 from March 2023 (GPT-4-0314 on the board)‚Äî70 models in total.\\n\\nScreenshot of a comparison table showing AI model rankings. Table headers: Rank (UB), Rank (StyleCtrl), Model, Arena Score, 95% CI, Votes, Organization, License. Shows 12 models including GLM-4-0520, Llama-3-70B-Instruct, Gemini-1.5-Flash-8B-Exp-0827, with rankings, scores, and licensing details. Models range from rank 52-69 with Arena scores between 1186-1207.\\n\\nThe earliest of those was Google‚Äôs Gemini 1.5 Pro, released in February. In addition to producing GPT-4 level outputs, it introduced several brand new capabilities to the field‚Äîmost notably its 1 million (and then later 2 million) token input context length, and the ability to input video.']",
                  "['<1-hop>\\n\\nof the best descriptions I‚Äôve seen of this comes from the Phi-4 technical report, which included this: Synthetic data as a substantial component of pretraining is becoming increasingly common, and the Phi series of models has consistently emphasized the importance of synthetic data. Rather than serving as a cheap substitute for organic data, synthetic data has several direct advantages over organic data. Structured and Gradual Learning. In organic datasets, the relationship between tokens is often complex and indirect. Many reasoning steps may be required to connect the current token to the next, making it challenging for the model to learn effectively from next-token prediction. By contrast, each token generated by a language model is by definition predicted by the preceding tokens, making it easier for a model to follow the resulting reasoning patterns. Another common technique is to use larger models to help create training data for their smaller, cheaper alternatives‚Äîa trick used by an increasing number of labs. DeepSeek v3 used ‚Äúreasoning‚Äù data created by DeepSeek-R1. Meta‚Äôs Llama 3.3 70B fine-tuning used over 25M synthetically generated examples. Careful design of the training data that goes into an LLM appears to be the entire game for creating these models. The days of just grabbing a full scrape of the web and indiscriminately dumping it into a training run are long gone. LLMs somehow got even harder to use A drum I‚Äôve been banging for a while is that LLMs are power-user tools‚Äîthey‚Äôre chainsaws disguised as kitchen knives. They look deceptively simple to use‚Äîhow hard can it be to type messages to a chatbot?‚Äîbut in reality you need a huge depth of both understanding and experience to make the most of them and avoid their many pitfalls. If anything, this problem got worse in 2024. We‚Äôve built computer systems you can talk to in human language, that will answer your questions and usually get them right! ... depending on the question, and how you ask it, and whether it‚Äôs accurately reflected in the undocumented and secret training set. The number of available systems has exploded. Different systems have different tools they can apply to your problems‚Äîlike Python and JavaScript and web search and image generation and maybe even database lookups... so you‚Äôd better understand what those tools are, what they can do and how to tell if the LLM used them or not. Did you know ChatGPT has two entirely different ways of running Python now? Want to build a Claude Artifact that talks to an external API? You‚Äôd better understand CSP and CORS HTTP headers first. The models may have got more capable, but most of the limitations remained the same. OpenAI‚Äôs o1 may finally be able to (mostly) count the Rs in strawberry, but its abilities are still limited by its nature as an LLM and the constraints placed on it by the harness it‚Äôs running in. o1 can‚Äôt run web searches or use Code Interpreter, but GPT-4o can‚Äîboth in that same ChatGPT UI. (o1 will pretend to do those things if you ask it to, a regression to the URL hallucinations bug from early 2023). What are we doing about this? Not much. Most users are thrown in at the deep end. The default LLM chat UI is like taking brand new computer users, dropping them into a Linux terminal and expecting them to figure it all out. Meanwhile, it‚Äôs increasingly common for end users to develop wildly inaccurate mental models of how these things work and what they are capable of. I‚Äôve seen so many examples of people trying to win an argument with a screenshot from ChatGPT‚Äîan inherently ludicrous proposition, given the inherent unreliability of these models crossed with the fact that you can get them to say anything if you prompt them right. There‚Äôs a flipside to this too: a lot of better informed people have sworn off LLMs entirely because they can‚Äôt see how anyone could benefit from a tool with so many flaws. The key skill in getting the most out of LLMs is learning to work with tech that is both inherently unreliable and incredibly powerful at the same time. This is a decidedly non-obvious skill to acquire! There is so much space for helpful education content here, but we need to do do a lot better than outsourcing it all to AI grifters with bombastic Twitter threads. Knowledge is incredibly unevenly distributed Most people have heard of ChatGPT by now. How many have heard of Claude? The knowledge gap between the people who actively follow this stuff and the 99% of the population who do not is vast. The pace of change doesn‚Äôt help either. In just the past month we‚Äôve seen general availability of live interfaces where you can point your phone‚Äôs camera at something and talk about it with your voice... and optionally have it pretend to be Santa. Most self-certified nerds haven‚Äôt even tried that yet. Given the ongoing (and potential) impact on society that this technology has, I don‚Äôt think the size of this gap is healthy. I‚Äôd like to see a lot more effort put into improving this. LLMs need better criticism A lot of people absolutely hate this stuff. In some of the spaces I hang out (Mastodon, Bluesky, Lobste.rs, even Hacker News on occasion) even suggesting that ‚ÄúLLMs are useful‚Äù can be enough to kick off a huge fight. I get it. There are plenty of reasons to dislike this technology‚Äîthe environmental impact, the (lack of) ethics of the training data, the lack of reliability, the negative applications, the potential impact on people‚Äôs jobs. LLMs absolutely warrant criticism. We need to be talking through these problems, finding ways to mitigate them and helping people learn how to use these tools responsibly in ways where the positive applications outweigh the negative. I like people who are skeptical of this stuff. The hype has been deafening for more than two years now, and there are enormous quantities of snake oil and misinformation out there. A lot', '<2-hop>\\n\\nyou talk to me exclusively in Spanish. OpenAI aren‚Äôt the only group with a multi-modal audio model. Google‚Äôs Gemini also accepts audio input, and the Google Gemini apps can speak in a similar way to ChatGPT now. Amazon also pre-announced voice mode for Amazon Nova, but that‚Äôs meant to roll out in Q1 of 2025. Google‚Äôs NotebookLM, released in September, took audio output to a new level by producing spookily realistic conversations between two ‚Äúpodcast hosts‚Äù about anything you fed into their tool. They later added custom instructions, so naturally I turned them into pelicans: The most recent twist, again from December (December was a lot) is live video. ChatGPT voice mode now provides the option to share your camera feed with the model and talk about what you can see in real time. Google Gemini have a preview of the same feature, which they managed to ship the day before ChatGPT did. These abilities are just a few weeks old at this point, and I don‚Äôt think their impact has been fully felt yet. If you haven‚Äôt tried them out yet you really should. Both Gemini and OpenAI offer API access to these features as well. OpenAI started with a WebSocket API that was quite challenging to use, but in December they announced a new WebRTC API which is much easier to get started with. Building a web app that a user can talk to via voice is easy now! Prompt driven app generation is a commodity already This was possible with GPT-4 in 2023, but the value it provides became evident in 2024. We already knew LLMs were spookily good at writing code. If you prompt them right, it turns out they can build you a full interactive application using HTML, CSS and JavaScript (and tools like React if you wire up some extra supporting build mechanisms)‚Äîoften in a single prompt. Anthropic kicked this idea into high gear when they released Claude Artifacts, a groundbreaking new feature that was initially slightly lost in the noise due to being described half way through their announcement of the incredible Claude 3.5 Sonnet. With Artifacts, Claude can write you an on-demand interactive application and then let you use it directly inside the Claude interface. Here‚Äôs my Extract URLs app, entirely generated by Claude: Extract URLs tool. Content pasted. URLs extracted. Shows a list of extracted URLs. I‚Äôve found myself using this a lot. I noticed how much I was relying on it in October and wrote Everything I built with Claude Artifacts this week, describing 14 little tools I had put together in a seven day period. Since then, a whole bunch of other teams have built similar systems. GitHub announced their version of this‚ÄîGitHub Spark‚Äîin October. Mistral Chat added it as a feature called Canvas in November. Steve Krouse from Val Town built a version of it against Cerebras, showcasing how a 2,000 token/second LLM can iterate on an application with changes visible in less than a second. Then in December, the Chatbot Arena team introduced a whole new leaderboard for this feature, driven by users building the same interactive app twice with two different models and voting on the answer. Hard to come up with a more convincing argument that this feature is now a commodity that can be effectively implemented against all of the leading models. I‚Äôve been tinkering with a version of this myself for my Datasette project, with the goal of letting users use prompts to build and iterate on custom widgets and data visualizations against their own data. I also figured out a similar pattern for writing one-shot Python programs, enabled by uv. This prompt-driven custom interface feature is so powerful and easy to build (once you‚Äôve figured out the gnarly details of browser sandboxing) that I expect it to show up as a feature in a wide range of products in 2025. Universal access to the best models lasted for just a few short months For a few short months this year all three of the best available models‚ÄîGPT-4o, Claude 3.5 Sonnet and Gemini 1.5 Pro‚Äîwere freely available to most of the world. OpenAI made GPT-4o free for all users in May, and Claude 3.5 Sonnet was freely available from its launch in June. This was a momentus change, because for the previous year free users had mostly been restricted to GPT-3.5 level models, meaning new users got a very inaccurate mental model of what a capable LLM could actually do. That era appears to have ended, likely permanently, with OpenAI‚Äôs launch of ChatGPT Pro. This $200/month subscription service is the only way to access their most capable model, o1 Pro. Since the trick behind the o1 series (and the future models it will undoubtedly inspire) is to expend more compute time to get better results, I don‚Äôt think those days of free access to the best available models are likely to return. ‚ÄúAgents‚Äù still haven‚Äôt really happened yet I find the term ‚Äúagents‚Äù extremely frustrating. It lacks a single, clear and widely understood meaning... but the people who use the term never seem to acknowledge that. If you tell me that you are building ‚Äúagents‚Äù, you‚Äôve conveyed almost no information to me at all. Without reading your mind I have no way of telling which of the dozens of possible definitions you are talking about. The two main categories I see are people who think AI agents are obviously things that go and act on your behalf‚Äîthe travel agent model‚Äîand people who think in terms of LLMs that have been given access to tools which they can run in a loop as part of solving a problem. The term ‚Äúautonomy‚Äù is often thrown into the mix too, again without including a clear definition. (I also collected 211 definitions on Twitter a few months ago‚Äîhere they are in Datasette Lite‚Äîand had gemini-exp-1206 attempt to summarize them.) Whatever the term may mean, agents still have that feeling of perpetually ‚Äúcoming soon‚Äù. Terminology aside, I remain']",
                  "Recent advanced features introduced in ChatGPT include live video sharing, where the voice mode now allows users to share their camera feed and interact with the model in real time. Additionally, ChatGPT has enhanced its voice capabilities to include accents and multi-modal audio input, such as understanding and generating speech in different accents and languages. OpenAI also launched a new WebRTC API in December, making it easier to build web applications that incorporate voice interactions.\n\nIn comparison, Google Gemini has introduced similar capabilities, including a preview of live video sharing, which they managed to ship just a day before ChatGPT. Gemini also accepts audio input and can produce speech output comparable to ChatGPT‚Äôs voice mode. Furthermore, Google‚Äôs Gemini has extended its capabilities with a large input context length (up to 2 million tokens) and the ability to input video, aligning with the multi-modal focus seen in ChatGPT‚Äôs recent updates.\n\nOverall, both models now support multi-modal interactions‚Äîvideo, audio, and speech‚Äîwith Gemini having a slight edge in early deployment timing and context length capabilities. ChatGPT has made significant strides in ease of use and accessibility, especially with the new WebRTC API, making voice and video features more practical for developers and users.",
                  "Recent advanced features introduced in ChatGPT include a voice mode that allows users to share their camera feed and have real-time conversations about what they see, as well as the ability to interact via voice. These features enable live video and audio interactions with the model. Google Gemini has introduced similar capabilities, such as accepting audio input and providing spoken responses, and also previewed live video features around the same time as ChatGPT. Both OpenAI and Google now offer API access to these multi-modal features, making it easier for developers to build applications that leverage voice and video interactions. While Amazon has announced a voice mode for Amazon Nova, it is scheduled for release in 2025. Overall, ChatGPT and Google Gemini are closely matched in rolling out these advanced multi-modal features, with both platforms providing users and developers with new ways to interact beyond text.",
                  "multi_hop_specific_query_synthesizer"
                ]
              ],
              "shape": {
                "columns": 6,
                "rows": 12
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_input</th>\n",
              "      <th>retrieved_contexts</th>\n",
              "      <th>reference_contexts</th>\n",
              "      <th>response</th>\n",
              "      <th>reference</th>\n",
              "      <th>synthesizer_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Which organizations, including Stability AI, h...</td>\n",
              "      <td>[If you can gather the right data, and afford ...</td>\n",
              "      <td>[We don‚Äôt yet know how to build GPT-4 Vibes Ba...</td>\n",
              "      <td>Organizations that have produced better-than-G...</td>\n",
              "      <td>Organizations that have produced better-than-G...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How does the use of Python by large language m...</td>\n",
              "      <td>[It‚Äôs still astonishing to me how effective th...</td>\n",
              "      <td>[I‚Äôm surprised that no-one has beaten the now ...</td>\n",
              "      <td>The use of Python by large language models (LL...</td>\n",
              "      <td>According to the context, writing code is one ...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Wut is AI?</td>\n",
              "      <td>[A lot of people are excited about AI agents‚Äîa...</td>\n",
              "      <td>[Simon Willison‚Äôs Weblog Subscribe Stuff we fi...</td>\n",
              "      <td>Based on the provided context, AI refers to sy...</td>\n",
              "      <td>AI refers to Large Language Models, which are ...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Whaat is the signifficance of OpenAI in the co...</td>\n",
              "      <td>[Law is not ethics. Is it OK to train models o...</td>\n",
              "      <td>[Microsoft over this issue. The 69 page PDF is...</td>\n",
              "      <td>According to the blog's 2023 tag cloud and tra...</td>\n",
              "      <td>According to the blog's 2023 tag cloud, 'opena...</td>\n",
              "      <td>single_hop_specifc_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Considering the applications of LLMs such as c...</td>\n",
              "      <td>[It‚Äôs still astonishing to me how effective th...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nWe don‚Äôt yet know how to build GPT...</td>\n",
              "      <td>The rise of LLMs in software engineering and p...</td>\n",
              "      <td>The rise of LLMs has significantly impacted so...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>How have large language models impacted softwa...</td>\n",
              "      <td>[It‚Äôs still astonishing to me how effective th...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nWe don‚Äôt yet know how to build GPT...</td>\n",
              "      <td>Large language models have significantly impac...</td>\n",
              "      <td>Large language models (LLMs) have significantl...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>How does the use of synthetic training data pr...</td>\n",
              "      <td>[One of the best descriptions I‚Äôve seen of thi...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nThe rise of inference-scaling ‚Äúrea...</td>\n",
              "      <td>The use of synthetic training data offers seve...</td>\n",
              "      <td>Synthetic training data offers several direct ...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>How have improvements in LLM efficiency over t...</td>\n",
              "      <td>[Simon Willison‚Äôs Weblog\\n\\nSubscribe\\n\\nThing...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nThe rise of inference-scaling ‚Äúrea...</td>\n",
              "      <td>Improvements in LLM efficiency over the past y...</td>\n",
              "      <td>Improvements in LLM efficiency over the past y...</td>\n",
              "      <td>multi_hop_abstract_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>How has ChatGPT been discussed in relation to ...</td>\n",
              "      <td>[Law is not ethics. Is it OK to train models o...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nof very bad decisions are being ma...</td>\n",
              "      <td>ChatGPT has been discussed extensively in rela...</td>\n",
              "      <td>ChatGPT has been a recurring topic in blog pos...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Anthropic make LLMs, but what is problem with ...</td>\n",
              "      <td>[LLMs need better criticism\\n\\nA lot of people...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nskeptical as to their utility base...</td>\n",
              "      <td>The main problems with LLMs, as highlighted in...</td>\n",
              "      <td>Anthropic is one of the organizations that has...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>How did Meta's Llama 3.3 70B utilize synthetic...</td>\n",
              "      <td>[I can now run a GPT-4 class model on my lapto...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nof the best descriptions I‚Äôve seen...</td>\n",
              "      <td>Meta's Llama 3.3 70B utilized over 25 million ...</td>\n",
              "      <td>Meta's Llama 3.3 70B fine-tuning process incor...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>What are some recent advanced features introdu...</td>\n",
              "      <td>[The most recent twist, again from December (D...</td>\n",
              "      <td>[&lt;1-hop&gt;\\n\\nof the best descriptions I‚Äôve seen...</td>\n",
              "      <td>Recent advanced features introduced in ChatGPT...</td>\n",
              "      <td>Recent advanced features introduced in ChatGPT...</td>\n",
              "      <td>multi_hop_specific_query_synthesizer</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           user_input  \\\n",
              "0   Which organizations, including Stability AI, h...   \n",
              "1   How does the use of Python by large language m...   \n",
              "2                                          Wut is AI?   \n",
              "3   Whaat is the signifficance of OpenAI in the co...   \n",
              "4   Considering the applications of LLMs such as c...   \n",
              "5   How have large language models impacted softwa...   \n",
              "6   How does the use of synthetic training data pr...   \n",
              "7   How have improvements in LLM efficiency over t...   \n",
              "8   How has ChatGPT been discussed in relation to ...   \n",
              "9   Anthropic make LLMs, but what is problem with ...   \n",
              "10  How did Meta's Llama 3.3 70B utilize synthetic...   \n",
              "11  What are some recent advanced features introdu...   \n",
              "\n",
              "                                   retrieved_contexts  \\\n",
              "0   [If you can gather the right data, and afford ...   \n",
              "1   [It‚Äôs still astonishing to me how effective th...   \n",
              "2   [A lot of people are excited about AI agents‚Äîa...   \n",
              "3   [Law is not ethics. Is it OK to train models o...   \n",
              "4   [It‚Äôs still astonishing to me how effective th...   \n",
              "5   [It‚Äôs still astonishing to me how effective th...   \n",
              "6   [One of the best descriptions I‚Äôve seen of thi...   \n",
              "7   [Simon Willison‚Äôs Weblog\\n\\nSubscribe\\n\\nThing...   \n",
              "8   [Law is not ethics. Is it OK to train models o...   \n",
              "9   [LLMs need better criticism\\n\\nA lot of people...   \n",
              "10  [I can now run a GPT-4 class model on my lapto...   \n",
              "11  [The most recent twist, again from December (D...   \n",
              "\n",
              "                                   reference_contexts  \\\n",
              "0   [We don‚Äôt yet know how to build GPT-4 Vibes Ba...   \n",
              "1   [I‚Äôm surprised that no-one has beaten the now ...   \n",
              "2   [Simon Willison‚Äôs Weblog Subscribe Stuff we fi...   \n",
              "3   [Microsoft over this issue. The 69 page PDF is...   \n",
              "4   [<1-hop>\\n\\nWe don‚Äôt yet know how to build GPT...   \n",
              "5   [<1-hop>\\n\\nWe don‚Äôt yet know how to build GPT...   \n",
              "6   [<1-hop>\\n\\nThe rise of inference-scaling ‚Äúrea...   \n",
              "7   [<1-hop>\\n\\nThe rise of inference-scaling ‚Äúrea...   \n",
              "8   [<1-hop>\\n\\nof very bad decisions are being ma...   \n",
              "9   [<1-hop>\\n\\nskeptical as to their utility base...   \n",
              "10  [<1-hop>\\n\\nof the best descriptions I‚Äôve seen...   \n",
              "11  [<1-hop>\\n\\nof the best descriptions I‚Äôve seen...   \n",
              "\n",
              "                                             response  \\\n",
              "0   Organizations that have produced better-than-G...   \n",
              "1   The use of Python by large language models (LL...   \n",
              "2   Based on the provided context, AI refers to sy...   \n",
              "3   According to the blog's 2023 tag cloud and tra...   \n",
              "4   The rise of LLMs in software engineering and p...   \n",
              "5   Large language models have significantly impac...   \n",
              "6   The use of synthetic training data offers seve...   \n",
              "7   Improvements in LLM efficiency over the past y...   \n",
              "8   ChatGPT has been discussed extensively in rela...   \n",
              "9   The main problems with LLMs, as highlighted in...   \n",
              "10  Meta's Llama 3.3 70B utilized over 25 million ...   \n",
              "11  Recent advanced features introduced in ChatGPT...   \n",
              "\n",
              "                                            reference  \\\n",
              "0   Organizations that have produced better-than-G...   \n",
              "1   According to the context, writing code is one ...   \n",
              "2   AI refers to Large Language Models, which are ...   \n",
              "3   According to the blog's 2023 tag cloud, 'opena...   \n",
              "4   The rise of LLMs has significantly impacted so...   \n",
              "5   Large language models (LLMs) have significantl...   \n",
              "6   Synthetic training data offers several direct ...   \n",
              "7   Improvements in LLM efficiency over the past y...   \n",
              "8   ChatGPT has been a recurring topic in blog pos...   \n",
              "9   Anthropic is one of the organizations that has...   \n",
              "10  Meta's Llama 3.3 70B fine-tuning process incor...   \n",
              "11  Recent advanced features introduced in ChatGPT...   \n",
              "\n",
              "                        synthesizer_name  \n",
              "0   single_hop_specifc_query_synthesizer  \n",
              "1   single_hop_specifc_query_synthesizer  \n",
              "2   single_hop_specifc_query_synthesizer  \n",
              "3   single_hop_specifc_query_synthesizer  \n",
              "4   multi_hop_abstract_query_synthesizer  \n",
              "5   multi_hop_abstract_query_synthesizer  \n",
              "6   multi_hop_abstract_query_synthesizer  \n",
              "7   multi_hop_abstract_query_synthesizer  \n",
              "8   multi_hop_specific_query_synthesizer  \n",
              "9   multi_hop_specific_query_synthesizer  \n",
              "10  multi_hop_specific_query_synthesizer  \n",
              "11  multi_hop_specific_query_synthesizer  "
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset.to_csv('./data/evaluation-dataset-using-cohere.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluation_dataset_with_cohere = EvaluationDataset.from_pandas(dataset.to_pandas())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257,
          "referenced_widgets": [
            "b09b0c42e0364396aee593f2ba1f18a2",
            "ae2cb8aa76424c01b0e39988cba92f0a",
            "9e837089e2ed4366b518306993092ede",
            "ccc8bd831acf490bb821cbe9a4d6ce5e",
            "d7f40417bcb24600b0e562fe2be29560",
            "a06cc5c232fe415c80c3a468b29ccc66",
            "d06dd06393844bbc8e176fea19a4e142",
            "31981ef797934adebeba357626d4e287",
            "66e038d8569b43fb8adc5211537fccef",
            "ab759276b57d4de6acefd71e01bcacc6",
            "117883f62a654d6996c2f9f8464cd22b"
          ]
        },
        "id": "5jXHvoIDCeKI",
        "outputId": "90b7754d-d2b0-487f-912f-6f572e56d2e4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "44be167525044c24b5b237dacece1669",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/72 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception raised in Job[1]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-ULKD0BfHsBV4junY2FxMu8EA on tokens per min (TPM): Limit 30000, Used 29657, Requested 1778. Please try again in 2.87s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "Exception raised in Job[13]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-ULKD0BfHsBV4junY2FxMu8EA on tokens per min (TPM): Limit 30000, Used 29498, Requested 1871. Please try again in 2.738s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "Exception raised in Job[25]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-ULKD0BfHsBV4junY2FxMu8EA on tokens per min (TPM): Limit 30000, Used 29606, Requested 1561. Please try again in 2.334s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "Exception raised in Job[7]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-ULKD0BfHsBV4junY2FxMu8EA on tokens per min (TPM): Limit 30000, Used 29449, Requested 2092. Please try again in 3.082s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "Exception raised in Job[24]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-ULKD0BfHsBV4junY2FxMu8EA on tokens per min (TPM): Limit 30000, Used 29601, Requested 1961. Please try again in 3.124s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "Exception raised in Job[30]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-ULKD0BfHsBV4junY2FxMu8EA on tokens per min (TPM): Limit 30000, Used 29835, Requested 2035. Please try again in 3.74s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "Exception raised in Job[19]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-ULKD0BfHsBV4junY2FxMu8EA on tokens per min (TPM): Limit 30000, Used 29604, Requested 1808. Please try again in 2.824s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "Exception raised in Job[11]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-ULKD0BfHsBV4junY2FxMu8EA on tokens per min (TPM): Limit 30000, Used 29599, Requested 1649. Please try again in 2.496s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "Exception raised in Job[36]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-ULKD0BfHsBV4junY2FxMu8EA on tokens per min (TPM): Limit 30000, Used 29751, Requested 1900. Please try again in 3.302s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "Exception raised in Job[29]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-ULKD0BfHsBV4junY2FxMu8EA on tokens per min (TPM): Limit 30000, Used 28660, Requested 1691. Please try again in 702ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "Exception raised in Job[31]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-ULKD0BfHsBV4junY2FxMu8EA on tokens per min (TPM): Limit 30000, Used 29599, Requested 2068. Please try again in 3.334s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "Exception raised in Job[32]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-ULKD0BfHsBV4junY2FxMu8EA on tokens per min (TPM): Limit 30000, Used 29731, Requested 1592. Please try again in 2.646s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "Exception raised in Job[43]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-ULKD0BfHsBV4junY2FxMu8EA on tokens per min (TPM): Limit 30000, Used 28427, Requested 1946. Please try again in 746ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "Exception raised in Job[54]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-ULKD0BfHsBV4junY2FxMu8EA on tokens per min (TPM): Limit 30000, Used 29423, Requested 1838. Please try again in 2.522s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "Exception raised in Job[50]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-ULKD0BfHsBV4junY2FxMu8EA on tokens per min (TPM): Limit 30000, Used 29631, Requested 1752. Please try again in 2.766s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "Exception raised in Job[37]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-ULKD0BfHsBV4junY2FxMu8EA on tokens per min (TPM): Limit 30000, Used 28627, Requested 2015. Please try again in 1.284s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "Exception raised in Job[48]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-ULKD0BfHsBV4junY2FxMu8EA on tokens per min (TPM): Limit 30000, Used 29414, Requested 2049. Please try again in 2.926s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "Exception raised in Job[42]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-ULKD0BfHsBV4junY2FxMu8EA on tokens per min (TPM): Limit 30000, Used 30000, Requested 1933. Please try again in 3.865s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "Exception raised in Job[35]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-ULKD0BfHsBV4junY2FxMu8EA on tokens per min (TPM): Limit 30000, Used 29803, Requested 1583. Please try again in 2.772s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "Exception raised in Job[49]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-ULKD0BfHsBV4junY2FxMu8EA on tokens per min (TPM): Limit 30000, Used 30000, Requested 2223. Please try again in 4.446s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n",
            "Exception raised in Job[53]: TimeoutError()\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'context_recall': 0.5694, 'faithfulness': 0.6740, 'factual_correctness': 0.5580, 'answer_relevancy': 0.8825, 'context_entity_recall': 0.3670, 'noise_sensitivity_relevant': 0.1346}"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result_with_cohere = evaluate(\n",
        "    dataset=evaluation_dataset_with_cohere,\n",
        "    metrics=[LLMContextRecall(), Faithfulness(), FactualCorrectness(), ResponseRelevancy(), ContextEntityRecall(), NoiseSensitivity()],\n",
        "    llm=evaluator_llm,\n",
        "    run_config=custom_run_config\n",
        ")\n",
        "result_with_cohere"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Baseline Result:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'context_recall': 0.4722, 'faithfulness': 0.7415, 'factual_correctness': 0.4225, 'answer_relevancy': 0.9538, 'context_entity_recall': 0.4993, 'noise_sensitivity_relevant': 0.1831}"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "baseline_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Result using Cohere:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'context_recall': 0.5694, 'faithfulness': 0.6740, 'factual_correctness': 0.5580, 'answer_relevancy': 0.8825, 'context_entity_recall': 0.3670, 'noise_sensitivity_relevant': 0.1346}"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result_with_cohere"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Comparison between Baseline and after Re-ranking**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.plotly.v1+json": {
              "config": {
                "plotlyServerURL": "https://plot.ly"
              },
              "data": [
                {
                  "name": "Baseline",
                  "textposition": "auto",
                  "type": "bar",
                  "x": [
                    "context_recall",
                    "faithfulness",
                    "factual_correctness",
                    "answer_relevancy",
                    "context_entity_recall",
                    "noise_sensitivity_relevant"
                  ],
                  "y": [
                    0.4722,
                    0.7415,
                    0.4225,
                    0.9538,
                    0.4993,
                    0.1831
                  ]
                },
                {
                  "name": "Using Cohere",
                  "textposition": "auto",
                  "type": "bar",
                  "x": [
                    "context_recall",
                    "faithfulness",
                    "factual_correctness",
                    "answer_relevancy",
                    "context_entity_recall",
                    "noise_sensitivity_relevant"
                  ],
                  "y": [
                    0.5694,
                    0.674,
                    0.55,
                    0.8825,
                    0.367,
                    0.1346
                  ]
                }
              ],
              "layout": {
                "barmode": "group",
                "template": {
                  "data": {
                    "bar": [
                      {
                        "error_x": {
                          "color": "#2a3f5f"
                        },
                        "error_y": {
                          "color": "#2a3f5f"
                        },
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "bar"
                      }
                    ],
                    "barpolar": [
                      {
                        "marker": {
                          "line": {
                            "color": "#E5ECF6",
                            "width": 0.5
                          },
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "barpolar"
                      }
                    ],
                    "carpet": [
                      {
                        "aaxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "baxis": {
                          "endlinecolor": "#2a3f5f",
                          "gridcolor": "white",
                          "linecolor": "white",
                          "minorgridcolor": "white",
                          "startlinecolor": "#2a3f5f"
                        },
                        "type": "carpet"
                      }
                    ],
                    "choropleth": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "choropleth"
                      }
                    ],
                    "contour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "contour"
                      }
                    ],
                    "contourcarpet": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "contourcarpet"
                      }
                    ],
                    "heatmap": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "heatmap"
                      }
                    ],
                    "histogram": [
                      {
                        "marker": {
                          "pattern": {
                            "fillmode": "overlay",
                            "size": 10,
                            "solidity": 0.2
                          }
                        },
                        "type": "histogram"
                      }
                    ],
                    "histogram2d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2d"
                      }
                    ],
                    "histogram2dcontour": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "histogram2dcontour"
                      }
                    ],
                    "mesh3d": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "type": "mesh3d"
                      }
                    ],
                    "parcoords": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "parcoords"
                      }
                    ],
                    "pie": [
                      {
                        "automargin": true,
                        "type": "pie"
                      }
                    ],
                    "scatter": [
                      {
                        "fillpattern": {
                          "fillmode": "overlay",
                          "size": 10,
                          "solidity": 0.2
                        },
                        "type": "scatter"
                      }
                    ],
                    "scatter3d": [
                      {
                        "line": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatter3d"
                      }
                    ],
                    "scattercarpet": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattercarpet"
                      }
                    ],
                    "scattergeo": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergeo"
                      }
                    ],
                    "scattergl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattergl"
                      }
                    ],
                    "scattermap": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattermap"
                      }
                    ],
                    "scattermapbox": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scattermapbox"
                      }
                    ],
                    "scatterpolar": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolar"
                      }
                    ],
                    "scatterpolargl": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterpolargl"
                      }
                    ],
                    "scatterternary": [
                      {
                        "marker": {
                          "colorbar": {
                            "outlinewidth": 0,
                            "ticks": ""
                          }
                        },
                        "type": "scatterternary"
                      }
                    ],
                    "surface": [
                      {
                        "colorbar": {
                          "outlinewidth": 0,
                          "ticks": ""
                        },
                        "colorscale": [
                          [
                            0,
                            "#0d0887"
                          ],
                          [
                            0.1111111111111111,
                            "#46039f"
                          ],
                          [
                            0.2222222222222222,
                            "#7201a8"
                          ],
                          [
                            0.3333333333333333,
                            "#9c179e"
                          ],
                          [
                            0.4444444444444444,
                            "#bd3786"
                          ],
                          [
                            0.5555555555555556,
                            "#d8576b"
                          ],
                          [
                            0.6666666666666666,
                            "#ed7953"
                          ],
                          [
                            0.7777777777777778,
                            "#fb9f3a"
                          ],
                          [
                            0.8888888888888888,
                            "#fdca26"
                          ],
                          [
                            1,
                            "#f0f921"
                          ]
                        ],
                        "type": "surface"
                      }
                    ],
                    "table": [
                      {
                        "cells": {
                          "fill": {
                            "color": "#EBF0F8"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "header": {
                          "fill": {
                            "color": "#C8D4E3"
                          },
                          "line": {
                            "color": "white"
                          }
                        },
                        "type": "table"
                      }
                    ]
                  },
                  "layout": {
                    "annotationdefaults": {
                      "arrowcolor": "#2a3f5f",
                      "arrowhead": 0,
                      "arrowwidth": 1
                    },
                    "autotypenumbers": "strict",
                    "coloraxis": {
                      "colorbar": {
                        "outlinewidth": 0,
                        "ticks": ""
                      }
                    },
                    "colorscale": {
                      "diverging": [
                        [
                          0,
                          "#8e0152"
                        ],
                        [
                          0.1,
                          "#c51b7d"
                        ],
                        [
                          0.2,
                          "#de77ae"
                        ],
                        [
                          0.3,
                          "#f1b6da"
                        ],
                        [
                          0.4,
                          "#fde0ef"
                        ],
                        [
                          0.5,
                          "#f7f7f7"
                        ],
                        [
                          0.6,
                          "#e6f5d0"
                        ],
                        [
                          0.7,
                          "#b8e186"
                        ],
                        [
                          0.8,
                          "#7fbc41"
                        ],
                        [
                          0.9,
                          "#4d9221"
                        ],
                        [
                          1,
                          "#276419"
                        ]
                      ],
                      "sequential": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ],
                      "sequentialminus": [
                        [
                          0,
                          "#0d0887"
                        ],
                        [
                          0.1111111111111111,
                          "#46039f"
                        ],
                        [
                          0.2222222222222222,
                          "#7201a8"
                        ],
                        [
                          0.3333333333333333,
                          "#9c179e"
                        ],
                        [
                          0.4444444444444444,
                          "#bd3786"
                        ],
                        [
                          0.5555555555555556,
                          "#d8576b"
                        ],
                        [
                          0.6666666666666666,
                          "#ed7953"
                        ],
                        [
                          0.7777777777777778,
                          "#fb9f3a"
                        ],
                        [
                          0.8888888888888888,
                          "#fdca26"
                        ],
                        [
                          1,
                          "#f0f921"
                        ]
                      ]
                    },
                    "colorway": [
                      "#636efa",
                      "#EF553B",
                      "#00cc96",
                      "#ab63fa",
                      "#FFA15A",
                      "#19d3f3",
                      "#FF6692",
                      "#B6E880",
                      "#FF97FF",
                      "#FECB52"
                    ],
                    "font": {
                      "color": "#2a3f5f"
                    },
                    "geo": {
                      "bgcolor": "white",
                      "lakecolor": "white",
                      "landcolor": "#E5ECF6",
                      "showlakes": true,
                      "showland": true,
                      "subunitcolor": "white"
                    },
                    "hoverlabel": {
                      "align": "left"
                    },
                    "hovermode": "closest",
                    "mapbox": {
                      "style": "light"
                    },
                    "paper_bgcolor": "white",
                    "plot_bgcolor": "#E5ECF6",
                    "polar": {
                      "angularaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "radialaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "scene": {
                      "xaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "yaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      },
                      "zaxis": {
                        "backgroundcolor": "#E5ECF6",
                        "gridcolor": "white",
                        "gridwidth": 2,
                        "linecolor": "white",
                        "showbackground": true,
                        "ticks": "",
                        "zerolinecolor": "white"
                      }
                    },
                    "shapedefaults": {
                      "line": {
                        "color": "#2a3f5f"
                      }
                    },
                    "ternary": {
                      "aaxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "baxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      },
                      "bgcolor": "#E5ECF6",
                      "caxis": {
                        "gridcolor": "white",
                        "linecolor": "white",
                        "ticks": ""
                      }
                    },
                    "title": {
                      "x": 0.05
                    },
                    "xaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    },
                    "yaxis": {
                      "automargin": true,
                      "gridcolor": "white",
                      "linecolor": "white",
                      "ticks": "",
                      "title": {
                        "standoff": 15
                      },
                      "zerolinecolor": "white",
                      "zerolinewidth": 2
                    }
                  }
                },
                "title": {
                  "text": "RAG Evaluation Metrics: Baseline vs Using Cohere Reranker"
                },
                "xaxis": {
                  "tickangle": -45
                },
                "yaxis": {
                  "title": {
                    "text": "Score"
                  }
                }
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "# Extracted metrics from the image\n",
        "baseline_result = {\n",
        "    'context_recall': 0.4722,\n",
        "    'faithfulness': 0.7415,\n",
        "    'factual_correctness': 0.4225,\n",
        "    'answer_relevancy': 0.9538,\n",
        "    'context_entity_recall': 0.4993,\n",
        "    'noise_sensitivity_relevant': 0.1831\n",
        "}\n",
        "\n",
        "cohere_result = {\n",
        "    'context_recall': 0.5694,\n",
        "    'faithfulness': 0.6740,\n",
        "    'factual_correctness': 0.5500,\n",
        "    'answer_relevancy': 0.8825,\n",
        "    'context_entity_recall': 0.3670,\n",
        "    'noise_sensitivity_relevant': 0.1346\n",
        "}\n",
        "\n",
        "# Common x-axis\n",
        "metrics = list(baseline_result.keys())\n",
        "\n",
        "# Bar chart\n",
        "fig = go.Figure()\n",
        "\n",
        "fig.add_trace(go.Bar(\n",
        "    x=metrics,\n",
        "    y=[baseline_result[m] for m in metrics],\n",
        "    name='Baseline',\n",
        "    textposition='auto'\n",
        "))\n",
        "\n",
        "fig.add_trace(go.Bar(\n",
        "    x=metrics,\n",
        "    y=[cohere_result[m] for m in metrics],\n",
        "    name='Using Cohere',\n",
        "    textposition='auto'\n",
        "))\n",
        "\n",
        "# Layout settings\n",
        "fig.update_layout(\n",
        "    title='RAG Evaluation Metrics: Baseline vs Using Cohere Reranker',\n",
        "    yaxis_title='Score',\n",
        "    barmode='group',\n",
        "    xaxis_tickangle=-45\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Question: \n",
        "\n",
        "Which system performed better, on what metrics, and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "| **Metric**                | **Baseline** | **Using Cohere** | **Better System** | **Explanation**                                                                       |\n",
        "| ------------------------- | ------------ | ---------------- | ----------------- | ------------------------------------------------------------------------------------- |\n",
        "| **Context Recall**        | 0.4722       | **0.5694**       | ‚úÖ Cohere          | Retrieved more relevant content; higher recall due to reranking.                      |\n",
        "| **Faithfulness (‚Üì)**          | **0.7415**   | 0.6740           | ‚úÖ Baseline        | Answers better aligned with provided context in baseline.                             |\n",
        "| **Factual Correctness**   | 0.4225       | **0.5500**       | ‚úÖ Cohere          | Improved factual grounding with top reranked context.                                 |\n",
        "| **Answer Relevancy (‚Üì)**      | **0.9538**   | 0.8825           | ‚úÖ Baseline        | Slightly more precise answers in baseline; less dilution.                             |\n",
        "| **Context Entity Recall (‚Üì)** | **0.4993**   | 0.3670           | ‚úÖ Baseline        | More named entities preserved in baseline; Cohere compression may have filtered some. |\n",
        "| **Noise Sensitivity (‚Üì)** | 0.1831       | **0.1346**       | ‚úÖ Cohere          | Less affected by noisy/unrelated context; better precision under Cohere.              |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Conclusion**\n",
        "\n",
        "* **Cohere reranking improved**:\n",
        "\n",
        "  * **Context recall**, **factual correctness**, and **noise robustness**\n",
        "  * Ideal for improving accuracy and grounding\n",
        "\n",
        "* **Baseline performed better** in:\n",
        "\n",
        "  * **Faithfulness**, **answer relevancy**, and **entity recall**\n",
        "  * Better if retaining broader context fidelity is more important\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Therefore, if **factual accuracy and robustness** are your goals, **Cohere** outperforms.  If you prioritize **tight alignment to reference context and high answer relevancy**, stick with the **Baseline**.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0107beec40af42ffa66b216070f97d5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "01fa9def167548fba96e573921712950": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c470306f04542f29c53dd21a4de93d7",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7c0ead4589784ecb8d5380a895fe1c41",
            "value": 3
          }
        },
        "03e6ff4dc0d645668324964cbf114211": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7803a3e67b28452390202dc69d4289f3",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_618a24e305d44bd39a3023aa44f3383c",
            "value": "Applying‚Äá[CosineSimilarityBuilder,‚ÄáOverlapScoreBuilder]:‚Äá‚Äá‚Äá0%"
          }
        },
        "0e460f92c5a749efb198864545a124c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_245c32a588d142628f06eba44324c1b8",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_f9499b2235294b638ed87d73894b341f",
            "value": "‚Äá1/2‚Äá[00:02&lt;00:02,‚Äá‚Äá2.48s/it]"
          }
        },
        "117883f62a654d6996c2f9f8464cd22b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11d272eb6b7146659e5c688ec04c8749": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba29aad6b8d74a09ad347ce8648deeab",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_96426fde6b9542208f45409965d0216c",
            "value": "Generating‚ÄáSamples:‚Äá100%"
          }
        },
        "16a0c539ddb040d7b32047894480a348": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "19160948d9af4cd5bfe1a8a97727fb49": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4470c9d055c4b8793dda8dfc7496b83",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_4183285878f347f1b8caae9dce6ec0fd",
            "value": "Applying‚ÄáCustomNodeFilter:‚Äá‚Äá75%"
          }
        },
        "1ea4551d38bc4e3ea2a99eb62e6bf942": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "1f6cdc06bb18480aa341a732a2f1be13": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e03f27c3ff84046bceb5b4ec1dec571",
            "max": 72,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_44f817c0df384faa90ac99e8bd772bc5",
            "value": 72
          }
        },
        "20848c82096c458fb118006897a0b7e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "245c32a588d142628f06eba44324c1b8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25baeb72f87d4e5ba0e8c10bcf3afd58": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b72baad55d34b77b5c56588c00280b9",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_16a0c539ddb040d7b32047894480a348",
            "value": "‚Äá26/26‚Äá[00:06&lt;00:00,‚Äá‚Äá3.07it/s]"
          }
        },
        "2b4f209c6c3c46abaa0d5a83cb10ae38": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c9e188608204caa9c6a449843084ceb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8299304353ff46b597fdadeacddabdf5",
              "IPY_MODEL_fc33ba2055c149a4a85ac6f586de47ee",
              "IPY_MODEL_8e87eb2bff19452ab778993dbc1a2586"
            ],
            "layout": "IPY_MODEL_be4c08a6cdb54d23a32b283379fdea8e"
          }
        },
        "2d888020728341a6ad146908634a6a2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e5fe22186e742e6bd1142a0d8471656",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_79fce08fefc948d0bec02db61a6ab21b",
            "value": "‚Äá0/2‚Äá[00:00&lt;?,‚Äá?it/s]"
          }
        },
        "31981ef797934adebeba357626d4e287": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "319b66f299064965b91ce4282dc9c280": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3230d232b04448fe9a68a204b46bc91c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35e6cd723807485f81eb053c2c92b96c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35e71aea98cc41b7a090071a9d8ccde7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "37831f1641db461e93e5011d343b5cb2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b72baad55d34b77b5c56588c00280b9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c470306f04542f29c53dd21a4de93d7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4183285878f347f1b8caae9dce6ec0fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4347f5ea75c74effbc9552cb69c82301": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "44f817c0df384faa90ac99e8bd772bc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4592465145b44c17a9acb5fcab9b2e8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "472c776f27834cd8907902679ff93c24": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_19160948d9af4cd5bfe1a8a97727fb49",
              "IPY_MODEL_d528743f9a0047778a7f808214fdf49c",
              "IPY_MODEL_a37137bd3fad4362bef3817ae7ad2ad9"
            ],
            "layout": "IPY_MODEL_da926343593245d9b34f8a77183c4115"
          }
        },
        "4e03f27c3ff84046bceb5b4ec1dec571": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "521c3b51f249490986addd4010423064": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bda6a62b9fd143a3b0628e60580d23c9",
              "IPY_MODEL_970b83c42f4f4d7ebb252c4f26f6ea56",
              "IPY_MODEL_d1e5f706d17b4c27b0ce1cb127fdc891"
            ],
            "layout": "IPY_MODEL_7d5ccb84254b461da11bd8045424bc30"
          }
        },
        "559b618c027e4f12bfe58286b208c9b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "594a9d371fb4406e97630f35712d276c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7bf032ee32c46628a3a28ff2cedcc10",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_810264507cae4987b88531845ca03921",
            "value": "Applying‚Äá[EmbeddingExtractor,‚ÄáThemesExtractor,‚ÄáNERExtractor]:‚Äá100%"
          }
        },
        "5bec2586cfcb4ddabf9f2378b32fa4dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5cea5f1121f64866b6932ac6bb0a8829": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_03e6ff4dc0d645668324964cbf114211",
              "IPY_MODEL_c1b6cdf48bae4226a374ffbabb861ecc",
              "IPY_MODEL_ec44f75ea457496c9443b881bc156146"
            ],
            "layout": "IPY_MODEL_d64c39da94b148d4989fe271521dc967"
          }
        },
        "5d5df07e34d545ed9b2975034645c453": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e5fe22186e742e6bd1142a0d8471656": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "618a24e305d44bd39a3023aa44f3383c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66e038d8569b43fb8adc5211537fccef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "675034bd626b4c528eb77e35e4087191": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "68599f8e85ef4fcba92ea891f75b5535": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bba06b49269840ea8247ecc85552050b",
            "max": 12,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9e0794e92f9646ab8aa21f0ec0ed7981",
            "value": 12
          }
        },
        "7288a537b3034e499797d2c3294f8383": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8723f89faf044f97b5abfa3666404497",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_7c8f4bf420754b538baea7a420b6a76a",
            "value": "‚Äá3/3‚Äá[00:10&lt;00:00,‚Äá‚Äá3.60s/it]"
          }
        },
        "74ac36e0ca6c4a3ba53d070b37b9f1aa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7803a3e67b28452390202dc69d4289f3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79fce08fefc948d0bec02db61a6ab21b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a84047d2b724edd891ca63b5741a43b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c0ead4589784ecb8d5380a895fe1c41": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7c8f4bf420754b538baea7a420b6a76a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7cfc3038a06249819e2496f7e0571b89": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec3472c7d29b4ad0ab91e3c2f6874bd5",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_2b4f209c6c3c46abaa0d5a83cb10ae38",
            "value": "Generating‚ÄáScenarios:‚Äá100%"
          }
        },
        "7d5ccb84254b461da11bd8045424bc30": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "810264507cae4987b88531845ca03921": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8299304353ff46b597fdadeacddabdf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5a56214fe25441e8a5004ec76476a94",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_3230d232b04448fe9a68a204b46bc91c",
            "value": "Applying‚ÄáSummaryExtractor:‚Äá100%"
          }
        },
        "837e33bad8be4a6d8722ca878b9d409e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8723f89faf044f97b5abfa3666404497": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b77a827824440d6b53f4a14346c0d70": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ba70976ee1c451184f77494d8c47c7d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8be24cac973b4db7a85ab46581c1efb7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c251e4b43214ca894f136c5397b4a94": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e87eb2bff19452ab778993dbc1a2586": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8be24cac973b4db7a85ab46581c1efb7",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_cbe80c1e537a413ebe0f5a98038148d6",
            "value": "‚Äá2/2‚Äá[00:03&lt;00:00,‚Äá‚Äá1.64s/it]"
          }
        },
        "8f986d822b964e969ad20d1b1088dec9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fe50cb21cf9449e94efe57920440845": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96426fde6b9542208f45409965d0216c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96b1fb2a1577445d9778ad65da0abdbb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "970b83c42f4f4d7ebb252c4f26f6ea56": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_837e33bad8be4a6d8722ca878b9d409e",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_559b618c027e4f12bfe58286b208c9b4",
            "value": 2
          }
        },
        "9e0794e92f9646ab8aa21f0ec0ed7981": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9e837089e2ed4366b518306993092ede": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31981ef797934adebeba357626d4e287",
            "max": 72,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_66e038d8569b43fb8adc5211537fccef",
            "value": 72
          }
        },
        "a06cc5c232fe415c80c3a468b29ccc66": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a37137bd3fad4362bef3817ae7ad2ad9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74ac36e0ca6c4a3ba53d070b37b9f1aa",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ba53eab6f7e441569d2a16aa8f26511d",
            "value": "‚Äá9/12‚Äá[00:00&lt;00:00,‚Äá13.99it/s]"
          }
        },
        "a5e6260095bf4ca6bce229adfe9c3fbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb12c0b6145b48908ca058e0a7282828",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0107beec40af42ffa66b216070f97d5c",
            "value": 2
          }
        },
        "a604a0b844a94570be523a881c8455ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_594a9d371fb4406e97630f35712d276c",
              "IPY_MODEL_d52c4da39f564a12ba46044e0797eb95",
              "IPY_MODEL_25baeb72f87d4e5ba0e8c10bcf3afd58"
            ],
            "layout": "IPY_MODEL_96b1fb2a1577445d9778ad65da0abdbb"
          }
        },
        "a74c472ad4ff49d49dd6648ce89f5471": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b12c215bb97e49fea6129d7ca7cdcc6b",
              "IPY_MODEL_f37518d278b34353a38bcc50f8743959",
              "IPY_MODEL_2d888020728341a6ad146908634a6a2f"
            ],
            "layout": "IPY_MODEL_1ea4551d38bc4e3ea2a99eb62e6bf942"
          }
        },
        "ab759276b57d4de6acefd71e01bcacc6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae2cb8aa76424c01b0e39988cba92f0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a06cc5c232fe415c80c3a468b29ccc66",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_d06dd06393844bbc8e176fea19a4e142",
            "value": "Evaluating:‚Äá100%"
          }
        },
        "b09b0c42e0364396aee593f2ba1f18a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ae2cb8aa76424c01b0e39988cba92f0a",
              "IPY_MODEL_9e837089e2ed4366b518306993092ede",
              "IPY_MODEL_ccc8bd831acf490bb821cbe9a4d6ce5e"
            ],
            "layout": "IPY_MODEL_d7f40417bcb24600b0e562fe2be29560"
          }
        },
        "b12c215bb97e49fea6129d7ca7cdcc6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da4d36932dad4270a94b003affc28333",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_675034bd626b4c528eb77e35e4087191",
            "value": "Applying‚ÄáHeadlineSplitter:‚Äá‚Äá‚Äá0%"
          }
        },
        "b38eb659d045417cb0e05a4486a83590": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7cfc3038a06249819e2496f7e0571b89",
              "IPY_MODEL_01fa9def167548fba96e573921712950",
              "IPY_MODEL_7288a537b3034e499797d2c3294f8383"
            ],
            "layout": "IPY_MODEL_f3c9086c454841f6914e299a11f7d217"
          }
        },
        "ba29aad6b8d74a09ad347ce8648deeab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba53eab6f7e441569d2a16aa8f26511d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bba06b49269840ea8247ecc85552050b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bda6a62b9fd143a3b0628e60580d23c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd71a316693343cc9a92fae9471a2f6e",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_35e6cd723807485f81eb053c2c92b96c",
            "value": "Generating‚Äápersonas:‚Äá100%"
          }
        },
        "be4c08a6cdb54d23a32b283379fdea8e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "bf73dc001ec14333975be942dc78df31": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ea51201a73a045de8579dafb17d70bec",
              "IPY_MODEL_a5e6260095bf4ca6bce229adfe9c3fbe",
              "IPY_MODEL_0e460f92c5a749efb198864545a124c0"
            ],
            "layout": "IPY_MODEL_4347f5ea75c74effbc9552cb69c82301"
          }
        },
        "c1b6cdf48bae4226a374ffbabb861ecc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9f54cd68cd8493fb1bc2a216eb15c03",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4592465145b44c17a9acb5fcab9b2e8b",
            "value": 2
          }
        },
        "c40abe6ce691401ea8db2562b3b322fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4470c9d055c4b8793dda8dfc7496b83": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb12c0b6145b48908ca058e0a7282828": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbe80c1e537a413ebe0f5a98038148d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ccc8bd831acf490bb821cbe9a4d6ce5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab759276b57d4de6acefd71e01bcacc6",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_117883f62a654d6996c2f9f8464cd22b",
            "value": "‚Äá72/72‚Äá[04:58&lt;00:00,‚Äá15.82s/it]"
          }
        },
        "d06dd06393844bbc8e176fea19a4e142": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0718259769b46089abda354accc4de8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_df156fe12b7c4d1dbb4f688d7bd3c4a3",
              "IPY_MODEL_1f6cdc06bb18480aa341a732a2f1be13",
              "IPY_MODEL_e362bfd3e01241c6b20e2cf0a34db7a1"
            ],
            "layout": "IPY_MODEL_8ba70976ee1c451184f77494d8c47c7d"
          }
        },
        "d08cba8d32514ca2bb1e0d403ceadd7e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1b550cbeaef43a7a98ffbba97fb37ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f10fe2d8ed6e45b595e66db0a3f972a1",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_fe1cfe8194c142fdb11a4dd28e1adb00",
            "value": "‚Äá12/12‚Äá[00:04&lt;00:00,‚Äá‚Äá3.98it/s]"
          }
        },
        "d1e5f706d17b4c27b0ce1cb127fdc891": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d5df07e34d545ed9b2975034645c453",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_319b66f299064965b91ce4282dc9c280",
            "value": "‚Äá2/2‚Äá[00:01&lt;00:00,‚Äá‚Äá1.35it/s]"
          }
        },
        "d390d71dd2694801a77b103a6a707da3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_11d272eb6b7146659e5c688ec04c8749",
              "IPY_MODEL_68599f8e85ef4fcba92ea891f75b5535",
              "IPY_MODEL_d1b550cbeaef43a7a98ffbba97fb37ee"
            ],
            "layout": "IPY_MODEL_d08cba8d32514ca2bb1e0d403ceadd7e"
          }
        },
        "d528743f9a0047778a7f808214fdf49c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37831f1641db461e93e5011d343b5cb2",
            "max": 12,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f69d31545a1045d4959e0640abe3409a",
            "value": 12
          }
        },
        "d52c4da39f564a12ba46044e0797eb95": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6395d76874241cf87b37390a6c58424",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_35e71aea98cc41b7a090071a9d8ccde7",
            "value": 26
          }
        },
        "d6395d76874241cf87b37390a6c58424": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d64c39da94b148d4989fe271521dc967": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "d7f40417bcb24600b0e562fe2be29560": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9f54cd68cd8493fb1bc2a216eb15c03": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da4d36932dad4270a94b003affc28333": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da926343593245d9b34f8a77183c4115": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "df156fe12b7c4d1dbb4f688d7bd3c4a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea70433388ef4d1aaf1093eaeea94dd4",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8fe50cb21cf9449e94efe57920440845",
            "value": "Evaluating:‚Äá100%"
          }
        },
        "e0e92282b50048c4a25414273f1777ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e362bfd3e01241c6b20e2cf0a34db7a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c251e4b43214ca894f136c5397b4a94",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e74718a731f0471e9740a7ae5aec571e",
            "value": "‚Äá72/72‚Äá[04:59&lt;00:00,‚Äá16.52s/it]"
          }
        },
        "e74718a731f0471e9740a7ae5aec571e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea51201a73a045de8579dafb17d70bec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f986d822b964e969ad20d1b1088dec9",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c40abe6ce691401ea8db2562b3b322fb",
            "value": "Applying‚ÄáHeadlinesExtractor:‚Äá‚Äá50%"
          }
        },
        "ea70433388ef4d1aaf1093eaeea94dd4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec3472c7d29b4ad0ab91e3c2f6874bd5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec44f75ea457496c9443b881bc156146": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b77a827824440d6b53f4a14346c0d70",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_20848c82096c458fb118006897a0b7e0",
            "value": "‚Äá0/2‚Äá[00:00&lt;?,‚Äá?it/s]"
          }
        },
        "f10fe2d8ed6e45b595e66db0a3f972a1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f37518d278b34353a38bcc50f8743959": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a84047d2b724edd891ca63b5741a43b",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5bec2586cfcb4ddabf9f2378b32fa4dc",
            "value": 2
          }
        },
        "f3c9086c454841f6914e299a11f7d217": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5a56214fe25441e8a5004ec76476a94": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f69d31545a1045d4959e0640abe3409a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f7bf032ee32c46628a3a28ff2cedcc10": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9499b2235294b638ed87d73894b341f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc33ba2055c149a4a85ac6f586de47ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd11e4046c464b7285ddd7a7b7cd51c8",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e0e92282b50048c4a25414273f1777ff",
            "value": 2
          }
        },
        "fd11e4046c464b7285ddd7a7b7cd51c8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd71a316693343cc9a92fae9471a2f6e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe1cfe8194c142fdb11a4dd28e1adb00": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "state": {}
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
